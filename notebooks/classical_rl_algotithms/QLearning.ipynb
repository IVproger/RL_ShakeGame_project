{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow to import modules from the project root directory\n",
    "import sys\n",
    "import os\n",
    "# Add the project root directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from src.ParObsSnakeEnv import ParObsSnakeEnv\n",
    "from src.FullObsSnakeEnv import FullObsSnakeEnv\n",
    "from src.utils import compute_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../artifacts/images/Qlearning.png\" alt=\"Q-learning algorithm\" width=\"1000\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent:\n",
    "    def __init__(self, env, learning_rate=0.5, discount_factor=0.99, epsilon=0.1, learning_rate_decay=0.8, epsilon_decay=0.9):\n",
    "        self.env = env\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "        self.learning_rate_decay = learning_rate_decay\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.q_table = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "\n",
    "    def choose_action(self, state, Greedy=False):\n",
    "        state = tuple(state.flatten())\n",
    "        if Greedy:\n",
    "            return np.argmax(self.q_table[state]), None\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return self.env.action_space.sample(), None  # Explore\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state]), None  # Exploit\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        next_action = self.choose_action(next_state, Greedy=True)  # Choose next action using epsilon-greedy approach\n",
    "        next_state = tuple(next_state.flatten())\n",
    "        state = tuple(state.flatten())\n",
    "        td_target = reward + self.discount_factor * self.q_table[next_state][next_action]\n",
    "        td_error = td_target - self.q_table[state][action]\n",
    "        self.q_table[state][action] += self.learning_rate * td_error\n",
    "\n",
    "    def print_qtable(self):\n",
    "        for state, actions in self.q_table.items():\n",
    "            print(f\"State: {state}\")\n",
    "            for action, value in enumerate(actions):\n",
    "                print(f\"  Action {action}: {value:.2f}\")\n",
    "            print()\n",
    "    \n",
    "    def save_table(self, table_path):\n",
    "        with open(table_path, 'wb') as f:\n",
    "            pickle.dump(dict(self.q_table), f)\n",
    "    \n",
    "    def load_table(self, table_path):\n",
    "        with open(table_path, 'rb') as f:\n",
    "            self.q_table = pickle.load(f)\n",
    "\n",
    "    def train(self, num_episodes):\n",
    "        for episode in tqdm(range(num_episodes), desc='Training', unit='Episode'):\n",
    "            state = self.env.reset()\n",
    "            done = False\n",
    "            while not done:\n",
    "                action, _ = self.choose_action(state)\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                self.update_q_value(state, action, reward, next_state)\n",
    "                state = next_state\n",
    "            # decaying    \n",
    "            if episode % 1000 == 0 and episode != 0:\n",
    "                self.epsilon *= self.epsilon_decay  # Decay epsilon\n",
    "                self.learning_rate *= self.learning_rate_decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 10\n",
    "# env = FullObsSnakeEnv(grid_size=grid_size, interact=False)\n",
    "env = ParObsSnakeEnv(grid_size=grid_size, interact=False)\n",
    "agent = QLearningAgent(env, epsilon=0.1, discount_factor=0.9, learning_rate=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/50000 [00:00<?, ?Episode/s]/tmp/ipykernel_63578/323638319.py:26: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  self.q_table[state][action] += self.learning_rate * td_error\n",
      "Training: 100%|██████████| 50000/50000 [02:03<00:00, 406.09Episode/s]\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 50000\n",
    "agent.train(num_episodes=num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = 'full 'if isinstance(env, FullObsSnakeEnv) else 'par'\n",
    "\n",
    "table_name = f'q_learning_table_{environment}_{num_episodes}_{grid_size}.pkl'\n",
    "model_weights_dir = os.path.join('../..', 'models', 'q-learning')\n",
    "os.makedirs(model_weights_dir, exist_ok=True)\n",
    "table_path = os.path.join(model_weights_dir, table_name)\n",
    "\n",
    "agent.save_table(table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [00:00<00:00, 222.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 16, Episode reward: 1233\n",
      "Snake length: 16, Episode reward: 1331\n",
      "Snake length: 51, Episode reward: 4375\n",
      "Snake length: 30, Episode reward: 2486\n",
      "Snake length: 18, Episode reward: 1432\n",
      "Snake length: 31, Episode reward: 2670\n",
      "Snake length: 24, Episode reward: 1953\n",
      "Snake length: 30, Episode reward: 2450\n",
      "Snake length: 17, Episode reward: 1351\n",
      "Snake length: 36, Episode reward: 3000\n",
      "Snake length: 30, Episode reward: 2469\n",
      "Snake length: 13, Episode reward: 945\n",
      "Snake length: 32, Episode reward: 2755\n",
      "Snake length: 19, Episode reward: 1489\n",
      "Snake length: 18, Episode reward: 1446\n",
      "Snake length: 28, Episode reward: 2291\n",
      "Snake length: 15, Episode reward: 1177\n",
      "Snake length: 37, Episode reward: 3068\n",
      "Snake length: 39, Episode reward: 3340\n",
      "Snake length: 16, Episode reward: 1246\n",
      "Snake length: 29, Episode reward: 2412\n",
      "Snake length: 35, Episode reward: 2974\n",
      "Snake length: 9, Episode reward: 625\n",
      "Snake length: 18, Episode reward: 1397\n",
      "Snake length: 22, Episode reward: 1826\n",
      "Snake length: 41, Episode reward: 3558\n",
      "Snake length: 40, Episode reward: 3405\n",
      "Snake length: 22, Episode reward: 1783\n",
      "Snake length: 25, Episode reward: 2002\n",
      "Snake length: 34, Episode reward: 2900\n",
      "Snake length: 38, Episode reward: 3258\n",
      "Snake length: 25, Episode reward: 2047\n",
      "Snake length: 24, Episode reward: 1980\n",
      "Snake length: 35, Episode reward: 2971\n",
      "Snake length: 42, Episode reward: 3572\n",
      "Snake length: 26, Episode reward: 2128\n",
      "Snake length: 29, Episode reward: 2324\n",
      "Snake length: 43, Episode reward: 3598\n",
      "Snake length: 28, Episode reward: 2288\n",
      "Snake length: 24, Episode reward: 1939\n",
      "Snake length: 40, Episode reward: 3386\n",
      "Snake length: 18, Episode reward: 1441\n",
      "Snake length: 35, Episode reward: 2960\n",
      "Snake length: 14, Episode reward: 1099\n",
      "Snake length: 31, Episode reward: 2592\n",
      "Snake length: 8, Episode reward: 555\n",
      "Snake length: 38, Episode reward: 3225\n",
      "Snake length: 29, Episode reward: 2373\n",
      "Snake length: 21, Episode reward: 1694\n",
      "Snake length: 18, Episode reward: 1439\n",
      "Snake length: 21, Episode reward: 1636\n",
      "Snake length: 30, Episode reward: 2526\n",
      "Snake length: 10, Episode reward: 724\n",
      "Snake length: 42, Episode reward: 3642\n",
      "Snake length: 32, Episode reward: 2658\n",
      "Snake length: 26, Episode reward: 2103\n",
      "Snake length: 15, Episode reward: 1176\n",
      "Snake length: 30, Episode reward: 2450\n",
      "Snake length: 38, Episode reward: 3146\n",
      "Snake length: 27, Episode reward: 2256\n",
      "Snake length: 27, Episode reward: 2249\n",
      "Snake length: 29, Episode reward: 2483\n",
      "Snake length: 24, Episode reward: 1949\n",
      "Snake length: 35, Episode reward: 2989\n",
      "Snake length: 40, Episode reward: 3392\n",
      "Snake length: 35, Episode reward: 2978\n",
      "Snake length: 26, Episode reward: 2146\n",
      "Snake length: 31, Episode reward: 2659\n",
      "Snake length: 35, Episode reward: 2905\n",
      "Snake length: 41, Episode reward: 3399\n",
      "Snake length: 28, Episode reward: 2287\n",
      "Snake length: 38, Episode reward: 3258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 244.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 31, Episode reward: 2605\n",
      "Snake length: 5, Episode reward: 282\n",
      "Snake length: 34, Episode reward: 2913\n",
      "Snake length: 33, Episode reward: 2681\n",
      "Snake length: 16, Episode reward: 1266\n",
      "Snake length: 22, Episode reward: 1836\n",
      "Snake length: 25, Episode reward: 2035\n",
      "Snake length: 28, Episode reward: 2352\n",
      "Snake length: 35, Episode reward: 2904\n",
      "Snake length: 40, Episode reward: 3400\n",
      "Snake length: 11, Episode reward: 801\n",
      "Snake length: 26, Episode reward: 2188\n",
      "Snake length: 25, Episode reward: 2079\n",
      "Snake length: 35, Episode reward: 2899\n",
      "Snake length: 31, Episode reward: 2510\n",
      "Snake length: 37, Episode reward: 3089\n",
      "Snake length: 38, Episode reward: 3221\n",
      "Snake length: 26, Episode reward: 2127\n",
      "Snake length: 17, Episode reward: 1294\n",
      "Snake length: 24, Episode reward: 2042\n",
      "Snake length: 20, Episode reward: 1569\n",
      "Snake length: 35, Episode reward: 2939\n",
      "Snake length: 35, Episode reward: 2983\n",
      "Snake length: 15, Episode reward: 1172\n",
      "Snake length: 45, Episode reward: 3864\n",
      "Snake length: 16, Episode reward: 1290\n",
      "Snake length: 33, Episode reward: 2720\n",
      "Snake length: 23, Episode reward: 1860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'snake_lengths': [16,\n",
       "  16,\n",
       "  51,\n",
       "  30,\n",
       "  18,\n",
       "  31,\n",
       "  24,\n",
       "  30,\n",
       "  17,\n",
       "  36,\n",
       "  30,\n",
       "  13,\n",
       "  32,\n",
       "  19,\n",
       "  18,\n",
       "  28,\n",
       "  15,\n",
       "  37,\n",
       "  39,\n",
       "  16,\n",
       "  29,\n",
       "  35,\n",
       "  9,\n",
       "  18,\n",
       "  22,\n",
       "  41,\n",
       "  40,\n",
       "  22,\n",
       "  25,\n",
       "  34,\n",
       "  38,\n",
       "  25,\n",
       "  24,\n",
       "  35,\n",
       "  42,\n",
       "  26,\n",
       "  29,\n",
       "  43,\n",
       "  28,\n",
       "  24,\n",
       "  40,\n",
       "  18,\n",
       "  35,\n",
       "  14,\n",
       "  31,\n",
       "  8,\n",
       "  38,\n",
       "  29,\n",
       "  21,\n",
       "  18,\n",
       "  21,\n",
       "  30,\n",
       "  10,\n",
       "  42,\n",
       "  32,\n",
       "  26,\n",
       "  15,\n",
       "  30,\n",
       "  38,\n",
       "  27,\n",
       "  27,\n",
       "  29,\n",
       "  24,\n",
       "  35,\n",
       "  40,\n",
       "  35,\n",
       "  26,\n",
       "  31,\n",
       "  35,\n",
       "  41,\n",
       "  28,\n",
       "  38,\n",
       "  31,\n",
       "  5,\n",
       "  34,\n",
       "  33,\n",
       "  16,\n",
       "  22,\n",
       "  25,\n",
       "  28,\n",
       "  35,\n",
       "  40,\n",
       "  11,\n",
       "  26,\n",
       "  25,\n",
       "  35,\n",
       "  31,\n",
       "  37,\n",
       "  38,\n",
       "  26,\n",
       "  17,\n",
       "  24,\n",
       "  20,\n",
       "  35,\n",
       "  35,\n",
       "  15,\n",
       "  45,\n",
       "  16,\n",
       "  33,\n",
       "  23],\n",
       " 'episode_rewards': [1233,\n",
       "  1331,\n",
       "  4375,\n",
       "  2486,\n",
       "  1432,\n",
       "  2670,\n",
       "  1953,\n",
       "  2450,\n",
       "  1351,\n",
       "  3000,\n",
       "  2469,\n",
       "  945,\n",
       "  2755,\n",
       "  1489,\n",
       "  1446,\n",
       "  2291,\n",
       "  1177,\n",
       "  3068,\n",
       "  3340,\n",
       "  1246,\n",
       "  2412,\n",
       "  2974,\n",
       "  625,\n",
       "  1397,\n",
       "  1826,\n",
       "  3558,\n",
       "  3405,\n",
       "  1783,\n",
       "  2002,\n",
       "  2900,\n",
       "  3258,\n",
       "  2047,\n",
       "  1980,\n",
       "  2971,\n",
       "  3572,\n",
       "  2128,\n",
       "  2324,\n",
       "  3598,\n",
       "  2288,\n",
       "  1939,\n",
       "  3386,\n",
       "  1441,\n",
       "  2960,\n",
       "  1099,\n",
       "  2592,\n",
       "  555,\n",
       "  3225,\n",
       "  2373,\n",
       "  1694,\n",
       "  1439,\n",
       "  1636,\n",
       "  2526,\n",
       "  724,\n",
       "  3642,\n",
       "  2658,\n",
       "  2103,\n",
       "  1176,\n",
       "  2450,\n",
       "  3146,\n",
       "  2256,\n",
       "  2249,\n",
       "  2483,\n",
       "  1949,\n",
       "  2989,\n",
       "  3392,\n",
       "  2978,\n",
       "  2146,\n",
       "  2659,\n",
       "  2905,\n",
       "  3399,\n",
       "  2287,\n",
       "  3258,\n",
       "  2605,\n",
       "  282,\n",
       "  2913,\n",
       "  2681,\n",
       "  1266,\n",
       "  1836,\n",
       "  2035,\n",
       "  2352,\n",
       "  2904,\n",
       "  3400,\n",
       "  801,\n",
       "  2188,\n",
       "  2079,\n",
       "  2899,\n",
       "  2510,\n",
       "  3089,\n",
       "  3221,\n",
       "  2127,\n",
       "  1294,\n",
       "  2042,\n",
       "  1569,\n",
       "  2939,\n",
       "  2983,\n",
       "  1172,\n",
       "  3864,\n",
       "  1290,\n",
       "  2720,\n",
       "  1860]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if isinstance(env, ParObsSnakeEnv):\n",
    "    env = ParObsSnakeEnv(grid_size=2*grid_size, interact=False)\n",
    "\n",
    "num_simulations = 100\n",
    "metrics_name = f'q_learning_metrics_{environment}_{num_episodes}_{env.grid_size}_{num_simulations}.jsn'\n",
    "model_metrics_dir = os.path.join('../..', 'artifacts', 'models_stats', 'q-learning')\n",
    "os.makedirs(model_metrics_dir, exist_ok=True)\n",
    "metrics_path = os.path.join(model_metrics_dir, metrics_name)\n",
    "\n",
    "compute_metrics(agent, env, metrics_path, num_simulations=num_simulations)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -75\n"
     ]
    }
   ],
   "source": [
    "if isinstance(env, FullObsSnakeEnv):\n",
    "    env.interact = True\n",
    "else:\n",
    "    env = ParObsSnakeEnv(grid_size=2*grid_size)\n",
    "    \n",
    "state = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action, _ = agent.choose_action(state)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    print(f\"Reward: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
