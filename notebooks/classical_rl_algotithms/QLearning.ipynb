{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow to import modules from the project root directory\n",
    "import sys\n",
    "import os\n",
    "# Add the project root directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from src.ParObsSnakeEnv import ParObsSnakeEnv\n",
    "from src.FullObsSnakeEnv import FullObsSnakeEnv\n",
    "from src.utils import compute_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../artifacts/images/Qlearning.png\" alt=\"Q-learning algorithm\" width=\"1000\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, env, learning_rate=0.5, discount_factor=0.99, epsilon=0.1, learning_rate_decay=0.8, epsilon_decay=0.9):\n",
    "        self.env = env\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "        self.learning_rate_decay = learning_rate_decay\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.q_table = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "\n",
    "    def choose_action(self, state, Greedy=False):\n",
    "        state = tuple(state.flatten())\n",
    "        if Greedy:\n",
    "            return np.argmax(self.q_table[state]), None\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return self.env.action_space.sample(), None  # Explore\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state]), None  # Exploit\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        next_action = self.choose_action(next_state, Greedy=True)  # Choose next action using epsilon-greedy approach\n",
    "        next_state = tuple(next_state.flatten())\n",
    "        state = tuple(state.flatten())\n",
    "        td_target = reward + self.discount_factor * self.q_table[next_state][next_action]\n",
    "        td_error = td_target - self.q_table[state][action]\n",
    "        self.q_table[state][action] += self.learning_rate * td_error\n",
    "\n",
    "    def print_qtable(self):\n",
    "        for state, actions in self.q_table.items():\n",
    "            print(f\"State: {state}\")\n",
    "            for action, value in enumerate(actions):\n",
    "                print(f\"  Action {action}: {value:.2f}\")\n",
    "            print()\n",
    "\n",
    "    def train(self, num_episodes):\n",
    "        for episode in tqdm(range(num_episodes), desc='Training', unit='Episode'):\n",
    "            state = self.env.reset()\n",
    "            done = False\n",
    "            while not done:\n",
    "                action, _ = self.choose_action(state)\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                self.update_q_value(state, action, reward, next_state)\n",
    "                state = next_state\n",
    "            # decaying    \n",
    "            if episode % 1000 == 0 and episode != 0:\n",
    "                self.epsilon *= self.epsilon_decay  # Decay epsilon\n",
    "                self.learning_rate *= self.learning_rate_decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 10\n",
    "# env = FullObsSnakeEnv(grid_size=grid_size, interact=False)\n",
    "env = ParObsSnakeEnv(grid_size=grid_size, interact=False)\n",
    "agent = QLearningAgent(env, epsilon=0.1, discount_factor=0.9, learning_rate=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Q-table\n",
    "# with open('q_learning_agent.pkl', 'rb') as f:\n",
    "#     agent.q_table = defaultdict(lambda: np.zeros(env.action_space.n), pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/50000 [00:00<?, ?Episode/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39372/1236178289.py:31: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  self.q_table[state][action] += self.learning_rate * td_error\n",
      "Training: 100%|██████████| 50000/50000 [02:00<00:00, 413.52Episode/s]\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 50000\n",
    "agent.train(num_episodes=num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = 'full 'if isinstance(env, FullObsSnakeEnv) else 'par'\n",
    "\n",
    "table_name = f'q_learning_table_{environment}_{num_episodes}_{grid_size}.pkl'\n",
    "model_weights_dir = os.path.join('../..', 'models', 'q-learning')\n",
    "os.makedirs(model_weights_dir, exist_ok=True)\n",
    "table_path = os.path.join(model_weights_dir, table_name)\n",
    "\n",
    "with open(table_path, 'wb') as f:\n",
    "        pickle.dump(dict(agent.q_table), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [00:00<00:00, 264.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 35, Episode reward: 2952\n",
      "Snake length: 18, Episode reward: 1426\n",
      "Snake length: 29, Episode reward: 2457\n",
      "Snake length: 26, Episode reward: 2095\n",
      "Snake length: 17, Episode reward: 1287\n",
      "Snake length: 27, Episode reward: 2157\n",
      "Snake length: 11, Episode reward: 806\n",
      "Snake length: 15, Episode reward: 1176\n",
      "Snake length: 30, Episode reward: 2509\n",
      "Snake length: 29, Episode reward: 2380\n",
      "Snake length: 22, Episode reward: 1816\n",
      "Snake length: 22, Episode reward: 1811\n",
      "Snake length: 30, Episode reward: 2513\n",
      "Snake length: 28, Episode reward: 2327\n",
      "Snake length: 38, Episode reward: 3134\n",
      "Snake length: 25, Episode reward: 2065\n",
      "Snake length: 10, Episode reward: 702\n",
      "Snake length: 39, Episode reward: 3352\n",
      "Snake length: 22, Episode reward: 1846\n",
      "Snake length: 35, Episode reward: 2898\n",
      "Snake length: 24, Episode reward: 2000\n",
      "Snake length: 30, Episode reward: 2542\n",
      "Snake length: 38, Episode reward: 3246\n",
      "Snake length: 16, Episode reward: 1288\n",
      "Snake length: 29, Episode reward: 2498\n",
      "Snake length: 17, Episode reward: 1318\n",
      "Snake length: 9, Episode reward: 621\n",
      "Snake length: 34, Episode reward: 2909\n",
      "Snake length: 18, Episode reward: 1393\n",
      "Snake length: 42, Episode reward: 3607\n",
      "Snake length: 29, Episode reward: 2435\n",
      "Snake length: 45, Episode reward: 3877\n",
      "Snake length: 33, Episode reward: 2675\n",
      "Snake length: 17, Episode reward: 1323\n",
      "Snake length: 43, Episode reward: 3670\n",
      "Snake length: 20, Episode reward: 1587\n",
      "Snake length: 23, Episode reward: 1857\n",
      "Snake length: 26, Episode reward: 2115\n",
      "Snake length: 24, Episode reward: 1946\n",
      "Snake length: 32, Episode reward: 2679\n",
      "Snake length: 35, Episode reward: 2955\n",
      "Snake length: 42, Episode reward: 3568\n",
      "Snake length: 23, Episode reward: 1874\n",
      "Snake length: 29, Episode reward: 2374\n",
      "Snake length: 28, Episode reward: 2349\n",
      "Snake length: 36, Episode reward: 3036\n",
      "Snake length: 33, Episode reward: 2793\n",
      "Snake length: 25, Episode reward: 2015\n",
      "Snake length: 27, Episode reward: 2210\n",
      "Snake length: 31, Episode reward: 2552\n",
      "Snake length: 20, Episode reward: 1578\n",
      "Snake length: 24, Episode reward: 1992\n",
      "Snake length: 25, Episode reward: 2052\n",
      "Snake length: 32, Episode reward: 2653\n",
      "Snake length: 15, Episode reward: 1206\n",
      "Snake length: 33, Episode reward: 2760\n",
      "Snake length: 31, Episode reward: 2562\n",
      "Snake length: 31, Episode reward: 2581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 274.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 38, Episode reward: 3202\n",
      "Snake length: 37, Episode reward: 3128\n",
      "Snake length: 49, Episode reward: 4210\n",
      "Snake length: 16, Episode reward: 1265\n",
      "Snake length: 18, Episode reward: 1490\n",
      "Snake length: 24, Episode reward: 1934\n",
      "Snake length: 18, Episode reward: 1483\n",
      "Snake length: 43, Episode reward: 3657\n",
      "Snake length: 27, Episode reward: 2217\n",
      "Snake length: 34, Episode reward: 2838\n",
      "Snake length: 25, Episode reward: 2034\n",
      "Snake length: 20, Episode reward: 1589\n",
      "Snake length: 19, Episode reward: 1518\n",
      "Snake length: 37, Episode reward: 3133\n",
      "Snake length: 7, Episode reward: 478\n",
      "Snake length: 20, Episode reward: 1564\n",
      "Snake length: 46, Episode reward: 4009\n",
      "Snake length: 28, Episode reward: 2259\n",
      "Snake length: 25, Episode reward: 2076\n",
      "Snake length: 17, Episode reward: 1317\n",
      "Snake length: 13, Episode reward: 986\n",
      "Snake length: 15, Episode reward: 1163\n",
      "Snake length: 23, Episode reward: 1864\n",
      "Snake length: 25, Episode reward: 2055\n",
      "Snake length: 23, Episode reward: 1894\n",
      "Snake length: 14, Episode reward: 1102\n",
      "Snake length: 32, Episode reward: 2738\n",
      "Snake length: 23, Episode reward: 1861\n",
      "Snake length: 35, Episode reward: 2987\n",
      "Snake length: 26, Episode reward: 2139\n",
      "Snake length: 17, Episode reward: 1345\n",
      "Snake length: 23, Episode reward: 1890\n",
      "Snake length: 25, Episode reward: 2023\n",
      "Snake length: 4, Episode reward: 189\n",
      "Snake length: 38, Episode reward: 3189\n",
      "Snake length: 13, Episode reward: 986\n",
      "Snake length: 19, Episode reward: 1544\n",
      "Snake length: 2, Episode reward: 19\n",
      "Snake length: 31, Episode reward: 2666\n",
      "Snake length: 14, Episode reward: 1079\n",
      "Snake length: 28, Episode reward: 2250\n",
      "Snake length: 12, Episode reward: 919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'snake_lengths': [35,\n",
       "  18,\n",
       "  29,\n",
       "  26,\n",
       "  17,\n",
       "  27,\n",
       "  11,\n",
       "  15,\n",
       "  30,\n",
       "  29,\n",
       "  22,\n",
       "  22,\n",
       "  30,\n",
       "  28,\n",
       "  38,\n",
       "  25,\n",
       "  10,\n",
       "  39,\n",
       "  22,\n",
       "  35,\n",
       "  24,\n",
       "  30,\n",
       "  38,\n",
       "  16,\n",
       "  29,\n",
       "  17,\n",
       "  9,\n",
       "  34,\n",
       "  18,\n",
       "  42,\n",
       "  29,\n",
       "  45,\n",
       "  33,\n",
       "  17,\n",
       "  43,\n",
       "  20,\n",
       "  23,\n",
       "  26,\n",
       "  24,\n",
       "  32,\n",
       "  35,\n",
       "  42,\n",
       "  23,\n",
       "  29,\n",
       "  28,\n",
       "  36,\n",
       "  33,\n",
       "  25,\n",
       "  27,\n",
       "  31,\n",
       "  20,\n",
       "  24,\n",
       "  25,\n",
       "  32,\n",
       "  15,\n",
       "  33,\n",
       "  31,\n",
       "  31,\n",
       "  38,\n",
       "  37,\n",
       "  49,\n",
       "  16,\n",
       "  18,\n",
       "  24,\n",
       "  18,\n",
       "  43,\n",
       "  27,\n",
       "  34,\n",
       "  25,\n",
       "  20,\n",
       "  19,\n",
       "  37,\n",
       "  7,\n",
       "  20,\n",
       "  46,\n",
       "  28,\n",
       "  25,\n",
       "  17,\n",
       "  13,\n",
       "  15,\n",
       "  23,\n",
       "  25,\n",
       "  23,\n",
       "  14,\n",
       "  32,\n",
       "  23,\n",
       "  35,\n",
       "  26,\n",
       "  17,\n",
       "  23,\n",
       "  25,\n",
       "  4,\n",
       "  38,\n",
       "  13,\n",
       "  19,\n",
       "  2,\n",
       "  31,\n",
       "  14,\n",
       "  28,\n",
       "  12],\n",
       " 'episode_rewards': [2952,\n",
       "  1426,\n",
       "  2457,\n",
       "  2095,\n",
       "  1287,\n",
       "  2157,\n",
       "  806,\n",
       "  1176,\n",
       "  2509,\n",
       "  2380,\n",
       "  1816,\n",
       "  1811,\n",
       "  2513,\n",
       "  2327,\n",
       "  3134,\n",
       "  2065,\n",
       "  702,\n",
       "  3352,\n",
       "  1846,\n",
       "  2898,\n",
       "  2000,\n",
       "  2542,\n",
       "  3246,\n",
       "  1288,\n",
       "  2498,\n",
       "  1318,\n",
       "  621,\n",
       "  2909,\n",
       "  1393,\n",
       "  3607,\n",
       "  2435,\n",
       "  3877,\n",
       "  2675,\n",
       "  1323,\n",
       "  3670,\n",
       "  1587,\n",
       "  1857,\n",
       "  2115,\n",
       "  1946,\n",
       "  2679,\n",
       "  2955,\n",
       "  3568,\n",
       "  1874,\n",
       "  2374,\n",
       "  2349,\n",
       "  3036,\n",
       "  2793,\n",
       "  2015,\n",
       "  2210,\n",
       "  2552,\n",
       "  1578,\n",
       "  1992,\n",
       "  2052,\n",
       "  2653,\n",
       "  1206,\n",
       "  2760,\n",
       "  2562,\n",
       "  2581,\n",
       "  3202,\n",
       "  3128,\n",
       "  4210,\n",
       "  1265,\n",
       "  1490,\n",
       "  1934,\n",
       "  1483,\n",
       "  3657,\n",
       "  2217,\n",
       "  2838,\n",
       "  2034,\n",
       "  1589,\n",
       "  1518,\n",
       "  3133,\n",
       "  478,\n",
       "  1564,\n",
       "  4009,\n",
       "  2259,\n",
       "  2076,\n",
       "  1317,\n",
       "  986,\n",
       "  1163,\n",
       "  1864,\n",
       "  2055,\n",
       "  1894,\n",
       "  1102,\n",
       "  2738,\n",
       "  1861,\n",
       "  2987,\n",
       "  2139,\n",
       "  1345,\n",
       "  1890,\n",
       "  2023,\n",
       "  189,\n",
       "  3189,\n",
       "  986,\n",
       "  1544,\n",
       "  19,\n",
       "  2666,\n",
       "  1079,\n",
       "  2250,\n",
       "  919]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if isinstance(env, ParObsSnakeEnv):\n",
    "    env = ParObsSnakeEnv(grid_size=2*grid_size, interact=False)\n",
    "\n",
    "num_simulations = 100\n",
    "metrics_name = f'q_learning_metrics_{environment}_{num_episodes}_{env.grid_size}_{num_simulations}.jsn'\n",
    "model_metrics_dir = os.path.join('../..', 'artifacts', 'models_stats', 'q-learning')\n",
    "os.makedirs(model_metrics_dir, exist_ok=True)\n",
    "metrics_path = os.path.join(model_metrics_dir, metrics_name)\n",
    "\n",
    "compute_metrics(agent, env, metrics_path, num_simulations=num_simulations)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: -75\n"
     ]
    }
   ],
   "source": [
    "if isinstance(env, FullObsSnakeEnv):\n",
    "    env.interact = True\n",
    "else:\n",
    "    env = ParObsSnakeEnv(grid_size=2*grid_size)\n",
    "    \n",
    "state = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action, _ = agent.choose_action(state)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    print(f\"Reward: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
