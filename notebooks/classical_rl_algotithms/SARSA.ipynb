{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "# allow to import modules from the project root directory\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
    "\n",
    "from src.ParObsSnakeEnv import ParObsSnakeEnv\n",
    "from src.FullObsSnakeEnv import FullObsSnakeEnv\n",
    "from src.utils import compute_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../artifacts/images/SARSA.png\" alt=\"SARSA algorithm\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SarsaAgent:\n",
    "    def __init__(self, env, learning_rate=0.5, discount_factor=0.99, epsilon=0.1, learning_rate_decay=0.8, epsilon_decay=0.9):\n",
    "        self.env = env\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "        self.learning_rate_decay = learning_rate_decay\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.q_table = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        state = tuple(state.flatten())\n",
    "        if random.uniform(0, 1) < self.epsilon:\n",
    "            return self.env.action_space.sample(), None  # Explore\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state]), None  # Exploit\n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state, next_action):\n",
    "        next_state = tuple(next_state.flatten())\n",
    "        state = tuple(state.flatten())\n",
    "        td_target = reward + self.discount_factor * self.q_table[next_state][next_action]\n",
    "        td_error = td_target - self.q_table[state][action]\n",
    "        self.q_table[state][action] += self.learning_rate * td_error\n",
    "\n",
    "    def train(self, num_episodes):\n",
    "        for episode in tqdm(range(num_episodes), desc='Training', unit='Episode'):\n",
    "            state = self.env.reset()\n",
    "            action = self.choose_action(state)\n",
    "            done = False\n",
    "            while not done:\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                next_action, _ = self.choose_action(next_state)\n",
    "                self.update_q_value(state, action, reward, next_state, next_action)\n",
    "                state = next_state\n",
    "                action = next_action\n",
    "            # Decaying    \n",
    "            if episode % 1000 == 0 and episode != 0:\n",
    "                self.epsilon *= self.epsilon_decay  # Decay epsilon\n",
    "                self.learning_rate *= self.learning_rate_decay\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 10\n",
    "# env = FullObsSnakeEnv(grid_size=grid_size, interact=False)\n",
    "env = ParObsSnakeEnv(grid_size=grid_size, interact=False)\n",
    "agent = SarsaAgent(env, epsilon=0.1, discount_factor=0.9, learning_rate=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50000/50000 [01:08<00:00, 732.91Episode/s]\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 50000\n",
    "agent.train(num_episodes=num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = 'full 'if isinstance(env, FullObsSnakeEnv) else 'par'\n",
    "\n",
    "table_name = f'sarsa_table_{environment}_{num_episodes}_{grid_size}.pkl'\n",
    "model_weights_dir = os.path.join('../..', 'models', 'sarsa')\n",
    "os.makedirs(model_weights_dir, exist_ok=True)\n",
    "table_path = os.path.join(model_weights_dir, table_name)\n",
    "\n",
    "with open(table_path, 'wb') as f:\n",
    "        pickle.dump(dict(agent.q_table), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [00:00<00:00, 254.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 25, Episode reward: 1992\n",
      "Snake length: 27, Episode reward: 2253\n",
      "Snake length: 26, Episode reward: 2160\n",
      "Snake length: 20, Episode reward: 1609\n",
      "Snake length: 35, Episode reward: 2943\n",
      "Snake length: 30, Episode reward: 2499\n",
      "Snake length: 26, Episode reward: 2204\n",
      "Snake length: 30, Episode reward: 2475\n",
      "Snake length: 16, Episode reward: 1249\n",
      "Snake length: 28, Episode reward: 2361\n",
      "Snake length: 33, Episode reward: 2777\n",
      "Snake length: 22, Episode reward: 1755\n",
      "Snake length: 20, Episode reward: 1589\n",
      "Snake length: 44, Episode reward: 3774\n",
      "Snake length: 40, Episode reward: 3312\n",
      "Snake length: 28, Episode reward: 2298\n",
      "Snake length: 28, Episode reward: 2323\n",
      "Snake length: 14, Episode reward: 1065\n",
      "Snake length: 18, Episode reward: 1401\n",
      "Snake length: 10, Episode reward: 707\n",
      "Snake length: 23, Episode reward: 1809\n",
      "Snake length: 17, Episode reward: 1316\n",
      "Snake length: 24, Episode reward: 1958\n",
      "Snake length: 34, Episode reward: 2779\n",
      "Snake length: 43, Episode reward: 3729\n",
      "Snake length: 25, Episode reward: 2028\n",
      "Snake length: 14, Episode reward: 1025\n",
      "Snake length: 8, Episode reward: 515\n",
      "Snake length: 17, Episode reward: 1326\n",
      "Snake length: 29, Episode reward: 2422\n",
      "Snake length: 35, Episode reward: 2975\n",
      "Snake length: 38, Episode reward: 3236\n",
      "Snake length: 21, Episode reward: 1687\n",
      "Snake length: 25, Episode reward: 2038\n",
      "Snake length: 47, Episode reward: 4072\n",
      "Snake length: 38, Episode reward: 3100\n",
      "Snake length: 27, Episode reward: 2189\n",
      "Snake length: 21, Episode reward: 1705\n",
      "Snake length: 12, Episode reward: 895\n",
      "Snake length: 24, Episode reward: 1948\n",
      "Snake length: 17, Episode reward: 1334\n",
      "Snake length: 26, Episode reward: 2143\n",
      "Snake length: 32, Episode reward: 2606\n",
      "Snake length: 28, Episode reward: 2323\n",
      "Snake length: 43, Episode reward: 3601\n",
      "Snake length: 20, Episode reward: 1589\n",
      "Snake length: 18, Episode reward: 1417\n",
      "Snake length: 30, Episode reward: 2560\n",
      "Snake length: 35, Episode reward: 2938\n",
      "Snake length: 32, Episode reward: 2604\n",
      "Snake length: 34, Episode reward: 2835\n",
      "Snake length: 27, Episode reward: 2193\n",
      "Snake length: 20, Episode reward: 1644\n",
      "Snake length: 16, Episode reward: 1258\n",
      "Snake length: 20, Episode reward: 1584\n",
      "Snake length: 15, Episode reward: 1123\n",
      "Snake length: 36, Episode reward: 3005\n",
      "Snake length: 12, Episode reward: 943\n",
      "Snake length: 24, Episode reward: 2016\n",
      "Snake length: 42, Episode reward: 3586\n",
      "Snake length: 35, Episode reward: 2952\n",
      "Snake length: 16, Episode reward: 1219\n",
      "Snake length: 23, Episode reward: 1883\n",
      "Snake length: 31, Episode reward: 2604\n",
      "Snake length: 17, Episode reward: 1313\n",
      "Snake length: 18, Episode reward: 1453\n",
      "Snake length: 44, Episode reward: 3691\n",
      "Snake length: 47, Episode reward: 4000\n",
      "Snake length: 17, Episode reward: 1331\n",
      "Snake length: 35, Episode reward: 2918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 267.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 19, Episode reward: 1500\n",
      "Snake length: 30, Episode reward: 2477\n",
      "Snake length: 33, Episode reward: 2758\n",
      "Snake length: 23, Episode reward: 1845\n",
      "Snake length: 21, Episode reward: 1698\n",
      "Snake length: 24, Episode reward: 1952\n",
      "Snake length: 35, Episode reward: 2845\n",
      "Snake length: 39, Episode reward: 3285\n",
      "Snake length: 41, Episode reward: 3485\n",
      "Snake length: 21, Episode reward: 1743\n",
      "Snake length: 40, Episode reward: 3395\n",
      "Snake length: 27, Episode reward: 2210\n",
      "Snake length: 11, Episode reward: 806\n",
      "Snake length: 46, Episode reward: 3984\n",
      "Snake length: 18, Episode reward: 1435\n",
      "Snake length: 26, Episode reward: 2153\n",
      "Snake length: 17, Episode reward: 1348\n",
      "Snake length: 24, Episode reward: 1963\n",
      "Snake length: 25, Episode reward: 2031\n",
      "Snake length: 20, Episode reward: 1579\n",
      "Snake length: 37, Episode reward: 3158\n",
      "Snake length: 22, Episode reward: 1790\n",
      "Snake length: 24, Episode reward: 1948\n",
      "Snake length: 32, Episode reward: 2645\n",
      "Snake length: 35, Episode reward: 2967\n",
      "Snake length: 11, Episode reward: 803\n",
      "Snake length: 39, Episode reward: 3283\n",
      "Snake length: 18, Episode reward: 1428\n",
      "Snake length: 18, Episode reward: 1425\n",
      "Snake length: 20, Episode reward: 1564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'snake_lengths': [25,\n",
       "  27,\n",
       "  26,\n",
       "  20,\n",
       "  35,\n",
       "  30,\n",
       "  26,\n",
       "  30,\n",
       "  16,\n",
       "  28,\n",
       "  33,\n",
       "  22,\n",
       "  20,\n",
       "  44,\n",
       "  40,\n",
       "  28,\n",
       "  28,\n",
       "  14,\n",
       "  18,\n",
       "  10,\n",
       "  23,\n",
       "  17,\n",
       "  24,\n",
       "  34,\n",
       "  43,\n",
       "  25,\n",
       "  14,\n",
       "  8,\n",
       "  17,\n",
       "  29,\n",
       "  35,\n",
       "  38,\n",
       "  21,\n",
       "  25,\n",
       "  47,\n",
       "  38,\n",
       "  27,\n",
       "  21,\n",
       "  12,\n",
       "  24,\n",
       "  17,\n",
       "  26,\n",
       "  32,\n",
       "  28,\n",
       "  43,\n",
       "  20,\n",
       "  18,\n",
       "  30,\n",
       "  35,\n",
       "  32,\n",
       "  34,\n",
       "  27,\n",
       "  20,\n",
       "  16,\n",
       "  20,\n",
       "  15,\n",
       "  36,\n",
       "  12,\n",
       "  24,\n",
       "  42,\n",
       "  35,\n",
       "  16,\n",
       "  23,\n",
       "  31,\n",
       "  17,\n",
       "  18,\n",
       "  44,\n",
       "  47,\n",
       "  17,\n",
       "  35,\n",
       "  19,\n",
       "  30,\n",
       "  33,\n",
       "  23,\n",
       "  21,\n",
       "  24,\n",
       "  35,\n",
       "  39,\n",
       "  41,\n",
       "  21,\n",
       "  40,\n",
       "  27,\n",
       "  11,\n",
       "  46,\n",
       "  18,\n",
       "  26,\n",
       "  17,\n",
       "  24,\n",
       "  25,\n",
       "  20,\n",
       "  37,\n",
       "  22,\n",
       "  24,\n",
       "  32,\n",
       "  35,\n",
       "  11,\n",
       "  39,\n",
       "  18,\n",
       "  18,\n",
       "  20],\n",
       " 'episode_rewards': [1992,\n",
       "  2253,\n",
       "  2160,\n",
       "  1609,\n",
       "  2943,\n",
       "  2499,\n",
       "  2204,\n",
       "  2475,\n",
       "  1249,\n",
       "  2361,\n",
       "  2777,\n",
       "  1755,\n",
       "  1589,\n",
       "  3774,\n",
       "  3312,\n",
       "  2298,\n",
       "  2323,\n",
       "  1065,\n",
       "  1401,\n",
       "  707,\n",
       "  1809,\n",
       "  1316,\n",
       "  1958,\n",
       "  2779,\n",
       "  3729,\n",
       "  2028,\n",
       "  1025,\n",
       "  515,\n",
       "  1326,\n",
       "  2422,\n",
       "  2975,\n",
       "  3236,\n",
       "  1687,\n",
       "  2038,\n",
       "  4072,\n",
       "  3100,\n",
       "  2189,\n",
       "  1705,\n",
       "  895,\n",
       "  1948,\n",
       "  1334,\n",
       "  2143,\n",
       "  2606,\n",
       "  2323,\n",
       "  3601,\n",
       "  1589,\n",
       "  1417,\n",
       "  2560,\n",
       "  2938,\n",
       "  2604,\n",
       "  2835,\n",
       "  2193,\n",
       "  1644,\n",
       "  1258,\n",
       "  1584,\n",
       "  1123,\n",
       "  3005,\n",
       "  943,\n",
       "  2016,\n",
       "  3586,\n",
       "  2952,\n",
       "  1219,\n",
       "  1883,\n",
       "  2604,\n",
       "  1313,\n",
       "  1453,\n",
       "  3691,\n",
       "  4000,\n",
       "  1331,\n",
       "  2918,\n",
       "  1500,\n",
       "  2477,\n",
       "  2758,\n",
       "  1845,\n",
       "  1698,\n",
       "  1952,\n",
       "  2845,\n",
       "  3285,\n",
       "  3485,\n",
       "  1743,\n",
       "  3395,\n",
       "  2210,\n",
       "  806,\n",
       "  3984,\n",
       "  1435,\n",
       "  2153,\n",
       "  1348,\n",
       "  1963,\n",
       "  2031,\n",
       "  1579,\n",
       "  3158,\n",
       "  1790,\n",
       "  1948,\n",
       "  2645,\n",
       "  2967,\n",
       "  803,\n",
       "  3283,\n",
       "  1428,\n",
       "  1425,\n",
       "  1564]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if isinstance(env, ParObsSnakeEnv):\n",
    "    env = ParObsSnakeEnv(grid_size=2*grid_size, interact=False)\n",
    "\n",
    "num_simulations = 100\n",
    "metrics_name = f'sarsa_metrics_{environment}_{num_episodes}_{env.grid_size}_{num_simulations}.jsn'\n",
    "model_metrics_dir = os.path.join('../..', 'artifacts', 'models_stats', 'sarsa')\n",
    "os.makedirs(model_metrics_dir, exist_ok=True)\n",
    "metrics_path = os.path.join(model_metrics_dir, metrics_name)\n",
    "\n",
    "compute_metrics(agent, env, metrics_path, num_simulations=num_simulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -75\n"
     ]
    }
   ],
   "source": [
    "if isinstance(env, FullObsSnakeEnv):\n",
    "    env.interact = True\n",
    "else:\n",
    "    env = ParObsSnakeEnv(grid_size=2*grid_size)\n",
    "    \n",
    "state = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action, _ = agent.choose_action(state)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    print(f\"Reward: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
