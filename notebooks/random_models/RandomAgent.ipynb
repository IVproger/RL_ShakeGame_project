{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "# Add the project root directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
    "import random\n",
    "\n",
    "from src.ParObsSnakeEnv import ParObsSnakeEnv\n",
    "from src.FullObsSnakeEnv import FullObsSnakeEnv\n",
    "from src.utils import compute_metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    def __init__(self, action_dim):\n",
    "        self.action_dim = action_dim\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        \"\"\"Randomly choose an action.\"\"\"\n",
    "        return random.randint(0, self.action_dim - 1), None\n",
    "\n",
    "    def train(self, env, episodes=1000, save_plots=False, plots_path='random_training_plots.png'):\n",
    "        self.episode_rewards = []\n",
    "\n",
    "        for episode in tqdm(range(episodes), desc=\"Training\", unit=\"episode\"):\n",
    "            state = env.reset()\n",
    "            total_reward = 0\n",
    "            done = False\n",
    "\n",
    "            while not done:\n",
    "                action, _ = self.choose_action(state)\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                total_reward += reward\n",
    "                state = next_state\n",
    "\n",
    "            self.episode_rewards.append(total_reward)\n",
    "\n",
    "        if save_plots:\n",
    "            self.save_plots(self.episode_rewards, plots_path)\n",
    "\n",
    "    def save_plots(self, plots_path):\n",
    "        \"\"\"Save the rewards plot for the random agent.\"\"\"\n",
    "        plots_dir = os.path.dirname(plots_path)\n",
    "        os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "        plt.plot(self.episode_rewards)\n",
    "        plt.title(\"Episode Rewards\")\n",
    "        plt.xlabel(\"Episode\")\n",
    "        plt.ylabel(\"Total Reward\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plots_path)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 10\n",
    "# env = FullObsSnakeEnv(grid_size=grid_size, interact=False)\n",
    "env = ParObsSnakeEnv(grid_size=grid_size, interact=False)\n",
    "if isinstance(env, FullObsSnakeEnv):\n",
    "    state_dim = env.observation_space.shape[0] * env.observation_space.shape[1] * env.observation_space.shape[2]\n",
    "else:\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "\n",
    "action_dim = env.action_space.n\n",
    "agent = RandomAgent(action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/10000 [00:00<?, ?episode/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10000/10000 [00:00<00:00, 17128.08episode/s]\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 10000\n",
    "agent.train(env, episodes=num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = 'full 'if isinstance(env, FullObsSnakeEnv) else 'par'\n",
    "\n",
    "agent_name = f'random_agent_{environment}_{num_episodes}_{grid_size}.pkl'\n",
    "model_weights_dir = os.path.join('../..', 'models', 'random')\n",
    "os.makedirs(model_weights_dir, exist_ok=True)\n",
    "agent_path = os.path.join(model_weights_dir, agent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 4440.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 1, Episode reward: -72\n",
      "Snake length: 1, Episode reward: -76\n",
      "Snake length: 1, Episode reward: -72\n",
      "Snake length: 1, Episode reward: -78\n",
      "Snake length: 1, Episode reward: -82\n",
      "Snake length: 1, Episode reward: -72\n",
      "Snake length: 1, Episode reward: -73\n",
      "Snake length: 1, Episode reward: -77\n",
      "Snake length: 1, Episode reward: -85\n",
      "Snake length: 1, Episode reward: -75\n",
      "Snake length: 1, Episode reward: -80\n",
      "Snake length: 1, Episode reward: -75\n",
      "Snake length: 1, Episode reward: -78\n",
      "Snake length: 1, Episode reward: -78\n",
      "Snake length: 1, Episode reward: -72\n",
      "Snake length: 1, Episode reward: -82\n",
      "Snake length: 1, Episode reward: -74\n",
      "Snake length: 1, Episode reward: -82\n",
      "Snake length: 1, Episode reward: -75\n",
      "Snake length: 1, Episode reward: -75\n",
      "Snake length: 1, Episode reward: -65\n",
      "Snake length: 1, Episode reward: -75\n",
      "Snake length: 1, Episode reward: -81\n",
      "Snake length: 1, Episode reward: -74\n",
      "Snake length: 3, Episode reward: 77\n",
      "Snake length: 2, Episode reward: 10\n",
      "Snake length: 1, Episode reward: -62\n",
      "Snake length: 1, Episode reward: -68\n",
      "Snake length: 1, Episode reward: -75\n",
      "Snake length: 1, Episode reward: -81\n",
      "Snake length: 1, Episode reward: -72\n",
      "Snake length: 1, Episode reward: -79\n",
      "Snake length: 1, Episode reward: -77\n",
      "Snake length: 2, Episode reward: 13\n",
      "Snake length: 1, Episode reward: -87\n",
      "Snake length: 1, Episode reward: -81\n",
      "Snake length: 1, Episode reward: -83\n",
      "Snake length: 1, Episode reward: -76\n",
      "Snake length: 1, Episode reward: -82\n",
      "Snake length: 1, Episode reward: -92\n",
      "Snake length: 2, Episode reward: 7\n",
      "Snake length: 1, Episode reward: -75\n",
      "Snake length: 1, Episode reward: -64\n",
      "Snake length: 1, Episode reward: -77\n",
      "Snake length: 1, Episode reward: -80\n",
      "Snake length: 1, Episode reward: -100\n",
      "Snake length: 1, Episode reward: -74\n",
      "Snake length: 1, Episode reward: -64\n",
      "Snake length: 1, Episode reward: -78\n",
      "Snake length: 1, Episode reward: -63\n",
      "Snake length: 1, Episode reward: -75\n",
      "Snake length: 1, Episode reward: -75\n",
      "Snake length: 1, Episode reward: -76\n",
      "Snake length: 1, Episode reward: -87\n",
      "Snake length: 1, Episode reward: -78\n",
      "Snake length: 1, Episode reward: -74\n",
      "Snake length: 1, Episode reward: -77\n",
      "Snake length: 1, Episode reward: -80\n",
      "Snake length: 1, Episode reward: -76\n",
      "Snake length: 1, Episode reward: -73\n",
      "Snake length: 1, Episode reward: -90\n",
      "Snake length: 1, Episode reward: -74\n",
      "Snake length: 1, Episode reward: -75\n",
      "Snake length: 1, Episode reward: -74\n",
      "Snake length: 1, Episode reward: -89\n",
      "Snake length: 1, Episode reward: -66\n",
      "Snake length: 1, Episode reward: -72\n",
      "Snake length: 1, Episode reward: -81\n",
      "Snake length: 1, Episode reward: -89\n",
      "Snake length: 1, Episode reward: -82\n",
      "Snake length: 1, Episode reward: -76\n",
      "Snake length: 1, Episode reward: -82\n",
      "Snake length: 1, Episode reward: -66\n",
      "Snake length: 1, Episode reward: -77\n",
      "Snake length: 1, Episode reward: -63\n",
      "Snake length: 1, Episode reward: -74\n",
      "Snake length: 1, Episode reward: -90\n",
      "Snake length: 1, Episode reward: -80\n",
      "Snake length: 1, Episode reward: -75\n",
      "Snake length: 1, Episode reward: -77\n",
      "Snake length: 1, Episode reward: -80\n",
      "Snake length: 1, Episode reward: -88\n",
      "Snake length: 1, Episode reward: -76\n",
      "Snake length: 1, Episode reward: -81\n",
      "Snake length: 1, Episode reward: -81\n",
      "Snake length: 1, Episode reward: -87\n",
      "Snake length: 1, Episode reward: -79\n",
      "Snake length: 1, Episode reward: -76\n",
      "Snake length: 1, Episode reward: -76\n",
      "Snake length: 1, Episode reward: -71\n",
      "Snake length: 1, Episode reward: -81\n",
      "Snake length: 1, Episode reward: -85\n",
      "Snake length: 1, Episode reward: -81\n",
      "Snake length: 1, Episode reward: -81\n",
      "Snake length: 1, Episode reward: -82\n",
      "Snake length: 1, Episode reward: -76\n",
      "Snake length: 1, Episode reward: -76\n",
      "Snake length: 1, Episode reward: -75\n",
      "Snake length: 1, Episode reward: -78\n",
      "Snake length: 2, Episode reward: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'snake_lengths': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2],\n",
       " 'episode_rewards': [-72,\n",
       "  -76,\n",
       "  -72,\n",
       "  -78,\n",
       "  -82,\n",
       "  -72,\n",
       "  -73,\n",
       "  -77,\n",
       "  -85,\n",
       "  -75,\n",
       "  -80,\n",
       "  -75,\n",
       "  -78,\n",
       "  -78,\n",
       "  -72,\n",
       "  -82,\n",
       "  -74,\n",
       "  -82,\n",
       "  -75,\n",
       "  -75,\n",
       "  -65,\n",
       "  -75,\n",
       "  -81,\n",
       "  -74,\n",
       "  77,\n",
       "  10,\n",
       "  -62,\n",
       "  -68,\n",
       "  -75,\n",
       "  -81,\n",
       "  -72,\n",
       "  -79,\n",
       "  -77,\n",
       "  13,\n",
       "  -87,\n",
       "  -81,\n",
       "  -83,\n",
       "  -76,\n",
       "  -82,\n",
       "  -92,\n",
       "  7,\n",
       "  -75,\n",
       "  -64,\n",
       "  -77,\n",
       "  -80,\n",
       "  -100,\n",
       "  -74,\n",
       "  -64,\n",
       "  -78,\n",
       "  -63,\n",
       "  -75,\n",
       "  -75,\n",
       "  -76,\n",
       "  -87,\n",
       "  -78,\n",
       "  -74,\n",
       "  -77,\n",
       "  -80,\n",
       "  -76,\n",
       "  -73,\n",
       "  -90,\n",
       "  -74,\n",
       "  -75,\n",
       "  -74,\n",
       "  -89,\n",
       "  -66,\n",
       "  -72,\n",
       "  -81,\n",
       "  -89,\n",
       "  -82,\n",
       "  -76,\n",
       "  -82,\n",
       "  -66,\n",
       "  -77,\n",
       "  -63,\n",
       "  -74,\n",
       "  -90,\n",
       "  -80,\n",
       "  -75,\n",
       "  -77,\n",
       "  -80,\n",
       "  -88,\n",
       "  -76,\n",
       "  -81,\n",
       "  -81,\n",
       "  -87,\n",
       "  -79,\n",
       "  -76,\n",
       "  -76,\n",
       "  -71,\n",
       "  -81,\n",
       "  -85,\n",
       "  -81,\n",
       "  -81,\n",
       "  -82,\n",
       "  -76,\n",
       "  -76,\n",
       "  -75,\n",
       "  -78,\n",
       "  14]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if isinstance(env, ParObsSnakeEnv):\n",
    "    env = ParObsSnakeEnv(grid_size=2*grid_size, interact=False)\n",
    "\n",
    "model_metrics_dir = os.path.join('../..', 'artifacts', 'models_stats', 'random')\n",
    "os.makedirs(model_metrics_dir, exist_ok=True)\n",
    "\n",
    "train_metrics_name = f'random_train_metrics_{environment}_{num_episodes}_{grid_size}.png'\n",
    "train_metrics_path = os.path.join(model_metrics_dir, train_metrics_name)\n",
    "agent.save_plots(train_metrics_path)\n",
    "\n",
    "num_simulations = 100\n",
    "sim_metrics_name = f'random_sim_metrics_{environment}_{num_episodes}_{env.grid_size}_{num_simulations}.json'\n",
    "sim_metrics_path = os.path.join(model_metrics_dir, sim_metrics_name)\n",
    "compute_metrics(agent, env, sim_metrics_path, num_simulations=num_simulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -75\n"
     ]
    }
   ],
   "source": [
    "if isinstance(env, FullObsSnakeEnv):\n",
    "    env.interact = True\n",
    "else:\n",
    "    env = ParObsSnakeEnv(grid_size=2*grid_size)\n",
    "    \n",
    "state = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action, _ = agent.choose_action(state)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    print(f\"Reward: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
