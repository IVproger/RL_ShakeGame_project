{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# Add the project root directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
    "\n",
    "from src.ParObsSnakeEnv import ParObsSnakeEnv\n",
    "from src.FullObsSnakeEnv import FullObsSnakeEnv\n",
    "from src.utils import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=128):\n",
    "        super(DQN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.fc1 = nn.Linear(input_dim, self.hidden_dim)\n",
    "        self.fc2 = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.fc3 = nn.Linear(self.hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DQN agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_dim, action_dim, lr=0.001, gamma=0.99, epsilon=1.0, epsilon_decay=0.995, epsilon_min=0.01, memory_size=10000, batch_size=64):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.memory = deque(maxlen=memory_size)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = DQN(state_dim, action_dim).to(self.device)\n",
    "        self.target_model = DQN(state_dim, action_dim).to(self.device)\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.randint(0, self.action_dim - 1), None\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
    "        state = state.reshape((1, -1))\n",
    "        with torch.no_grad():\n",
    "            # print(\">>>>\", state.shape)\n",
    "            q_values = self.model(state)\n",
    "        return torch.argmax(q_values).item(), None\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        batch = random.sample(self.memory, self.batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "        states = torch.FloatTensor(states).to(self.device)\n",
    "        actions = torch.LongTensor(actions).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).to(self.device)\n",
    "        next_states = torch.FloatTensor(next_states).to(self.device)\n",
    "        dones = torch.FloatTensor(dones).to(self.device)\n",
    "\n",
    "        states = states.reshape((self.batch_size, -1))\n",
    "        next_states = next_states.reshape((self.batch_size, -1))\n",
    "\n",
    "        # Compute current Q-values\n",
    "        q_values = self.model(states)\n",
    "        q_values = q_values.gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        # Compute target Q-values\n",
    "        next_q_values = self.target_model(next_states).max(1)[0]\n",
    "        target_q_values = rewards + (1 - dones) * self.gamma * next_q_values\n",
    "\n",
    "        # Update the Q-network\n",
    "        loss = self.criterion(q_values, target_q_values)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Decay epsilon\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\"Saves the entire agent to a file.\"\"\"\n",
    "        state = {\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'target_model_state_dict': self.target_model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'hyperparameters': {\n",
    "                'state_dim': self.state_dim,\n",
    "                'action_dim': self.action_dim,\n",
    "                'gamma': self.gamma,\n",
    "                'epsilon': self.epsilon,\n",
    "                'epsilon_decay': self.epsilon_decay,\n",
    "                'epsilon_min': self.epsilon_min,\n",
    "                'batch_size': self.batch_size,\n",
    "            },\n",
    "            'memory': list(self.memory),  # Convert deque to list\n",
    "        }\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(state, f)\n",
    "        print(f\"Agent saved to {filename}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, filename, lr=0.001):\n",
    "        \"\"\"Loads the agent from a file.\"\"\"\n",
    "        with open(filename, 'rb') as f:\n",
    "            state = pickle.load(f)\n",
    "        \n",
    "        # Recreate the agent\n",
    "        agent = cls(\n",
    "            state['hyperparameters']['state_dim'],\n",
    "            state['hyperparameters']['action_dim'],\n",
    "            lr=lr,\n",
    "            gamma=state['hyperparameters']['gamma'],\n",
    "            epsilon=state['hyperparameters']['epsilon'],\n",
    "            epsilon_decay=state['hyperparameters']['epsilon_decay'],\n",
    "            epsilon_min=state['hyperparameters']['epsilon_min'],\n",
    "            batch_size=state['hyperparameters']['batch_size'],\n",
    "        )\n",
    "        # Restore the agent's state\n",
    "        agent.model.load_state_dict(state['model_state_dict'])\n",
    "        agent.target_model.load_state_dict(state['target_model_state_dict'])\n",
    "        agent.optimizer.load_state_dict(state['optimizer_state_dict'])\n",
    "        agent.memory = deque(state['memory'], maxlen=len(state['memory']))\n",
    "        print(f\"Agent loaded from {filename}\")\n",
    "        return agent\n",
    "\n",
    "    # Train the agent\n",
    "    def train(self, env, episodes=1000, update_target_every=10):\n",
    "        for episode in tqdm(range(episodes), desc=\"Training\", unit='episode'):\n",
    "            state = env.reset()\n",
    "            total_reward = 0\n",
    "            done = False\n",
    "\n",
    "            while not done:\n",
    "                action, _ = self.choose_action(state)\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                self.remember(state, action, reward, next_state, done)\n",
    "                self.replay()\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "\n",
    "            \n",
    "            # print(f\"Episode {episode + 1}/{episodes}, Total Reward: {total_reward}, Epsilon: {agent.epsilon:.3f}\")\n",
    "\n",
    "            # if (episode + 1) % update_target_every == 0:\n",
    "                self.update_target_model()\n",
    "            #     print(\"Updated target model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 10\n",
    "# env = FullObsSnakeEnv(grid_size=grid_size, interact=False)\n",
    "env = ParObsSnakeEnv(grid_size=grid_size, interact=False)\n",
    "if isinstance(env, FullObsSnakeEnv):\n",
    "    state_dim = env.observation_space.shape[0] * env.observation_space.shape[1] * env.observation_space.shape[2]\n",
    "else:\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "\n",
    "action_dim = env.action_space.n\n",
    "agent = DQNAgent(state_dim, action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 300/300 [01:17<00:00,  3.88episode/s]\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 300\n",
    "agent.train(env, episodes=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent saved to ../../models/dqn/dqn_agent_par_300_10.pkl\n"
     ]
    }
   ],
   "source": [
    "environment = 'full 'if isinstance(env, FullObsSnakeEnv) else 'par'\n",
    "\n",
    "agent_name = f'dqn_agent_{environment}_{num_episodes}_{grid_size}.pkl'\n",
    "model_weights_dir = os.path.join('../..', 'models', 'dqn')\n",
    "os.makedirs(model_weights_dir, exist_ok=True)\n",
    "agent_path = os.path.join(model_weights_dir, agent_name)\n",
    "\n",
    "agent.save(agent_path)\n",
    "# agent = DQNAgent.load(agent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<00:12,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 39, Episode reward: 3272\n",
      "Snake length: 9, Episode reward: 595\n",
      "Snake length: 17, Episode reward: 1292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:00<00:06, 15.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 33, Episode reward: 2728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:00<00:06, 14.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 27, Episode reward: 2241\n",
      "Snake length: 20, Episode reward: 1575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:00<00:08, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 46, Episode reward: 3930\n",
      "Snake length: 23, Episode reward: 1927\n",
      "Snake length: 32, Episode reward: 2643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:00<00:08, 11.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 28, Episode reward: 2349\n",
      "Snake length: 33, Episode reward: 2756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:01<00:09,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 36, Episode reward: 3046\n",
      "Snake length: 43, Episode reward: 3669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:01<00:10,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 35, Episode reward: 2947\n",
      "Snake length: 42, Episode reward: 3652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:01<00:08,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 29, Episode reward: 2403\n",
      "Snake length: 32, Episode reward: 2615\n",
      "Snake length: 28, Episode reward: 2252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [00:02<00:06, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 36, Episode reward: 3007\n",
      "Snake length: 14, Episode reward: 1079\n",
      "Snake length: 5, Episode reward: 298\n",
      "Snake length: 27, Episode reward: 2244\n",
      "Snake length: 17, Episode reward: 1352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [00:02<00:05, 14.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 12, Episode reward: 885\n",
      "Snake length: 25, Episode reward: 2024\n",
      "Snake length: 27, Episode reward: 2223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [00:02<00:04, 14.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 18, Episode reward: 1411\n",
      "Snake length: 22, Episode reward: 1809\n",
      "Snake length: 24, Episode reward: 1922\n",
      "Snake length: 18, Episode reward: 1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [00:02<00:04, 15.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 28, Episode reward: 2392\n",
      "Snake length: 29, Episode reward: 2344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [00:02<00:05, 12.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 48, Episode reward: 4107\n",
      "Snake length: 36, Episode reward: 3147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [00:03<00:05, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 24, Episode reward: 1973\n",
      "Snake length: 15, Episode reward: 1146\n",
      "Snake length: 13, Episode reward: 1002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [00:03<00:05, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 36, Episode reward: 3025\n",
      "Snake length: 51, Episode reward: 4333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [00:03<00:05, 11.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 24, Episode reward: 1882\n",
      "Snake length: 33, Episode reward: 2814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [00:03<00:05, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 35, Episode reward: 2904\n",
      "Snake length: 25, Episode reward: 2065\n",
      "Snake length: 38, Episode reward: 3170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [00:04<00:05, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 24, Episode reward: 1938\n",
      "Snake length: 39, Episode reward: 3317\n",
      "Snake length: 19, Episode reward: 1521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [00:04<00:04, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 27, Episode reward: 2239\n",
      "Snake length: 32, Episode reward: 2683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [00:04<00:04, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 38, Episode reward: 3174\n",
      "Snake length: 39, Episode reward: 3315\n",
      "Snake length: 23, Episode reward: 1847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [00:04<00:04, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 23, Episode reward: 1867\n",
      "Snake length: 42, Episode reward: 3516\n",
      "Snake length: 15, Episode reward: 1104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [00:04<00:04, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 48, Episode reward: 4053\n",
      "Snake length: 12, Episode reward: 862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [00:05<00:03, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 55, Episode reward: 4715\n",
      "Snake length: 20, Episode reward: 1539\n",
      "Snake length: 39, Episode reward: 3282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [00:05<00:03,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 48, Episode reward: 4159\n",
      "Snake length: 27, Episode reward: 2212\n",
      "Snake length: 32, Episode reward: 2631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [00:05<00:03, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 32, Episode reward: 2670\n",
      "Snake length: 22, Episode reward: 1775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [00:06<00:03, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 46, Episode reward: 3882\n",
      "Snake length: 29, Episode reward: 2382\n",
      "Snake length: 21, Episode reward: 1744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [00:06<00:02, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 29, Episode reward: 2431\n",
      "Snake length: 26, Episode reward: 2159\n",
      "Snake length: 22, Episode reward: 1837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [00:06<00:02, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 29, Episode reward: 2402\n",
      "Snake length: 33, Episode reward: 2783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [00:06<00:02, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 34, Episode reward: 2805\n",
      "Snake length: 34, Episode reward: 2840\n",
      "Snake length: 24, Episode reward: 1929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [00:07<00:02, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 42, Episode reward: 3542\n",
      "Snake length: 33, Episode reward: 2708\n",
      "Snake length: 25, Episode reward: 2065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [00:07<00:01, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 27, Episode reward: 2252\n",
      "Snake length: 9, Episode reward: 648\n",
      "Snake length: 42, Episode reward: 3508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [00:07<00:01,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 52, Episode reward: 4471\n",
      "Snake length: 40, Episode reward: 3389\n",
      "Snake length: 26, Episode reward: 2093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [00:08<00:01, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 34, Episode reward: 2868\n",
      "Snake length: 6, Episode reward: 402\n",
      "Snake length: 35, Episode reward: 2960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [00:08<00:00, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 19, Episode reward: 1554\n",
      "Snake length: 42, Episode reward: 3598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [00:08<00:00,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 37, Episode reward: 3157\n",
      "Snake length: 40, Episode reward: 3433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [00:08<00:00,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 16, Episode reward: 1232\n",
      "Snake length: 38, Episode reward: 3181\n",
      "Snake length: 15, Episode reward: 1163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [00:09<00:00, 12.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 41, Episode reward: 3436\n",
      "Snake length: 16, Episode reward: 1220\n",
      "Snake length: 16, Episode reward: 1276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snake length: 34, Episode reward: 2846\n",
      "Snake length: 11, Episode reward: 798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'snake_lengths': [39,\n",
       "  9,\n",
       "  17,\n",
       "  33,\n",
       "  27,\n",
       "  20,\n",
       "  46,\n",
       "  23,\n",
       "  32,\n",
       "  28,\n",
       "  33,\n",
       "  36,\n",
       "  43,\n",
       "  35,\n",
       "  42,\n",
       "  29,\n",
       "  32,\n",
       "  28,\n",
       "  36,\n",
       "  14,\n",
       "  5,\n",
       "  27,\n",
       "  17,\n",
       "  12,\n",
       "  25,\n",
       "  27,\n",
       "  18,\n",
       "  22,\n",
       "  24,\n",
       "  18,\n",
       "  28,\n",
       "  29,\n",
       "  48,\n",
       "  36,\n",
       "  24,\n",
       "  15,\n",
       "  13,\n",
       "  36,\n",
       "  51,\n",
       "  24,\n",
       "  33,\n",
       "  35,\n",
       "  25,\n",
       "  38,\n",
       "  24,\n",
       "  39,\n",
       "  19,\n",
       "  27,\n",
       "  32,\n",
       "  38,\n",
       "  39,\n",
       "  23,\n",
       "  23,\n",
       "  42,\n",
       "  15,\n",
       "  48,\n",
       "  12,\n",
       "  55,\n",
       "  20,\n",
       "  39,\n",
       "  48,\n",
       "  27,\n",
       "  32,\n",
       "  32,\n",
       "  22,\n",
       "  46,\n",
       "  29,\n",
       "  21,\n",
       "  29,\n",
       "  26,\n",
       "  22,\n",
       "  29,\n",
       "  33,\n",
       "  34,\n",
       "  34,\n",
       "  24,\n",
       "  42,\n",
       "  33,\n",
       "  25,\n",
       "  27,\n",
       "  9,\n",
       "  42,\n",
       "  52,\n",
       "  40,\n",
       "  26,\n",
       "  34,\n",
       "  6,\n",
       "  35,\n",
       "  19,\n",
       "  42,\n",
       "  37,\n",
       "  40,\n",
       "  16,\n",
       "  38,\n",
       "  15,\n",
       "  41,\n",
       "  16,\n",
       "  16,\n",
       "  34,\n",
       "  11],\n",
       " 'episode_rewards': [3272,\n",
       "  595,\n",
       "  1292,\n",
       "  2728,\n",
       "  2241,\n",
       "  1575,\n",
       "  3930,\n",
       "  1927,\n",
       "  2643,\n",
       "  2349,\n",
       "  2756,\n",
       "  3046,\n",
       "  3669,\n",
       "  2947,\n",
       "  3652,\n",
       "  2403,\n",
       "  2615,\n",
       "  2252,\n",
       "  3007,\n",
       "  1079,\n",
       "  298,\n",
       "  2244,\n",
       "  1352,\n",
       "  885,\n",
       "  2024,\n",
       "  2223,\n",
       "  1411,\n",
       "  1809,\n",
       "  1922,\n",
       "  1400,\n",
       "  2392,\n",
       "  2344,\n",
       "  4107,\n",
       "  3147,\n",
       "  1973,\n",
       "  1146,\n",
       "  1002,\n",
       "  3025,\n",
       "  4333,\n",
       "  1882,\n",
       "  2814,\n",
       "  2904,\n",
       "  2065,\n",
       "  3170,\n",
       "  1938,\n",
       "  3317,\n",
       "  1521,\n",
       "  2239,\n",
       "  2683,\n",
       "  3174,\n",
       "  3315,\n",
       "  1847,\n",
       "  1867,\n",
       "  3516,\n",
       "  1104,\n",
       "  4053,\n",
       "  862,\n",
       "  4715,\n",
       "  1539,\n",
       "  3282,\n",
       "  4159,\n",
       "  2212,\n",
       "  2631,\n",
       "  2670,\n",
       "  1775,\n",
       "  3882,\n",
       "  2382,\n",
       "  1744,\n",
       "  2431,\n",
       "  2159,\n",
       "  1837,\n",
       "  2402,\n",
       "  2783,\n",
       "  2805,\n",
       "  2840,\n",
       "  1929,\n",
       "  3542,\n",
       "  2708,\n",
       "  2065,\n",
       "  2252,\n",
       "  648,\n",
       "  3508,\n",
       "  4471,\n",
       "  3389,\n",
       "  2093,\n",
       "  2868,\n",
       "  402,\n",
       "  2960,\n",
       "  1554,\n",
       "  3598,\n",
       "  3157,\n",
       "  3433,\n",
       "  1232,\n",
       "  3181,\n",
       "  1163,\n",
       "  3436,\n",
       "  1220,\n",
       "  1276,\n",
       "  2846,\n",
       "  798]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if isinstance(env, ParObsSnakeEnv):\n",
    "    env = ParObsSnakeEnv(grid_size=2*grid_size, interact=False)\n",
    "\n",
    "num_simulations = 100\n",
    "metrics_name = f'dqn_metrics_{environment}_{num_episodes}_{env.grid_size}_{num_simulations}.jsn'\n",
    "model_metrics_dir = os.path.join('../..', 'artifacts', 'models_stats', 'dqn')\n",
    "os.makedirs(model_metrics_dir, exist_ok=True)\n",
    "metrics_path = os.path.join(model_metrics_dir, metrics_name)\n",
    "\n",
    "compute_metrics(agent, env, metrics_path, num_simulations=num_simulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: -75\n"
     ]
    }
   ],
   "source": [
    "if isinstance(env, FullObsSnakeEnv):\n",
    "    env.interact = True\n",
    "else:\n",
    "    env = ParObsSnakeEnv(grid_size=2*grid_size)\n",
    "    \n",
    "state = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action, _ = agent.choose_action(state)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    print(f\"Reward: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
