{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../..')))\n",
    "\n",
    "from src.ParObsSnakeEnv import ParObsSnakeEnv\n",
    "from src.FullObsSnakeEnv import FullObsSnakeEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=128):\n",
    "        super(DQN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.fc1 = nn.Linear(input_dim, self.hidden_dim)\n",
    "        self.fc2 = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.fc3 = nn.Linear(self.hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DQN agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_dim, action_dim, lr=0.001, gamma=0.99, epsilon=1.0, epsilon_decay=0.9995, epsilon_min=0.01, memory_size=10000, batch_size=64):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.memory = deque(maxlen=memory_size)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = DQN(state_dim, action_dim).to(self.device)\n",
    "        self.target_model = DQN(state_dim, action_dim).to(self.device)\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def act(self, state):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.randint(0, self.action_dim - 1)\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
    "        state = state.reshape((1, -1))\n",
    "        with torch.no_grad():\n",
    "            # print(\">>>>\", state.shape)\n",
    "            q_values = self.model(state)\n",
    "        return torch.argmax(q_values).item()\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        batch = random.sample(self.memory, self.batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "        states = torch.FloatTensor(states).to(self.device)\n",
    "        actions = torch.LongTensor(actions).to(self.device)\n",
    "        rewards = torch.FloatTensor(rewards).to(self.device)\n",
    "        next_states = torch.FloatTensor(next_states).to(self.device)\n",
    "        dones = torch.FloatTensor(dones).to(self.device)\n",
    "\n",
    "        states = states.reshape((self.batch_size, -1))\n",
    "        next_states = next_states.reshape((self.batch_size, -1))\n",
    "\n",
    "        # Compute current Q-values\n",
    "        q_values = self.model(states)\n",
    "        q_values = q_values.gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        # Compute target Q-values\n",
    "        next_q_values = self.target_model(next_states).max(1)[0]\n",
    "        target_q_values = rewards + (1 - dones) * self.gamma * next_q_values\n",
    "\n",
    "        # Update the Q-network\n",
    "        loss = self.criterion(q_values, target_q_values)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Decay epsilon\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "# Train the agent\n",
    "def train_dqn(env, agent, episodes=1000, update_target_every=10):\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            agent.replay()\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "\n",
    "        agent.update_target_model()\n",
    "        print(f\"Episode {episode + 1}/{episodes}, Total Reward: {total_reward}, Epsilon: {agent.epsilon:.3f}\")\n",
    "\n",
    "        if (episode + 1) % update_target_every == 0:\n",
    "            print(\"Updated target model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = FullObsSnakeEnv(grid_size=3, interact=False)\n",
    "env = ParObsSnakeEnv(grid_size=10, interact=False)\n",
    "if isinstance(env, FullObsSnakeEnv):\n",
    "    state_dim = env.observation_space.shape[0] * env.observation_space.shape[1] * env.observation_space.shape[2]\n",
    "else:\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "\n",
    "action_dim = env.action_space.n\n",
    "agent = DQNAgent(state_dim, action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1/6000, Total Reward: 79, Epsilon: 1.000\n",
      "Episode 2/6000, Total Reward: -74, Epsilon: 1.000\n",
      "Episode 3/6000, Total Reward: -75, Epsilon: 1.000\n",
      "Episode 4/6000, Total Reward: -76, Epsilon: 1.000\n",
      "Episode 5/6000, Total Reward: -74, Epsilon: 1.000\n",
      "Episode 6/6000, Total Reward: -75, Epsilon: 1.000\n",
      "Episode 7/6000, Total Reward: -73, Epsilon: 1.000\n",
      "Episode 8/6000, Total Reward: -74, Epsilon: 1.000\n",
      "Episode 9/6000, Total Reward: -74, Epsilon: 1.000\n",
      "Episode 10/6000, Total Reward: 154, Epsilon: 1.000\n",
      "Updated target model.\n",
      "Episode 11/6000, Total Reward: -75, Epsilon: 1.000\n",
      "Episode 12/6000, Total Reward: -76, Epsilon: 1.000\n",
      "Episode 13/6000, Total Reward: -76, Epsilon: 1.000\n",
      "Episode 14/6000, Total Reward: -76, Epsilon: 1.000\n",
      "Episode 15/6000, Total Reward: -76, Epsilon: 1.000\n",
      "Episode 16/6000, Total Reward: -75, Epsilon: 1.000\n",
      "Episode 17/6000, Total Reward: -76, Epsilon: 1.000\n",
      "Episode 18/6000, Total Reward: -75, Epsilon: 1.000\n",
      "Episode 19/6000, Total Reward: -73, Epsilon: 1.000\n",
      "Episode 20/6000, Total Reward: 1, Epsilon: 1.000\n",
      "Updated target model.\n",
      "Episode 21/6000, Total Reward: -75, Epsilon: 1.000\n",
      "Episode 22/6000, Total Reward: -75, Epsilon: 1.000\n",
      "Episode 23/6000, Total Reward: 3, Epsilon: 1.000\n",
      "Episode 24/6000, Total Reward: -75, Epsilon: 1.000\n",
      "Episode 25/6000, Total Reward: -75, Epsilon: 1.000\n",
      "Episode 26/6000, Total Reward: -74, Epsilon: 0.999\n",
      "Episode 27/6000, Total Reward: -76, Epsilon: 0.998\n",
      "Episode 28/6000, Total Reward: -73, Epsilon: 0.997\n",
      "Episode 29/6000, Total Reward: -75, Epsilon: 0.996\n",
      "Episode 30/6000, Total Reward: 79, Epsilon: 0.990\n",
      "Updated target model.\n",
      "Episode 31/6000, Total Reward: -75, Epsilon: 0.989\n",
      "Episode 32/6000, Total Reward: -75, Epsilon: 0.989\n",
      "Episode 33/6000, Total Reward: -75, Epsilon: 0.988\n",
      "Episode 34/6000, Total Reward: -75, Epsilon: 0.988\n",
      "Episode 35/6000, Total Reward: -75, Epsilon: 0.987\n",
      "Episode 36/6000, Total Reward: -75, Epsilon: 0.986\n",
      "Episode 37/6000, Total Reward: 1, Epsilon: 0.985\n",
      "Episode 38/6000, Total Reward: -76, Epsilon: 0.982\n",
      "Episode 39/6000, Total Reward: -74, Epsilon: 0.981\n",
      "Episode 40/6000, Total Reward: -75, Epsilon: 0.979\n",
      "Updated target model.\n",
      "Episode 41/6000, Total Reward: 4, Epsilon: 0.977\n",
      "Episode 42/6000, Total Reward: -77, Epsilon: 0.975\n",
      "Episode 43/6000, Total Reward: -75, Epsilon: 0.975\n",
      "Episode 44/6000, Total Reward: 4, Epsilon: 0.971\n",
      "Episode 45/6000, Total Reward: -75, Epsilon: 0.970\n",
      "Episode 46/6000, Total Reward: -75, Epsilon: 0.969\n",
      "Episode 47/6000, Total Reward: -75, Epsilon: 0.969\n",
      "Episode 48/6000, Total Reward: -76, Epsilon: 0.968\n",
      "Episode 49/6000, Total Reward: -75, Epsilon: 0.968\n",
      "Episode 50/6000, Total Reward: -76, Epsilon: 0.967\n",
      "Updated target model.\n",
      "Episode 51/6000, Total Reward: 1, Epsilon: 0.964\n",
      "Episode 52/6000, Total Reward: -74, Epsilon: 0.963\n",
      "Episode 53/6000, Total Reward: 0, Epsilon: 0.961\n",
      "Episode 54/6000, Total Reward: -77, Epsilon: 0.960\n",
      "Episode 55/6000, Total Reward: -75, Epsilon: 0.959\n",
      "Episode 56/6000, Total Reward: -77, Epsilon: 0.957\n",
      "Episode 57/6000, Total Reward: 80, Epsilon: 0.954\n",
      "Episode 58/6000, Total Reward: -75, Epsilon: 0.954\n",
      "Episode 59/6000, Total Reward: -77, Epsilon: 0.952\n",
      "Episode 60/6000, Total Reward: -75, Epsilon: 0.951\n",
      "Updated target model.\n",
      "Episode 61/6000, Total Reward: -75, Epsilon: 0.950\n",
      "Episode 62/6000, Total Reward: -76, Epsilon: 0.949\n",
      "Episode 63/6000, Total Reward: -77, Epsilon: 0.947\n",
      "Episode 64/6000, Total Reward: -75, Epsilon: 0.946\n",
      "Episode 65/6000, Total Reward: -75, Epsilon: 0.946\n",
      "Episode 66/6000, Total Reward: -76, Epsilon: 0.945\n",
      "Episode 67/6000, Total Reward: -75, Epsilon: 0.945\n",
      "Episode 68/6000, Total Reward: -74, Epsilon: 0.944\n",
      "Episode 69/6000, Total Reward: -75, Epsilon: 0.943\n",
      "Episode 70/6000, Total Reward: -75, Epsilon: 0.942\n",
      "Updated target model.\n",
      "Episode 71/6000, Total Reward: -75, Epsilon: 0.941\n",
      "Episode 72/6000, Total Reward: -75, Epsilon: 0.941\n",
      "Episode 73/6000, Total Reward: -73, Epsilon: 0.939\n",
      "Episode 74/6000, Total Reward: -76, Epsilon: 0.938\n",
      "Episode 75/6000, Total Reward: -75, Epsilon: 0.938\n",
      "Episode 76/6000, Total Reward: -76, Epsilon: 0.937\n",
      "Episode 77/6000, Total Reward: -75, Epsilon: 0.937\n",
      "Episode 78/6000, Total Reward: 2, Epsilon: 0.935\n",
      "Episode 79/6000, Total Reward: -73, Epsilon: 0.934\n",
      "Episode 80/6000, Total Reward: 2, Epsilon: 0.931\n",
      "Updated target model.\n",
      "Episode 81/6000, Total Reward: 0, Epsilon: 0.930\n",
      "Episode 82/6000, Total Reward: -76, Epsilon: 0.928\n",
      "Episode 83/6000, Total Reward: 1, Epsilon: 0.926\n",
      "Episode 84/6000, Total Reward: -74, Epsilon: 0.925\n",
      "Episode 85/6000, Total Reward: -75, Epsilon: 0.925\n",
      "Episode 86/6000, Total Reward: -75, Epsilon: 0.923\n",
      "Episode 87/6000, Total Reward: -76, Epsilon: 0.922\n",
      "Episode 88/6000, Total Reward: -75, Epsilon: 0.921\n",
      "Episode 89/6000, Total Reward: 1, Epsilon: 0.919\n",
      "Episode 90/6000, Total Reward: -75, Epsilon: 0.919\n",
      "Updated target model.\n",
      "Episode 91/6000, Total Reward: -76, Epsilon: 0.918\n",
      "Episode 92/6000, Total Reward: -75, Epsilon: 0.917\n",
      "Episode 93/6000, Total Reward: -75, Epsilon: 0.916\n",
      "Episode 94/6000, Total Reward: -77, Epsilon: 0.915\n",
      "Episode 95/6000, Total Reward: -76, Epsilon: 0.914\n",
      "Episode 96/6000, Total Reward: -75, Epsilon: 0.913\n",
      "Episode 97/6000, Total Reward: 2, Epsilon: 0.911\n",
      "Episode 98/6000, Total Reward: -74, Epsilon: 0.910\n",
      "Episode 99/6000, Total Reward: -75, Epsilon: 0.910\n",
      "Episode 100/6000, Total Reward: -75, Epsilon: 0.909\n",
      "Updated target model.\n",
      "Episode 101/6000, Total Reward: -75, Epsilon: 0.908\n",
      "Episode 102/6000, Total Reward: -75, Epsilon: 0.907\n",
      "Episode 103/6000, Total Reward: -76, Epsilon: 0.906\n",
      "Episode 104/6000, Total Reward: -77, Epsilon: 0.904\n",
      "Episode 105/6000, Total Reward: 79, Epsilon: 0.902\n",
      "Episode 106/6000, Total Reward: -75, Epsilon: 0.901\n",
      "Episode 107/6000, Total Reward: -75, Epsilon: 0.900\n",
      "Episode 108/6000, Total Reward: -74, Epsilon: 0.899\n",
      "Episode 109/6000, Total Reward: -75, Epsilon: 0.899\n",
      "Episode 110/6000, Total Reward: -76, Epsilon: 0.898\n",
      "Updated target model.\n",
      "Episode 111/6000, Total Reward: -75, Epsilon: 0.898\n",
      "Episode 112/6000, Total Reward: -76, Epsilon: 0.897\n",
      "Episode 113/6000, Total Reward: -75, Epsilon: 0.895\n",
      "Episode 114/6000, Total Reward: -76, Epsilon: 0.894\n",
      "Episode 115/6000, Total Reward: -78, Epsilon: 0.893\n",
      "Episode 116/6000, Total Reward: 77, Epsilon: 0.891\n",
      "Episode 117/6000, Total Reward: 0, Epsilon: 0.888\n",
      "Episode 118/6000, Total Reward: 0, Epsilon: 0.887\n",
      "Episode 119/6000, Total Reward: -75, Epsilon: 0.886\n",
      "Episode 120/6000, Total Reward: -75, Epsilon: 0.886\n",
      "Updated target model.\n",
      "Episode 121/6000, Total Reward: -75, Epsilon: 0.886\n",
      "Episode 122/6000, Total Reward: -76, Epsilon: 0.885\n",
      "Episode 123/6000, Total Reward: 2, Epsilon: 0.882\n",
      "Episode 124/6000, Total Reward: -74, Epsilon: 0.881\n",
      "Episode 125/6000, Total Reward: -75, Epsilon: 0.880\n",
      "Episode 126/6000, Total Reward: -77, Epsilon: 0.879\n",
      "Episode 127/6000, Total Reward: -75, Epsilon: 0.877\n",
      "Episode 128/6000, Total Reward: -75, Epsilon: 0.876\n",
      "Episode 129/6000, Total Reward: -75, Epsilon: 0.876\n",
      "Episode 130/6000, Total Reward: 2, Epsilon: 0.875\n",
      "Updated target model.\n",
      "Episode 131/6000, Total Reward: -75, Epsilon: 0.874\n",
      "Episode 132/6000, Total Reward: -75, Epsilon: 0.874\n",
      "Episode 133/6000, Total Reward: -76, Epsilon: 0.873\n",
      "Episode 134/6000, Total Reward: -77, Epsilon: 0.872\n",
      "Episode 135/6000, Total Reward: -75, Epsilon: 0.871\n",
      "Episode 136/6000, Total Reward: 4, Epsilon: 0.869\n",
      "Episode 137/6000, Total Reward: -76, Epsilon: 0.868\n",
      "Episode 138/6000, Total Reward: -76, Epsilon: 0.867\n",
      "Episode 139/6000, Total Reward: -75, Epsilon: 0.867\n",
      "Episode 140/6000, Total Reward: -75, Epsilon: 0.866\n",
      "Updated target model.\n",
      "Episode 141/6000, Total Reward: -75, Epsilon: 0.865\n",
      "Episode 142/6000, Total Reward: -77, Epsilon: 0.864\n",
      "Episode 143/6000, Total Reward: -75, Epsilon: 0.863\n",
      "Episode 144/6000, Total Reward: -74, Epsilon: 0.862\n",
      "Episode 145/6000, Total Reward: -74, Epsilon: 0.862\n",
      "Episode 146/6000, Total Reward: -76, Epsilon: 0.861\n",
      "Episode 147/6000, Total Reward: 78, Epsilon: 0.859\n",
      "Episode 148/6000, Total Reward: -75, Epsilon: 0.858\n",
      "Episode 149/6000, Total Reward: -76, Epsilon: 0.857\n",
      "Episode 150/6000, Total Reward: -75, Epsilon: 0.856\n",
      "Updated target model.\n",
      "Episode 151/6000, Total Reward: -75, Epsilon: 0.854\n",
      "Episode 152/6000, Total Reward: -75, Epsilon: 0.854\n",
      "Episode 153/6000, Total Reward: 153, Epsilon: 0.852\n",
      "Episode 154/6000, Total Reward: -75, Epsilon: 0.852\n",
      "Episode 155/6000, Total Reward: -75, Epsilon: 0.850\n",
      "Episode 156/6000, Total Reward: -74, Epsilon: 0.848\n",
      "Episode 157/6000, Total Reward: -75, Epsilon: 0.847\n",
      "Episode 158/6000, Total Reward: -76, Epsilon: 0.847\n",
      "Episode 159/6000, Total Reward: -75, Epsilon: 0.846\n",
      "Episode 160/6000, Total Reward: -75, Epsilon: 0.844\n",
      "Updated target model.\n",
      "Episode 161/6000, Total Reward: -74, Epsilon: 0.843\n",
      "Episode 162/6000, Total Reward: -75, Epsilon: 0.843\n",
      "Episode 163/6000, Total Reward: 2, Epsilon: 0.842\n",
      "Episode 164/6000, Total Reward: 0, Epsilon: 0.840\n",
      "Episode 165/6000, Total Reward: -75, Epsilon: 0.839\n",
      "Episode 166/6000, Total Reward: -74, Epsilon: 0.838\n",
      "Episode 167/6000, Total Reward: -76, Epsilon: 0.836\n",
      "Episode 168/6000, Total Reward: -75, Epsilon: 0.836\n",
      "Episode 169/6000, Total Reward: -76, Epsilon: 0.835\n",
      "Episode 170/6000, Total Reward: 77, Epsilon: 0.833\n",
      "Updated target model.\n",
      "Episode 171/6000, Total Reward: -76, Epsilon: 0.832\n",
      "Episode 172/6000, Total Reward: -76, Epsilon: 0.831\n",
      "Episode 173/6000, Total Reward: -76, Epsilon: 0.831\n",
      "Episode 174/6000, Total Reward: -75, Epsilon: 0.830\n",
      "Episode 175/6000, Total Reward: -73, Epsilon: 0.829\n",
      "Episode 176/6000, Total Reward: -75, Epsilon: 0.829\n",
      "Episode 177/6000, Total Reward: -75, Epsilon: 0.828\n",
      "Episode 178/6000, Total Reward: 2, Epsilon: 0.827\n",
      "Episode 179/6000, Total Reward: -76, Epsilon: 0.824\n",
      "Episode 180/6000, Total Reward: -75, Epsilon: 0.824\n",
      "Updated target model.\n",
      "Episode 181/6000, Total Reward: -75, Epsilon: 0.824\n",
      "Episode 182/6000, Total Reward: 1, Epsilon: 0.823\n",
      "Episode 183/6000, Total Reward: 3, Epsilon: 0.821\n",
      "Episode 184/6000, Total Reward: -76, Epsilon: 0.820\n",
      "Episode 185/6000, Total Reward: -74, Epsilon: 0.820\n",
      "Episode 186/6000, Total Reward: -76, Epsilon: 0.819\n",
      "Episode 187/6000, Total Reward: -75, Epsilon: 0.818\n",
      "Episode 188/6000, Total Reward: 2, Epsilon: 0.815\n",
      "Episode 189/6000, Total Reward: -76, Epsilon: 0.814\n",
      "Episode 190/6000, Total Reward: -74, Epsilon: 0.812\n",
      "Updated target model.\n",
      "Episode 191/6000, Total Reward: -76, Epsilon: 0.811\n",
      "Episode 192/6000, Total Reward: 1, Epsilon: 0.811\n",
      "Episode 193/6000, Total Reward: -76, Epsilon: 0.810\n",
      "Episode 194/6000, Total Reward: -76, Epsilon: 0.809\n",
      "Episode 195/6000, Total Reward: 3, Epsilon: 0.807\n",
      "Episode 196/6000, Total Reward: -76, Epsilon: 0.806\n",
      "Episode 197/6000, Total Reward: -76, Epsilon: 0.805\n",
      "Episode 198/6000, Total Reward: -75, Epsilon: 0.804\n",
      "Episode 199/6000, Total Reward: -74, Epsilon: 0.803\n",
      "Episode 200/6000, Total Reward: -76, Epsilon: 0.802\n",
      "Updated target model.\n",
      "Episode 201/6000, Total Reward: 1, Epsilon: 0.800\n",
      "Episode 202/6000, Total Reward: -75, Epsilon: 0.800\n",
      "Episode 203/6000, Total Reward: -75, Epsilon: 0.800\n",
      "Episode 204/6000, Total Reward: -77, Epsilon: 0.798\n",
      "Episode 205/6000, Total Reward: -75, Epsilon: 0.798\n",
      "Episode 206/6000, Total Reward: -75, Epsilon: 0.798\n",
      "Episode 207/6000, Total Reward: 1, Epsilon: 0.796\n",
      "Episode 208/6000, Total Reward: -75, Epsilon: 0.796\n",
      "Episode 209/6000, Total Reward: -75, Epsilon: 0.795\n",
      "Episode 210/6000, Total Reward: -73, Epsilon: 0.794\n",
      "Updated target model.\n",
      "Episode 211/6000, Total Reward: -76, Epsilon: 0.793\n",
      "Episode 212/6000, Total Reward: -76, Epsilon: 0.792\n",
      "Episode 213/6000, Total Reward: -73, Epsilon: 0.791\n",
      "Episode 214/6000, Total Reward: -74, Epsilon: 0.790\n",
      "Episode 215/6000, Total Reward: -75, Epsilon: 0.789\n",
      "Episode 216/6000, Total Reward: -75, Epsilon: 0.789\n",
      "Episode 217/6000, Total Reward: 2, Epsilon: 0.788\n",
      "Episode 218/6000, Total Reward: -73, Epsilon: 0.787\n",
      "Episode 219/6000, Total Reward: 1, Epsilon: 0.786\n",
      "Episode 220/6000, Total Reward: -75, Epsilon: 0.785\n",
      "Updated target model.\n",
      "Episode 221/6000, Total Reward: 2, Epsilon: 0.784\n",
      "Episode 222/6000, Total Reward: -75, Epsilon: 0.784\n",
      "Episode 223/6000, Total Reward: 1, Epsilon: 0.782\n",
      "Episode 224/6000, Total Reward: -78, Epsilon: 0.781\n",
      "Episode 225/6000, Total Reward: -75, Epsilon: 0.780\n",
      "Episode 226/6000, Total Reward: -76, Epsilon: 0.780\n",
      "Episode 227/6000, Total Reward: -77, Epsilon: 0.778\n",
      "Episode 228/6000, Total Reward: -76, Epsilon: 0.778\n",
      "Episode 229/6000, Total Reward: -77, Epsilon: 0.776\n",
      "Episode 230/6000, Total Reward: -77, Epsilon: 0.774\n",
      "Updated target model.\n",
      "Episode 231/6000, Total Reward: 3, Epsilon: 0.773\n",
      "Episode 232/6000, Total Reward: -75, Epsilon: 0.773\n",
      "Episode 233/6000, Total Reward: -75, Epsilon: 0.772\n",
      "Episode 234/6000, Total Reward: -74, Epsilon: 0.771\n",
      "Episode 235/6000, Total Reward: 1, Epsilon: 0.771\n",
      "Episode 236/6000, Total Reward: -75, Epsilon: 0.770\n",
      "Episode 237/6000, Total Reward: -75, Epsilon: 0.769\n",
      "Episode 238/6000, Total Reward: -75, Epsilon: 0.769\n",
      "Episode 239/6000, Total Reward: -74, Epsilon: 0.768\n",
      "Episode 240/6000, Total Reward: -75, Epsilon: 0.768\n",
      "Updated target model.\n",
      "Episode 241/6000, Total Reward: -76, Epsilon: 0.767\n",
      "Episode 242/6000, Total Reward: -75, Epsilon: 0.766\n",
      "Episode 243/6000, Total Reward: -77, Epsilon: 0.765\n",
      "Episode 244/6000, Total Reward: 1, Epsilon: 0.764\n",
      "Episode 245/6000, Total Reward: -75, Epsilon: 0.764\n",
      "Episode 246/6000, Total Reward: -75, Epsilon: 0.762\n",
      "Episode 247/6000, Total Reward: -74, Epsilon: 0.761\n",
      "Episode 248/6000, Total Reward: 2, Epsilon: 0.758\n",
      "Episode 249/6000, Total Reward: -76, Epsilon: 0.757\n",
      "Episode 250/6000, Total Reward: -75, Epsilon: 0.757\n",
      "Updated target model.\n",
      "Episode 251/6000, Total Reward: -75, Epsilon: 0.756\n",
      "Episode 252/6000, Total Reward: -75, Epsilon: 0.756\n",
      "Episode 253/6000, Total Reward: -74, Epsilon: 0.755\n",
      "Episode 254/6000, Total Reward: -75, Epsilon: 0.755\n",
      "Episode 255/6000, Total Reward: -72, Epsilon: 0.753\n",
      "Episode 256/6000, Total Reward: -75, Epsilon: 0.753\n",
      "Episode 257/6000, Total Reward: -74, Epsilon: 0.752\n",
      "Episode 258/6000, Total Reward: -72, Epsilon: 0.750\n",
      "Episode 259/6000, Total Reward: -74, Epsilon: 0.749\n",
      "Episode 260/6000, Total Reward: 1, Epsilon: 0.749\n",
      "Updated target model.\n",
      "Episode 261/6000, Total Reward: -74, Epsilon: 0.747\n",
      "Episode 262/6000, Total Reward: -75, Epsilon: 0.747\n",
      "Episode 263/6000, Total Reward: -75, Epsilon: 0.746\n",
      "Episode 264/6000, Total Reward: -75, Epsilon: 0.745\n",
      "Episode 265/6000, Total Reward: -72, Epsilon: 0.744\n",
      "Episode 266/6000, Total Reward: -75, Epsilon: 0.743\n",
      "Episode 267/6000, Total Reward: 2, Epsilon: 0.742\n",
      "Episode 268/6000, Total Reward: -74, Epsilon: 0.741\n",
      "Episode 269/6000, Total Reward: -75, Epsilon: 0.740\n",
      "Episode 270/6000, Total Reward: -74, Epsilon: 0.740\n",
      "Updated target model.\n",
      "Episode 271/6000, Total Reward: -75, Epsilon: 0.739\n",
      "Episode 272/6000, Total Reward: 2, Epsilon: 0.737\n",
      "Episode 273/6000, Total Reward: -76, Epsilon: 0.737\n",
      "Episode 274/6000, Total Reward: 2, Epsilon: 0.736\n",
      "Episode 275/6000, Total Reward: -75, Epsilon: 0.735\n",
      "Episode 276/6000, Total Reward: -77, Epsilon: 0.734\n",
      "Episode 277/6000, Total Reward: -76, Epsilon: 0.733\n",
      "Episode 278/6000, Total Reward: -74, Epsilon: 0.731\n",
      "Episode 279/6000, Total Reward: -77, Epsilon: 0.730\n",
      "Episode 280/6000, Total Reward: -74, Epsilon: 0.729\n",
      "Updated target model.\n",
      "Episode 281/6000, Total Reward: -74, Epsilon: 0.728\n",
      "Episode 282/6000, Total Reward: -75, Epsilon: 0.728\n",
      "Episode 283/6000, Total Reward: -76, Epsilon: 0.727\n",
      "Episode 284/6000, Total Reward: 1, Epsilon: 0.726\n",
      "Episode 285/6000, Total Reward: 1, Epsilon: 0.725\n",
      "Episode 286/6000, Total Reward: -76, Epsilon: 0.724\n",
      "Episode 287/6000, Total Reward: -77, Epsilon: 0.723\n",
      "Episode 288/6000, Total Reward: 78, Epsilon: 0.721\n",
      "Episode 289/6000, Total Reward: -73, Epsilon: 0.720\n",
      "Episode 290/6000, Total Reward: -76, Epsilon: 0.720\n",
      "Updated target model.\n",
      "Episode 291/6000, Total Reward: -76, Epsilon: 0.719\n",
      "Episode 292/6000, Total Reward: -75, Epsilon: 0.719\n",
      "Episode 293/6000, Total Reward: -75, Epsilon: 0.718\n",
      "Episode 294/6000, Total Reward: -74, Epsilon: 0.717\n",
      "Episode 295/6000, Total Reward: -76, Epsilon: 0.716\n",
      "Episode 296/6000, Total Reward: 2, Epsilon: 0.714\n",
      "Episode 297/6000, Total Reward: -75, Epsilon: 0.713\n",
      "Episode 298/6000, Total Reward: -76, Epsilon: 0.712\n",
      "Episode 299/6000, Total Reward: 78, Epsilon: 0.710\n",
      "Episode 300/6000, Total Reward: -76, Epsilon: 0.709\n",
      "Updated target model.\n",
      "Episode 301/6000, Total Reward: -75, Epsilon: 0.709\n",
      "Episode 302/6000, Total Reward: -75, Epsilon: 0.707\n",
      "Episode 303/6000, Total Reward: 1, Epsilon: 0.705\n",
      "Episode 304/6000, Total Reward: -75, Epsilon: 0.705\n",
      "Episode 305/6000, Total Reward: 3, Epsilon: 0.704\n",
      "Episode 306/6000, Total Reward: -78, Epsilon: 0.702\n",
      "Episode 307/6000, Total Reward: -75, Epsilon: 0.702\n",
      "Episode 308/6000, Total Reward: -75, Epsilon: 0.701\n",
      "Episode 309/6000, Total Reward: -76, Epsilon: 0.700\n",
      "Episode 310/6000, Total Reward: -74, Epsilon: 0.699\n",
      "Updated target model.\n",
      "Episode 311/6000, Total Reward: -76, Epsilon: 0.698\n",
      "Episode 312/6000, Total Reward: 1, Epsilon: 0.697\n",
      "Episode 313/6000, Total Reward: -75, Epsilon: 0.696\n",
      "Episode 314/6000, Total Reward: 4, Epsilon: 0.694\n",
      "Episode 315/6000, Total Reward: -76, Epsilon: 0.694\n",
      "Episode 316/6000, Total Reward: 154, Epsilon: 0.691\n",
      "Episode 317/6000, Total Reward: -76, Epsilon: 0.691\n",
      "Episode 318/6000, Total Reward: -73, Epsilon: 0.690\n",
      "Episode 319/6000, Total Reward: -77, Epsilon: 0.689\n",
      "Episode 320/6000, Total Reward: -75, Epsilon: 0.688\n",
      "Updated target model.\n",
      "Episode 321/6000, Total Reward: -75, Epsilon: 0.688\n",
      "Episode 322/6000, Total Reward: -77, Epsilon: 0.687\n",
      "Episode 323/6000, Total Reward: 77, Epsilon: 0.685\n",
      "Episode 324/6000, Total Reward: -73, Epsilon: 0.684\n",
      "Episode 325/6000, Total Reward: 77, Epsilon: 0.682\n",
      "Episode 326/6000, Total Reward: -76, Epsilon: 0.682\n",
      "Episode 327/6000, Total Reward: -75, Epsilon: 0.681\n",
      "Episode 328/6000, Total Reward: -75, Epsilon: 0.680\n",
      "Episode 329/6000, Total Reward: -75, Epsilon: 0.680\n",
      "Episode 330/6000, Total Reward: 79, Epsilon: 0.678\n",
      "Updated target model.\n",
      "Episode 331/6000, Total Reward: -75, Epsilon: 0.677\n",
      "Episode 332/6000, Total Reward: -76, Epsilon: 0.677\n",
      "Episode 333/6000, Total Reward: -76, Epsilon: 0.675\n",
      "Episode 334/6000, Total Reward: -75, Epsilon: 0.675\n",
      "Episode 335/6000, Total Reward: -74, Epsilon: 0.674\n",
      "Episode 336/6000, Total Reward: 79, Epsilon: 0.671\n",
      "Episode 337/6000, Total Reward: -74, Epsilon: 0.670\n",
      "Episode 338/6000, Total Reward: -75, Epsilon: 0.670\n",
      "Episode 339/6000, Total Reward: 2, Epsilon: 0.669\n",
      "Episode 340/6000, Total Reward: -74, Epsilon: 0.668\n",
      "Updated target model.\n",
      "Episode 341/6000, Total Reward: 77, Epsilon: 0.666\n",
      "Episode 342/6000, Total Reward: 3, Epsilon: 0.665\n",
      "Episode 343/6000, Total Reward: -75, Epsilon: 0.665\n",
      "Episode 344/6000, Total Reward: -75, Epsilon: 0.664\n",
      "Episode 345/6000, Total Reward: -77, Epsilon: 0.663\n",
      "Episode 346/6000, Total Reward: -76, Epsilon: 0.663\n",
      "Episode 347/6000, Total Reward: -75, Epsilon: 0.662\n",
      "Episode 348/6000, Total Reward: 4, Epsilon: 0.660\n",
      "Episode 349/6000, Total Reward: 2, Epsilon: 0.659\n",
      "Episode 350/6000, Total Reward: -75, Epsilon: 0.659\n",
      "Updated target model.\n",
      "Episode 351/6000, Total Reward: 0, Epsilon: 0.657\n",
      "Episode 352/6000, Total Reward: -75, Epsilon: 0.657\n",
      "Episode 353/6000, Total Reward: 77, Epsilon: 0.655\n",
      "Episode 354/6000, Total Reward: -74, Epsilon: 0.654\n",
      "Episode 355/6000, Total Reward: -75, Epsilon: 0.653\n",
      "Episode 356/6000, Total Reward: 3, Epsilon: 0.651\n",
      "Episode 357/6000, Total Reward: -75, Epsilon: 0.651\n",
      "Episode 358/6000, Total Reward: 78, Epsilon: 0.649\n",
      "Episode 359/6000, Total Reward: -78, Epsilon: 0.647\n",
      "Episode 360/6000, Total Reward: -75, Epsilon: 0.646\n",
      "Updated target model.\n",
      "Episode 361/6000, Total Reward: -75, Epsilon: 0.645\n",
      "Episode 362/6000, Total Reward: -74, Epsilon: 0.645\n",
      "Episode 363/6000, Total Reward: -75, Epsilon: 0.642\n",
      "Episode 364/6000, Total Reward: -75, Epsilon: 0.641\n",
      "Episode 365/6000, Total Reward: -75, Epsilon: 0.640\n",
      "Episode 366/6000, Total Reward: 1, Epsilon: 0.640\n",
      "Episode 367/6000, Total Reward: -77, Epsilon: 0.638\n",
      "Episode 368/6000, Total Reward: 80, Epsilon: 0.634\n",
      "Episode 369/6000, Total Reward: 2, Epsilon: 0.633\n",
      "Episode 370/6000, Total Reward: -74, Epsilon: 0.632\n",
      "Updated target model.\n",
      "Episode 371/6000, Total Reward: -75, Epsilon: 0.632\n",
      "Episode 372/6000, Total Reward: -76, Epsilon: 0.631\n",
      "Episode 373/6000, Total Reward: -75, Epsilon: 0.631\n",
      "Episode 374/6000, Total Reward: -75, Epsilon: 0.631\n",
      "Episode 375/6000, Total Reward: -76, Epsilon: 0.629\n",
      "Episode 376/6000, Total Reward: -75, Epsilon: 0.628\n",
      "Episode 377/6000, Total Reward: 4, Epsilon: 0.627\n",
      "Episode 378/6000, Total Reward: -75, Epsilon: 0.626\n",
      "Episode 379/6000, Total Reward: -74, Epsilon: 0.626\n",
      "Episode 380/6000, Total Reward: -74, Epsilon: 0.625\n",
      "Updated target model.\n",
      "Episode 381/6000, Total Reward: -75, Epsilon: 0.624\n",
      "Episode 382/6000, Total Reward: -75, Epsilon: 0.624\n",
      "Episode 383/6000, Total Reward: -74, Epsilon: 0.623\n",
      "Episode 384/6000, Total Reward: -77, Epsilon: 0.622\n",
      "Episode 385/6000, Total Reward: -73, Epsilon: 0.621\n",
      "Episode 386/6000, Total Reward: 2, Epsilon: 0.619\n",
      "Episode 387/6000, Total Reward: 157, Epsilon: 0.615\n",
      "Episode 388/6000, Total Reward: -74, Epsilon: 0.614\n",
      "Episode 389/6000, Total Reward: -73, Epsilon: 0.613\n",
      "Episode 390/6000, Total Reward: -75, Epsilon: 0.612\n",
      "Updated target model.\n",
      "Episode 391/6000, Total Reward: -73, Epsilon: 0.611\n",
      "Episode 392/6000, Total Reward: -73, Epsilon: 0.610\n",
      "Episode 393/6000, Total Reward: -75, Epsilon: 0.610\n",
      "Episode 394/6000, Total Reward: -76, Epsilon: 0.609\n",
      "Episode 395/6000, Total Reward: -76, Epsilon: 0.609\n",
      "Episode 396/6000, Total Reward: -75, Epsilon: 0.608\n",
      "Episode 397/6000, Total Reward: 3, Epsilon: 0.606\n",
      "Episode 398/6000, Total Reward: 3, Epsilon: 0.605\n",
      "Episode 399/6000, Total Reward: -74, Epsilon: 0.604\n",
      "Episode 400/6000, Total Reward: -75, Epsilon: 0.604\n",
      "Updated target model.\n",
      "Episode 401/6000, Total Reward: -74, Epsilon: 0.603\n",
      "Episode 402/6000, Total Reward: -75, Epsilon: 0.602\n",
      "Episode 403/6000, Total Reward: -73, Epsilon: 0.601\n",
      "Episode 404/6000, Total Reward: 77, Epsilon: 0.599\n",
      "Episode 405/6000, Total Reward: 2, Epsilon: 0.598\n",
      "Episode 406/6000, Total Reward: -75, Epsilon: 0.598\n",
      "Episode 407/6000, Total Reward: 3, Epsilon: 0.597\n",
      "Episode 408/6000, Total Reward: -75, Epsilon: 0.597\n",
      "Episode 409/6000, Total Reward: -76, Epsilon: 0.595\n",
      "Episode 410/6000, Total Reward: 1, Epsilon: 0.594\n",
      "Updated target model.\n",
      "Episode 411/6000, Total Reward: -75, Epsilon: 0.593\n",
      "Episode 412/6000, Total Reward: -75, Epsilon: 0.592\n",
      "Episode 413/6000, Total Reward: -73, Epsilon: 0.591\n",
      "Episode 414/6000, Total Reward: -75, Epsilon: 0.591\n",
      "Episode 415/6000, Total Reward: -75, Epsilon: 0.591\n",
      "Episode 416/6000, Total Reward: -75, Epsilon: 0.591\n",
      "Episode 417/6000, Total Reward: -75, Epsilon: 0.590\n",
      "Episode 418/6000, Total Reward: -75, Epsilon: 0.590\n",
      "Episode 419/6000, Total Reward: -74, Epsilon: 0.589\n",
      "Episode 420/6000, Total Reward: -75, Epsilon: 0.589\n",
      "Updated target model.\n",
      "Episode 421/6000, Total Reward: 1, Epsilon: 0.589\n",
      "Episode 422/6000, Total Reward: -74, Epsilon: 0.587\n",
      "Episode 423/6000, Total Reward: 3, Epsilon: 0.586\n",
      "Episode 424/6000, Total Reward: -73, Epsilon: 0.585\n",
      "Episode 425/6000, Total Reward: 79, Epsilon: 0.584\n",
      "Episode 426/6000, Total Reward: -77, Epsilon: 0.583\n",
      "Episode 427/6000, Total Reward: -75, Epsilon: 0.583\n",
      "Episode 428/6000, Total Reward: -75, Epsilon: 0.582\n",
      "Episode 429/6000, Total Reward: -75, Epsilon: 0.582\n",
      "Episode 430/6000, Total Reward: -75, Epsilon: 0.581\n",
      "Updated target model.\n",
      "Episode 431/6000, Total Reward: 79, Epsilon: 0.579\n",
      "Episode 432/6000, Total Reward: 2, Epsilon: 0.578\n",
      "Episode 433/6000, Total Reward: -75, Epsilon: 0.578\n",
      "Episode 434/6000, Total Reward: 79, Epsilon: 0.577\n",
      "Episode 435/6000, Total Reward: -75, Epsilon: 0.576\n",
      "Episode 436/6000, Total Reward: -74, Epsilon: 0.576\n",
      "Episode 437/6000, Total Reward: -76, Epsilon: 0.575\n",
      "Episode 438/6000, Total Reward: 4, Epsilon: 0.574\n",
      "Episode 439/6000, Total Reward: -76, Epsilon: 0.573\n",
      "Episode 440/6000, Total Reward: -75, Epsilon: 0.573\n",
      "Updated target model.\n",
      "Episode 441/6000, Total Reward: -75, Epsilon: 0.573\n",
      "Episode 442/6000, Total Reward: -76, Epsilon: 0.572\n",
      "Episode 443/6000, Total Reward: 2, Epsilon: 0.571\n",
      "Episode 444/6000, Total Reward: -75, Epsilon: 0.571\n",
      "Episode 445/6000, Total Reward: -75, Epsilon: 0.570\n",
      "Episode 446/6000, Total Reward: -77, Epsilon: 0.569\n",
      "Episode 447/6000, Total Reward: 1, Epsilon: 0.569\n",
      "Episode 448/6000, Total Reward: -75, Epsilon: 0.568\n",
      "Episode 449/6000, Total Reward: -74, Epsilon: 0.568\n",
      "Episode 450/6000, Total Reward: -75, Epsilon: 0.567\n",
      "Updated target model.\n",
      "Episode 451/6000, Total Reward: 2, Epsilon: 0.566\n",
      "Episode 452/6000, Total Reward: -75, Epsilon: 0.566\n",
      "Episode 453/6000, Total Reward: 4, Epsilon: 0.564\n",
      "Episode 454/6000, Total Reward: -77, Epsilon: 0.563\n",
      "Episode 455/6000, Total Reward: 78, Epsilon: 0.562\n",
      "Episode 456/6000, Total Reward: -73, Epsilon: 0.561\n",
      "Episode 457/6000, Total Reward: 80, Epsilon: 0.559\n",
      "Episode 458/6000, Total Reward: 1, Epsilon: 0.558\n",
      "Episode 459/6000, Total Reward: -76, Epsilon: 0.557\n",
      "Episode 460/6000, Total Reward: 78, Epsilon: 0.554\n",
      "Updated target model.\n",
      "Episode 461/6000, Total Reward: -75, Epsilon: 0.554\n",
      "Episode 462/6000, Total Reward: 156, Epsilon: 0.552\n",
      "Episode 463/6000, Total Reward: 1, Epsilon: 0.550\n",
      "Episode 464/6000, Total Reward: -73, Epsilon: 0.550\n",
      "Episode 465/6000, Total Reward: -76, Epsilon: 0.549\n",
      "Episode 466/6000, Total Reward: -75, Epsilon: 0.549\n",
      "Episode 467/6000, Total Reward: -76, Epsilon: 0.548\n",
      "Episode 468/6000, Total Reward: 1, Epsilon: 0.548\n",
      "Episode 469/6000, Total Reward: -76, Epsilon: 0.547\n",
      "Episode 470/6000, Total Reward: 4, Epsilon: 0.546\n",
      "Updated target model.\n",
      "Episode 471/6000, Total Reward: -77, Epsilon: 0.544\n",
      "Episode 472/6000, Total Reward: -75, Epsilon: 0.544\n",
      "Episode 473/6000, Total Reward: -75, Epsilon: 0.544\n",
      "Episode 474/6000, Total Reward: -75, Epsilon: 0.543\n",
      "Episode 475/6000, Total Reward: -75, Epsilon: 0.542\n",
      "Episode 476/6000, Total Reward: -75, Epsilon: 0.542\n",
      "Episode 477/6000, Total Reward: 2, Epsilon: 0.541\n",
      "Episode 478/6000, Total Reward: 231, Epsilon: 0.538\n",
      "Episode 479/6000, Total Reward: -75, Epsilon: 0.538\n",
      "Episode 480/6000, Total Reward: -75, Epsilon: 0.538\n",
      "Updated target model.\n",
      "Episode 481/6000, Total Reward: 2, Epsilon: 0.537\n",
      "Episode 482/6000, Total Reward: 4, Epsilon: 0.535\n",
      "Episode 483/6000, Total Reward: 79, Epsilon: 0.534\n",
      "Episode 484/6000, Total Reward: 2, Epsilon: 0.533\n",
      "Episode 485/6000, Total Reward: -75, Epsilon: 0.533\n",
      "Episode 486/6000, Total Reward: -73, Epsilon: 0.531\n",
      "Episode 487/6000, Total Reward: 3, Epsilon: 0.530\n",
      "Episode 488/6000, Total Reward: 1, Epsilon: 0.529\n",
      "Episode 489/6000, Total Reward: -75, Epsilon: 0.529\n",
      "Episode 490/6000, Total Reward: -75, Epsilon: 0.528\n",
      "Updated target model.\n",
      "Episode 491/6000, Total Reward: -75, Epsilon: 0.528\n",
      "Episode 492/6000, Total Reward: 231, Epsilon: 0.526\n",
      "Episode 493/6000, Total Reward: -78, Epsilon: 0.525\n",
      "Episode 494/6000, Total Reward: 155, Epsilon: 0.523\n",
      "Episode 495/6000, Total Reward: -75, Epsilon: 0.523\n",
      "Episode 496/6000, Total Reward: 154, Epsilon: 0.519\n",
      "Episode 497/6000, Total Reward: 154, Epsilon: 0.517\n",
      "Episode 498/6000, Total Reward: 2, Epsilon: 0.517\n",
      "Episode 499/6000, Total Reward: -75, Epsilon: 0.516\n",
      "Episode 500/6000, Total Reward: -75, Epsilon: 0.516\n",
      "Updated target model.\n",
      "Episode 501/6000, Total Reward: -74, Epsilon: 0.515\n",
      "Episode 502/6000, Total Reward: -75, Epsilon: 0.515\n",
      "Episode 503/6000, Total Reward: -76, Epsilon: 0.514\n",
      "Episode 504/6000, Total Reward: 79, Epsilon: 0.511\n",
      "Episode 505/6000, Total Reward: -75, Epsilon: 0.511\n",
      "Episode 506/6000, Total Reward: -75, Epsilon: 0.510\n",
      "Episode 507/6000, Total Reward: -75, Epsilon: 0.510\n",
      "Episode 508/6000, Total Reward: -75, Epsilon: 0.510\n",
      "Episode 509/6000, Total Reward: -75, Epsilon: 0.510\n",
      "Episode 510/6000, Total Reward: 2, Epsilon: 0.509\n",
      "Updated target model.\n",
      "Episode 511/6000, Total Reward: -74, Epsilon: 0.508\n",
      "Episode 512/6000, Total Reward: -75, Epsilon: 0.508\n",
      "Episode 513/6000, Total Reward: -76, Epsilon: 0.508\n",
      "Episode 514/6000, Total Reward: -74, Epsilon: 0.507\n",
      "Episode 515/6000, Total Reward: 155, Epsilon: 0.505\n",
      "Episode 516/6000, Total Reward: -74, Epsilon: 0.505\n",
      "Episode 517/6000, Total Reward: 154, Epsilon: 0.503\n",
      "Episode 518/6000, Total Reward: 1, Epsilon: 0.503\n",
      "Episode 519/6000, Total Reward: -76, Epsilon: 0.502\n",
      "Episode 520/6000, Total Reward: 81, Epsilon: 0.500\n",
      "Updated target model.\n",
      "Episode 521/6000, Total Reward: 81, Epsilon: 0.498\n",
      "Episode 522/6000, Total Reward: 79, Epsilon: 0.496\n",
      "Episode 523/6000, Total Reward: 81, Epsilon: 0.495\n",
      "Episode 524/6000, Total Reward: 2, Epsilon: 0.494\n",
      "Episode 525/6000, Total Reward: -75, Epsilon: 0.493\n",
      "Episode 526/6000, Total Reward: 80, Epsilon: 0.492\n",
      "Episode 527/6000, Total Reward: 0, Epsilon: 0.491\n",
      "Episode 528/6000, Total Reward: -77, Epsilon: 0.490\n",
      "Episode 529/6000, Total Reward: 311, Epsilon: 0.487\n",
      "Episode 530/6000, Total Reward: -76, Epsilon: 0.486\n",
      "Updated target model.\n",
      "Episode 531/6000, Total Reward: 4, Epsilon: 0.485\n",
      "Episode 532/6000, Total Reward: -75, Epsilon: 0.485\n",
      "Episode 533/6000, Total Reward: -74, Epsilon: 0.484\n",
      "Episode 534/6000, Total Reward: -78, Epsilon: 0.483\n",
      "Episode 535/6000, Total Reward: -73, Epsilon: 0.481\n",
      "Episode 536/6000, Total Reward: -74, Epsilon: 0.480\n",
      "Episode 537/6000, Total Reward: 79, Epsilon: 0.479\n",
      "Episode 538/6000, Total Reward: -75, Epsilon: 0.478\n",
      "Episode 539/6000, Total Reward: 78, Epsilon: 0.477\n",
      "Episode 540/6000, Total Reward: -75, Epsilon: 0.477\n",
      "Updated target model.\n",
      "Episode 541/6000, Total Reward: 79, Epsilon: 0.476\n",
      "Episode 542/6000, Total Reward: -76, Epsilon: 0.475\n",
      "Episode 543/6000, Total Reward: 155, Epsilon: 0.474\n",
      "Episode 544/6000, Total Reward: 1, Epsilon: 0.472\n",
      "Episode 545/6000, Total Reward: 83, Epsilon: 0.470\n",
      "Episode 546/6000, Total Reward: 79, Epsilon: 0.469\n",
      "Episode 547/6000, Total Reward: -74, Epsilon: 0.468\n",
      "Episode 548/6000, Total Reward: -75, Epsilon: 0.468\n",
      "Episode 549/6000, Total Reward: 155, Epsilon: 0.465\n",
      "Episode 550/6000, Total Reward: 155, Epsilon: 0.464\n",
      "Updated target model.\n",
      "Episode 551/6000, Total Reward: -75, Epsilon: 0.464\n",
      "Episode 552/6000, Total Reward: -75, Epsilon: 0.464\n",
      "Episode 553/6000, Total Reward: 81, Epsilon: 0.462\n",
      "Episode 554/6000, Total Reward: 1, Epsilon: 0.461\n",
      "Episode 555/6000, Total Reward: -72, Epsilon: 0.460\n",
      "Episode 556/6000, Total Reward: -75, Epsilon: 0.460\n",
      "Episode 557/6000, Total Reward: -75, Epsilon: 0.460\n",
      "Episode 558/6000, Total Reward: 3, Epsilon: 0.458\n",
      "Episode 559/6000, Total Reward: 80, Epsilon: 0.457\n",
      "Episode 560/6000, Total Reward: 78, Epsilon: 0.456\n",
      "Updated target model.\n",
      "Episode 561/6000, Total Reward: -75, Epsilon: 0.455\n",
      "Episode 562/6000, Total Reward: 306, Epsilon: 0.453\n",
      "Episode 563/6000, Total Reward: -75, Epsilon: 0.451\n",
      "Episode 564/6000, Total Reward: 77, Epsilon: 0.451\n",
      "Episode 565/6000, Total Reward: -75, Epsilon: 0.450\n",
      "Episode 566/6000, Total Reward: 233, Epsilon: 0.448\n",
      "Episode 567/6000, Total Reward: 159, Epsilon: 0.445\n",
      "Episode 568/6000, Total Reward: -76, Epsilon: 0.445\n",
      "Episode 569/6000, Total Reward: -73, Epsilon: 0.444\n",
      "Episode 570/6000, Total Reward: 1, Epsilon: 0.444\n",
      "Updated target model.\n",
      "Episode 571/6000, Total Reward: 1, Epsilon: 0.443\n",
      "Episode 572/6000, Total Reward: 81, Epsilon: 0.442\n",
      "Episode 573/6000, Total Reward: -75, Epsilon: 0.441\n",
      "Episode 574/6000, Total Reward: -76, Epsilon: 0.440\n",
      "Episode 575/6000, Total Reward: -75, Epsilon: 0.440\n",
      "Episode 576/6000, Total Reward: -75, Epsilon: 0.440\n",
      "Episode 577/6000, Total Reward: 77, Epsilon: 0.439\n",
      "Episode 578/6000, Total Reward: 2, Epsilon: 0.438\n",
      "Episode 579/6000, Total Reward: 3, Epsilon: 0.437\n",
      "Episode 580/6000, Total Reward: 1, Epsilon: 0.436\n",
      "Updated target model.\n",
      "Episode 581/6000, Total Reward: -75, Epsilon: 0.436\n",
      "Episode 582/6000, Total Reward: 79, Epsilon: 0.434\n",
      "Episode 583/6000, Total Reward: -74, Epsilon: 0.434\n",
      "Episode 584/6000, Total Reward: -75, Epsilon: 0.433\n",
      "Episode 585/6000, Total Reward: 157, Epsilon: 0.431\n",
      "Episode 586/6000, Total Reward: -73, Epsilon: 0.430\n",
      "Episode 587/6000, Total Reward: -76, Epsilon: 0.429\n",
      "Episode 588/6000, Total Reward: 2, Epsilon: 0.429\n",
      "Episode 589/6000, Total Reward: 79, Epsilon: 0.428\n",
      "Episode 590/6000, Total Reward: 4, Epsilon: 0.426\n",
      "Updated target model.\n",
      "Episode 591/6000, Total Reward: -75, Epsilon: 0.426\n",
      "Episode 592/6000, Total Reward: -75, Epsilon: 0.426\n",
      "Episode 593/6000, Total Reward: -75, Epsilon: 0.425\n",
      "Episode 594/6000, Total Reward: 4, Epsilon: 0.423\n",
      "Episode 595/6000, Total Reward: -75, Epsilon: 0.423\n",
      "Episode 596/6000, Total Reward: -75, Epsilon: 0.422\n",
      "Episode 597/6000, Total Reward: 231, Epsilon: 0.420\n",
      "Episode 598/6000, Total Reward: -75, Epsilon: 0.420\n",
      "Episode 599/6000, Total Reward: 2, Epsilon: 0.418\n",
      "Episode 600/6000, Total Reward: -76, Epsilon: 0.417\n",
      "Updated target model.\n",
      "Episode 601/6000, Total Reward: -75, Epsilon: 0.417\n",
      "Episode 602/6000, Total Reward: -77, Epsilon: 0.417\n",
      "Episode 603/6000, Total Reward: 154, Epsilon: 0.415\n",
      "Episode 604/6000, Total Reward: 4, Epsilon: 0.413\n",
      "Episode 605/6000, Total Reward: -75, Epsilon: 0.413\n",
      "Episode 606/6000, Total Reward: 3, Epsilon: 0.412\n",
      "Episode 607/6000, Total Reward: 2, Epsilon: 0.411\n",
      "Episode 608/6000, Total Reward: 2, Epsilon: 0.410\n",
      "Episode 609/6000, Total Reward: 1, Epsilon: 0.409\n",
      "Episode 610/6000, Total Reward: 157, Epsilon: 0.407\n",
      "Updated target model.\n",
      "Episode 611/6000, Total Reward: 312, Epsilon: 0.404\n",
      "Episode 612/6000, Total Reward: -75, Epsilon: 0.404\n",
      "Episode 613/6000, Total Reward: -75, Epsilon: 0.404\n",
      "Episode 614/6000, Total Reward: -76, Epsilon: 0.403\n",
      "Episode 615/6000, Total Reward: -75, Epsilon: 0.403\n",
      "Episode 616/6000, Total Reward: 5, Epsilon: 0.402\n",
      "Episode 617/6000, Total Reward: -75, Epsilon: 0.401\n",
      "Episode 618/6000, Total Reward: -76, Epsilon: 0.401\n",
      "Episode 619/6000, Total Reward: -76, Epsilon: 0.401\n",
      "Episode 620/6000, Total Reward: -75, Epsilon: 0.400\n",
      "Updated target model.\n",
      "Episode 621/6000, Total Reward: 3, Epsilon: 0.400\n",
      "Episode 622/6000, Total Reward: -75, Epsilon: 0.399\n",
      "Episode 623/6000, Total Reward: -75, Epsilon: 0.399\n",
      "Episode 624/6000, Total Reward: 3, Epsilon: 0.398\n",
      "Episode 625/6000, Total Reward: -77, Epsilon: 0.396\n",
      "Episode 626/6000, Total Reward: -1, Epsilon: 0.395\n",
      "Episode 627/6000, Total Reward: -75, Epsilon: 0.395\n",
      "Episode 628/6000, Total Reward: 155, Epsilon: 0.394\n",
      "Episode 629/6000, Total Reward: 2, Epsilon: 0.393\n",
      "Episode 630/6000, Total Reward: -74, Epsilon: 0.393\n",
      "Updated target model.\n",
      "Episode 631/6000, Total Reward: -75, Epsilon: 0.393\n",
      "Episode 632/6000, Total Reward: 0, Epsilon: 0.392\n",
      "Episode 633/6000, Total Reward: 153, Epsilon: 0.391\n",
      "Episode 634/6000, Total Reward: -75, Epsilon: 0.391\n",
      "Episode 635/6000, Total Reward: 236, Epsilon: 0.388\n",
      "Episode 636/6000, Total Reward: -75, Epsilon: 0.388\n",
      "Episode 637/6000, Total Reward: 2, Epsilon: 0.387\n",
      "Episode 638/6000, Total Reward: 2, Epsilon: 0.386\n",
      "Episode 639/6000, Total Reward: 1, Epsilon: 0.386\n",
      "Episode 640/6000, Total Reward: 79, Epsilon: 0.385\n",
      "Updated target model.\n",
      "Episode 641/6000, Total Reward: -75, Epsilon: 0.385\n",
      "Episode 642/6000, Total Reward: 232, Epsilon: 0.383\n",
      "Episode 643/6000, Total Reward: 231, Epsilon: 0.381\n",
      "Episode 644/6000, Total Reward: 156, Epsilon: 0.380\n",
      "Episode 645/6000, Total Reward: -74, Epsilon: 0.379\n",
      "Episode 646/6000, Total Reward: -76, Epsilon: 0.379\n",
      "Episode 647/6000, Total Reward: -75, Epsilon: 0.379\n",
      "Episode 648/6000, Total Reward: -76, Epsilon: 0.378\n",
      "Episode 649/6000, Total Reward: 5, Epsilon: 0.376\n",
      "Episode 650/6000, Total Reward: 3, Epsilon: 0.375\n",
      "Updated target model.\n",
      "Episode 651/6000, Total Reward: 1, Epsilon: 0.374\n",
      "Episode 652/6000, Total Reward: -74, Epsilon: 0.374\n",
      "Episode 653/6000, Total Reward: -75, Epsilon: 0.374\n",
      "Episode 654/6000, Total Reward: -75, Epsilon: 0.374\n",
      "Episode 655/6000, Total Reward: 2, Epsilon: 0.372\n",
      "Episode 656/6000, Total Reward: 1, Epsilon: 0.371\n",
      "Episode 657/6000, Total Reward: 155, Epsilon: 0.370\n",
      "Episode 658/6000, Total Reward: 80, Epsilon: 0.369\n",
      "Episode 659/6000, Total Reward: -74, Epsilon: 0.368\n",
      "Episode 660/6000, Total Reward: -74, Epsilon: 0.367\n",
      "Updated target model.\n",
      "Episode 661/6000, Total Reward: -75, Epsilon: 0.367\n",
      "Episode 662/6000, Total Reward: 2, Epsilon: 0.366\n",
      "Episode 663/6000, Total Reward: 1, Epsilon: 0.366\n",
      "Episode 664/6000, Total Reward: -76, Epsilon: 0.365\n",
      "Episode 665/6000, Total Reward: -76, Epsilon: 0.365\n",
      "Episode 666/6000, Total Reward: -76, Epsilon: 0.365\n",
      "Episode 667/6000, Total Reward: -76, Epsilon: 0.364\n",
      "Episode 668/6000, Total Reward: 77, Epsilon: 0.363\n",
      "Episode 669/6000, Total Reward: -75, Epsilon: 0.363\n",
      "Episode 670/6000, Total Reward: 1, Epsilon: 0.362\n",
      "Updated target model.\n",
      "Episode 671/6000, Total Reward: 80, Epsilon: 0.361\n",
      "Episode 672/6000, Total Reward: -75, Epsilon: 0.361\n",
      "Episode 673/6000, Total Reward: 4, Epsilon: 0.359\n",
      "Episode 674/6000, Total Reward: 4, Epsilon: 0.357\n",
      "Episode 675/6000, Total Reward: 75, Epsilon: 0.356\n",
      "Episode 676/6000, Total Reward: 2, Epsilon: 0.355\n",
      "Episode 677/6000, Total Reward: 4, Epsilon: 0.355\n",
      "Episode 678/6000, Total Reward: -76, Epsilon: 0.354\n",
      "Episode 679/6000, Total Reward: -75, Epsilon: 0.353\n",
      "Episode 680/6000, Total Reward: 1, Epsilon: 0.353\n",
      "Updated target model.\n",
      "Episode 681/6000, Total Reward: -75, Epsilon: 0.352\n",
      "Episode 682/6000, Total Reward: 157, Epsilon: 0.351\n",
      "Episode 683/6000, Total Reward: -76, Epsilon: 0.350\n",
      "Episode 684/6000, Total Reward: -75, Epsilon: 0.350\n",
      "Episode 685/6000, Total Reward: -75, Epsilon: 0.350\n",
      "Episode 686/6000, Total Reward: 1, Epsilon: 0.349\n",
      "Episode 687/6000, Total Reward: -75, Epsilon: 0.349\n",
      "Episode 688/6000, Total Reward: -75, Epsilon: 0.349\n",
      "Episode 689/6000, Total Reward: -75, Epsilon: 0.348\n",
      "Episode 690/6000, Total Reward: -75, Epsilon: 0.348\n",
      "Updated target model.\n",
      "Episode 691/6000, Total Reward: -75, Epsilon: 0.348\n",
      "Episode 692/6000, Total Reward: 79, Epsilon: 0.346\n",
      "Episode 693/6000, Total Reward: 79, Epsilon: 0.345\n",
      "Episode 694/6000, Total Reward: -74, Epsilon: 0.345\n",
      "Episode 695/6000, Total Reward: 3, Epsilon: 0.344\n",
      "Episode 696/6000, Total Reward: -75, Epsilon: 0.343\n",
      "Episode 697/6000, Total Reward: 81, Epsilon: 0.342\n",
      "Episode 698/6000, Total Reward: -75, Epsilon: 0.342\n",
      "Episode 699/6000, Total Reward: 3, Epsilon: 0.341\n",
      "Episode 700/6000, Total Reward: -74, Epsilon: 0.341\n",
      "Updated target model.\n",
      "Episode 701/6000, Total Reward: -73, Epsilon: 0.341\n",
      "Episode 702/6000, Total Reward: 3, Epsilon: 0.340\n",
      "Episode 703/6000, Total Reward: 311, Epsilon: 0.336\n",
      "Episode 704/6000, Total Reward: 4, Epsilon: 0.335\n",
      "Episode 705/6000, Total Reward: -75, Epsilon: 0.334\n",
      "Episode 706/6000, Total Reward: -75, Epsilon: 0.334\n",
      "Episode 707/6000, Total Reward: -75, Epsilon: 0.334\n",
      "Episode 708/6000, Total Reward: -72, Epsilon: 0.333\n",
      "Episode 709/6000, Total Reward: -75, Epsilon: 0.333\n",
      "Episode 710/6000, Total Reward: -75, Epsilon: 0.332\n",
      "Updated target model.\n",
      "Episode 711/6000, Total Reward: -75, Epsilon: 0.332\n",
      "Episode 712/6000, Total Reward: -75, Epsilon: 0.332\n",
      "Episode 713/6000, Total Reward: 83, Epsilon: 0.330\n",
      "Episode 714/6000, Total Reward: 1, Epsilon: 0.330\n",
      "Episode 715/6000, Total Reward: 81, Epsilon: 0.328\n",
      "Episode 716/6000, Total Reward: 2, Epsilon: 0.328\n",
      "Episode 717/6000, Total Reward: 78, Epsilon: 0.327\n",
      "Episode 718/6000, Total Reward: -75, Epsilon: 0.327\n",
      "Episode 719/6000, Total Reward: 162, Epsilon: 0.324\n",
      "Episode 720/6000, Total Reward: 77, Epsilon: 0.324\n",
      "Updated target model.\n",
      "Episode 721/6000, Total Reward: 79, Epsilon: 0.323\n",
      "Episode 722/6000, Total Reward: -75, Epsilon: 0.323\n",
      "Episode 723/6000, Total Reward: -75, Epsilon: 0.322\n",
      "Episode 724/6000, Total Reward: -75, Epsilon: 0.322\n",
      "Episode 725/6000, Total Reward: -75, Epsilon: 0.322\n",
      "Episode 726/6000, Total Reward: 76, Epsilon: 0.321\n",
      "Episode 727/6000, Total Reward: -74, Epsilon: 0.321\n",
      "Episode 728/6000, Total Reward: 233, Epsilon: 0.319\n",
      "Episode 729/6000, Total Reward: -74, Epsilon: 0.319\n",
      "Episode 730/6000, Total Reward: -73, Epsilon: 0.318\n",
      "Updated target model.\n",
      "Episode 731/6000, Total Reward: 1, Epsilon: 0.318\n",
      "Episode 732/6000, Total Reward: 1, Epsilon: 0.318\n",
      "Episode 733/6000, Total Reward: -75, Epsilon: 0.317\n",
      "Episode 734/6000, Total Reward: -75, Epsilon: 0.317\n",
      "Episode 735/6000, Total Reward: -75, Epsilon: 0.317\n",
      "Episode 736/6000, Total Reward: -1, Epsilon: 0.316\n",
      "Episode 737/6000, Total Reward: -74, Epsilon: 0.315\n",
      "Episode 738/6000, Total Reward: 78, Epsilon: 0.315\n",
      "Episode 739/6000, Total Reward: -75, Epsilon: 0.314\n",
      "Episode 740/6000, Total Reward: 2, Epsilon: 0.314\n",
      "Updated target model.\n",
      "Episode 741/6000, Total Reward: 80, Epsilon: 0.313\n",
      "Episode 742/6000, Total Reward: 154, Epsilon: 0.312\n",
      "Episode 743/6000, Total Reward: -76, Epsilon: 0.312\n",
      "Episode 744/6000, Total Reward: -75, Epsilon: 0.312\n",
      "Episode 745/6000, Total Reward: 84, Epsilon: 0.310\n",
      "Episode 746/6000, Total Reward: -75, Epsilon: 0.310\n",
      "Episode 747/6000, Total Reward: 1, Epsilon: 0.309\n",
      "Episode 748/6000, Total Reward: 231, Epsilon: 0.307\n",
      "Episode 749/6000, Total Reward: -73, Epsilon: 0.307\n",
      "Episode 750/6000, Total Reward: 0, Epsilon: 0.303\n",
      "Updated target model.\n",
      "Episode 751/6000, Total Reward: -75, Epsilon: 0.303\n",
      "Episode 752/6000, Total Reward: -75, Epsilon: 0.303\n",
      "Episode 753/6000, Total Reward: -75, Epsilon: 0.303\n",
      "Episode 754/6000, Total Reward: -75, Epsilon: 0.303\n",
      "Episode 755/6000, Total Reward: 1, Epsilon: 0.302\n",
      "Episode 756/6000, Total Reward: 3, Epsilon: 0.302\n",
      "Episode 757/6000, Total Reward: 78, Epsilon: 0.301\n",
      "Episode 758/6000, Total Reward: -75, Epsilon: 0.301\n",
      "Episode 759/6000, Total Reward: 2, Epsilon: 0.300\n",
      "Episode 760/6000, Total Reward: 233, Epsilon: 0.299\n",
      "Updated target model.\n",
      "Episode 761/6000, Total Reward: 4, Epsilon: 0.298\n",
      "Episode 762/6000, Total Reward: -76, Epsilon: 0.298\n",
      "Episode 763/6000, Total Reward: -75, Epsilon: 0.297\n",
      "Episode 764/6000, Total Reward: -75, Epsilon: 0.297\n",
      "Episode 765/6000, Total Reward: -75, Epsilon: 0.297\n",
      "Episode 766/6000, Total Reward: -75, Epsilon: 0.297\n",
      "Episode 767/6000, Total Reward: -74, Epsilon: 0.297\n",
      "Episode 768/6000, Total Reward: -75, Epsilon: 0.296\n",
      "Episode 769/6000, Total Reward: -73, Epsilon: 0.296\n",
      "Episode 770/6000, Total Reward: 1, Epsilon: 0.296\n",
      "Updated target model.\n",
      "Episode 771/6000, Total Reward: 3, Epsilon: 0.295\n",
      "Episode 772/6000, Total Reward: 4, Epsilon: 0.294\n",
      "Episode 773/6000, Total Reward: 78, Epsilon: 0.293\n",
      "Episode 774/6000, Total Reward: 77, Epsilon: 0.292\n",
      "Episode 775/6000, Total Reward: 4, Epsilon: 0.290\n",
      "Episode 776/6000, Total Reward: -75, Epsilon: 0.290\n",
      "Episode 777/6000, Total Reward: -76, Epsilon: 0.290\n",
      "Episode 778/6000, Total Reward: -75, Epsilon: 0.290\n",
      "Episode 779/6000, Total Reward: 4, Epsilon: 0.289\n",
      "Episode 780/6000, Total Reward: 78, Epsilon: 0.288\n",
      "Updated target model.\n",
      "Episode 781/6000, Total Reward: 79, Epsilon: 0.287\n",
      "Episode 782/6000, Total Reward: -75, Epsilon: 0.287\n",
      "Episode 783/6000, Total Reward: 2, Epsilon: 0.285\n",
      "Episode 784/6000, Total Reward: 160, Epsilon: 0.283\n",
      "Episode 785/6000, Total Reward: -75, Epsilon: 0.283\n",
      "Episode 786/6000, Total Reward: 1, Epsilon: 0.281\n",
      "Episode 787/6000, Total Reward: 78, Epsilon: 0.280\n",
      "Episode 788/6000, Total Reward: -75, Epsilon: 0.280\n",
      "Episode 789/6000, Total Reward: -76, Epsilon: 0.280\n",
      "Episode 790/6000, Total Reward: -75, Epsilon: 0.280\n",
      "Updated target model.\n",
      "Episode 791/6000, Total Reward: -75, Epsilon: 0.280\n",
      "Episode 792/6000, Total Reward: -77, Epsilon: 0.279\n",
      "Episode 793/6000, Total Reward: 3, Epsilon: 0.279\n",
      "Episode 794/6000, Total Reward: -75, Epsilon: 0.279\n",
      "Episode 795/6000, Total Reward: 1, Epsilon: 0.278\n",
      "Episode 796/6000, Total Reward: 3, Epsilon: 0.278\n",
      "Episode 797/6000, Total Reward: -75, Epsilon: 0.278\n",
      "Episode 798/6000, Total Reward: 155, Epsilon: 0.277\n",
      "Episode 799/6000, Total Reward: 3, Epsilon: 0.276\n",
      "Episode 800/6000, Total Reward: -75, Epsilon: 0.275\n",
      "Updated target model.\n",
      "Episode 801/6000, Total Reward: 2, Epsilon: 0.275\n",
      "Episode 802/6000, Total Reward: 4, Epsilon: 0.274\n",
      "Episode 803/6000, Total Reward: -76, Epsilon: 0.274\n",
      "Episode 804/6000, Total Reward: 81, Epsilon: 0.273\n",
      "Episode 805/6000, Total Reward: 232, Epsilon: 0.271\n",
      "Episode 806/6000, Total Reward: -74, Epsilon: 0.271\n",
      "Episode 807/6000, Total Reward: 463, Epsilon: 0.269\n",
      "Episode 808/6000, Total Reward: 2, Epsilon: 0.268\n",
      "Episode 809/6000, Total Reward: -74, Epsilon: 0.268\n",
      "Episode 810/6000, Total Reward: -76, Epsilon: 0.268\n",
      "Updated target model.\n",
      "Episode 811/6000, Total Reward: -75, Epsilon: 0.268\n",
      "Episode 812/6000, Total Reward: -76, Epsilon: 0.267\n",
      "Episode 813/6000, Total Reward: 307, Epsilon: 0.266\n",
      "Episode 814/6000, Total Reward: 158, Epsilon: 0.264\n",
      "Episode 815/6000, Total Reward: -74, Epsilon: 0.264\n",
      "Episode 816/6000, Total Reward: -75, Epsilon: 0.264\n",
      "Episode 817/6000, Total Reward: 79, Epsilon: 0.263\n",
      "Episode 818/6000, Total Reward: 77, Epsilon: 0.263\n",
      "Episode 819/6000, Total Reward: 1, Epsilon: 0.262\n",
      "Episode 820/6000, Total Reward: -1, Epsilon: 0.261\n",
      "Updated target model.\n",
      "Episode 821/6000, Total Reward: -75, Epsilon: 0.261\n",
      "Episode 822/6000, Total Reward: -75, Epsilon: 0.261\n",
      "Episode 823/6000, Total Reward: 1, Epsilon: 0.261\n",
      "Episode 824/6000, Total Reward: 230, Epsilon: 0.259\n",
      "Episode 825/6000, Total Reward: 77, Epsilon: 0.258\n",
      "Episode 826/6000, Total Reward: 3, Epsilon: 0.256\n",
      "Episode 827/6000, Total Reward: 2, Epsilon: 0.255\n",
      "Episode 828/6000, Total Reward: 3, Epsilon: 0.254\n",
      "Episode 829/6000, Total Reward: -76, Epsilon: 0.253\n",
      "Episode 830/6000, Total Reward: 81, Epsilon: 0.252\n",
      "Updated target model.\n",
      "Episode 831/6000, Total Reward: 155, Epsilon: 0.251\n",
      "Episode 832/6000, Total Reward: 79, Epsilon: 0.250\n",
      "Episode 833/6000, Total Reward: 79, Epsilon: 0.249\n",
      "Episode 834/6000, Total Reward: 1, Epsilon: 0.247\n",
      "Episode 835/6000, Total Reward: -75, Epsilon: 0.247\n",
      "Episode 836/6000, Total Reward: -75, Epsilon: 0.247\n",
      "Episode 837/6000, Total Reward: 2, Epsilon: 0.247\n",
      "Episode 838/6000, Total Reward: 238, Epsilon: 0.245\n",
      "Episode 839/6000, Total Reward: 2, Epsilon: 0.243\n",
      "Episode 840/6000, Total Reward: -75, Epsilon: 0.242\n",
      "Updated target model.\n",
      "Episode 841/6000, Total Reward: 236, Epsilon: 0.241\n",
      "Episode 842/6000, Total Reward: -76, Epsilon: 0.241\n",
      "Episode 843/6000, Total Reward: -75, Epsilon: 0.241\n",
      "Episode 844/6000, Total Reward: 156, Epsilon: 0.240\n",
      "Episode 845/6000, Total Reward: -75, Epsilon: 0.239\n",
      "Episode 846/6000, Total Reward: -76, Epsilon: 0.239\n",
      "Episode 847/6000, Total Reward: -74, Epsilon: 0.239\n",
      "Episode 848/6000, Total Reward: 78, Epsilon: 0.239\n",
      "Episode 849/6000, Total Reward: 82, Epsilon: 0.237\n",
      "Episode 850/6000, Total Reward: -76, Epsilon: 0.237\n",
      "Updated target model.\n",
      "Episode 851/6000, Total Reward: -75, Epsilon: 0.237\n",
      "Episode 852/6000, Total Reward: -74, Epsilon: 0.236\n",
      "Episode 853/6000, Total Reward: 155, Epsilon: 0.235\n",
      "Episode 854/6000, Total Reward: -75, Epsilon: 0.235\n",
      "Episode 855/6000, Total Reward: 79, Epsilon: 0.234\n",
      "Episode 856/6000, Total Reward: 79, Epsilon: 0.233\n",
      "Episode 857/6000, Total Reward: -74, Epsilon: 0.233\n",
      "Episode 858/6000, Total Reward: 2, Epsilon: 0.232\n",
      "Episode 859/6000, Total Reward: 80, Epsilon: 0.231\n",
      "Episode 860/6000, Total Reward: 234, Epsilon: 0.230\n",
      "Updated target model.\n",
      "Episode 861/6000, Total Reward: -74, Epsilon: 0.229\n",
      "Episode 862/6000, Total Reward: 156, Epsilon: 0.228\n",
      "Episode 863/6000, Total Reward: -76, Epsilon: 0.227\n",
      "Episode 864/6000, Total Reward: 237, Epsilon: 0.226\n",
      "Episode 865/6000, Total Reward: 81, Epsilon: 0.225\n",
      "Episode 866/6000, Total Reward: -73, Epsilon: 0.224\n",
      "Episode 867/6000, Total Reward: 2, Epsilon: 0.224\n",
      "Episode 868/6000, Total Reward: 78, Epsilon: 0.223\n",
      "Episode 869/6000, Total Reward: 76, Epsilon: 0.223\n",
      "Episode 870/6000, Total Reward: 156, Epsilon: 0.222\n",
      "Updated target model.\n",
      "Episode 871/6000, Total Reward: 2, Epsilon: 0.221\n",
      "Episode 872/6000, Total Reward: 80, Epsilon: 0.221\n",
      "Episode 873/6000, Total Reward: 77, Epsilon: 0.219\n",
      "Episode 874/6000, Total Reward: -76, Epsilon: 0.219\n",
      "Episode 875/6000, Total Reward: 78, Epsilon: 0.219\n",
      "Episode 876/6000, Total Reward: 234, Epsilon: 0.218\n",
      "Episode 877/6000, Total Reward: -75, Epsilon: 0.218\n",
      "Episode 878/6000, Total Reward: -75, Epsilon: 0.217\n",
      "Episode 879/6000, Total Reward: 80, Epsilon: 0.217\n",
      "Episode 880/6000, Total Reward: 80, Epsilon: 0.215\n",
      "Updated target model.\n",
      "Episode 881/6000, Total Reward: 0, Epsilon: 0.214\n",
      "Episode 882/6000, Total Reward: 82, Epsilon: 0.213\n",
      "Episode 883/6000, Total Reward: -76, Epsilon: 0.213\n",
      "Episode 884/6000, Total Reward: 159, Epsilon: 0.212\n",
      "Episode 885/6000, Total Reward: 80, Epsilon: 0.212\n",
      "Episode 886/6000, Total Reward: 156, Epsilon: 0.211\n",
      "Episode 887/6000, Total Reward: 3, Epsilon: 0.210\n",
      "Episode 888/6000, Total Reward: 78, Epsilon: 0.210\n",
      "Episode 889/6000, Total Reward: 386, Epsilon: 0.208\n",
      "Episode 890/6000, Total Reward: 309, Epsilon: 0.207\n",
      "Updated target model.\n",
      "Episode 891/6000, Total Reward: -77, Epsilon: 0.206\n",
      "Episode 892/6000, Total Reward: 82, Epsilon: 0.205\n",
      "Episode 893/6000, Total Reward: 79, Epsilon: 0.205\n",
      "Episode 894/6000, Total Reward: 79, Epsilon: 0.204\n",
      "Episode 895/6000, Total Reward: -76, Epsilon: 0.204\n",
      "Episode 896/6000, Total Reward: -75, Epsilon: 0.204\n",
      "Episode 897/6000, Total Reward: 77, Epsilon: 0.203\n",
      "Episode 898/6000, Total Reward: 234, Epsilon: 0.202\n",
      "Episode 899/6000, Total Reward: -75, Epsilon: 0.202\n",
      "Episode 900/6000, Total Reward: 80, Epsilon: 0.201\n",
      "Updated target model.\n",
      "Episode 901/6000, Total Reward: -75, Epsilon: 0.200\n",
      "Episode 902/6000, Total Reward: -73, Epsilon: 0.200\n",
      "Episode 903/6000, Total Reward: 158, Epsilon: 0.199\n",
      "Episode 904/6000, Total Reward: 313, Epsilon: 0.198\n",
      "Episode 905/6000, Total Reward: -75, Epsilon: 0.197\n",
      "Episode 906/6000, Total Reward: 80, Epsilon: 0.197\n",
      "Episode 907/6000, Total Reward: -75, Epsilon: 0.196\n",
      "Episode 908/6000, Total Reward: 77, Epsilon: 0.196\n",
      "Episode 909/6000, Total Reward: 232, Epsilon: 0.195\n",
      "Episode 910/6000, Total Reward: 2, Epsilon: 0.195\n",
      "Updated target model.\n",
      "Episode 911/6000, Total Reward: 233, Epsilon: 0.194\n",
      "Episode 912/6000, Total Reward: 1, Epsilon: 0.193\n",
      "Episode 913/6000, Total Reward: -75, Epsilon: 0.193\n",
      "Episode 914/6000, Total Reward: 158, Epsilon: 0.192\n",
      "Episode 915/6000, Total Reward: -75, Epsilon: 0.192\n",
      "Episode 916/6000, Total Reward: -74, Epsilon: 0.191\n",
      "Episode 917/6000, Total Reward: 155, Epsilon: 0.190\n",
      "Episode 918/6000, Total Reward: 310, Epsilon: 0.189\n",
      "Episode 919/6000, Total Reward: 236, Epsilon: 0.187\n",
      "Episode 920/6000, Total Reward: 157, Epsilon: 0.185\n",
      "Updated target model.\n",
      "Episode 921/6000, Total Reward: -75, Epsilon: 0.185\n",
      "Episode 922/6000, Total Reward: 2, Epsilon: 0.183\n",
      "Episode 923/6000, Total Reward: 79, Epsilon: 0.183\n",
      "Episode 924/6000, Total Reward: 157, Epsilon: 0.182\n",
      "Episode 925/6000, Total Reward: -75, Epsilon: 0.182\n",
      "Episode 926/6000, Total Reward: 3, Epsilon: 0.181\n",
      "Episode 927/6000, Total Reward: -76, Epsilon: 0.181\n",
      "Episode 928/6000, Total Reward: -74, Epsilon: 0.181\n",
      "Episode 929/6000, Total Reward: -75, Epsilon: 0.180\n",
      "Episode 930/6000, Total Reward: 234, Epsilon: 0.180\n",
      "Updated target model.\n",
      "Episode 931/6000, Total Reward: 156, Epsilon: 0.179\n",
      "Episode 932/6000, Total Reward: 0, Epsilon: 0.177\n",
      "Episode 933/6000, Total Reward: -1, Epsilon: 0.176\n",
      "Episode 934/6000, Total Reward: -76, Epsilon: 0.176\n",
      "Episode 935/6000, Total Reward: 155, Epsilon: 0.175\n",
      "Episode 936/6000, Total Reward: -75, Epsilon: 0.175\n",
      "Episode 937/6000, Total Reward: -76, Epsilon: 0.175\n",
      "Episode 938/6000, Total Reward: 160, Epsilon: 0.174\n",
      "Episode 939/6000, Total Reward: 233, Epsilon: 0.172\n",
      "Episode 940/6000, Total Reward: 158, Epsilon: 0.170\n",
      "Updated target model.\n",
      "Episode 941/6000, Total Reward: 3, Epsilon: 0.170\n",
      "Episode 942/6000, Total Reward: 77, Epsilon: 0.169\n",
      "Episode 943/6000, Total Reward: -75, Epsilon: 0.169\n",
      "Episode 944/6000, Total Reward: 305, Epsilon: 0.169\n",
      "Episode 945/6000, Total Reward: -74, Epsilon: 0.169\n",
      "Episode 946/6000, Total Reward: 235, Epsilon: 0.167\n",
      "Episode 947/6000, Total Reward: -75, Epsilon: 0.167\n",
      "Episode 948/6000, Total Reward: -75, Epsilon: 0.166\n",
      "Episode 949/6000, Total Reward: 153, Epsilon: 0.166\n",
      "Episode 950/6000, Total Reward: 235, Epsilon: 0.165\n",
      "Updated target model.\n",
      "Episode 951/6000, Total Reward: 156, Epsilon: 0.164\n",
      "Episode 952/6000, Total Reward: 79, Epsilon: 0.163\n",
      "Episode 953/6000, Total Reward: -75, Epsilon: 0.163\n",
      "Episode 954/6000, Total Reward: -76, Epsilon: 0.163\n",
      "Episode 955/6000, Total Reward: 156, Epsilon: 0.163\n",
      "Episode 956/6000, Total Reward: 4, Epsilon: 0.162\n",
      "Episode 957/6000, Total Reward: 153, Epsilon: 0.161\n",
      "Episode 958/6000, Total Reward: 157, Epsilon: 0.161\n",
      "Episode 959/6000, Total Reward: 4, Epsilon: 0.160\n",
      "Episode 960/6000, Total Reward: -74, Epsilon: 0.160\n",
      "Updated target model.\n",
      "Episode 961/6000, Total Reward: 153, Epsilon: 0.159\n",
      "Episode 962/6000, Total Reward: -76, Epsilon: 0.159\n",
      "Episode 963/6000, Total Reward: 2, Epsilon: 0.159\n",
      "Episode 964/6000, Total Reward: -75, Epsilon: 0.158\n",
      "Episode 965/6000, Total Reward: -73, Epsilon: 0.158\n",
      "Episode 966/6000, Total Reward: -76, Epsilon: 0.158\n",
      "Episode 967/6000, Total Reward: 79, Epsilon: 0.157\n",
      "Episode 968/6000, Total Reward: 79, Epsilon: 0.156\n",
      "Episode 969/6000, Total Reward: -75, Epsilon: 0.156\n",
      "Episode 970/6000, Total Reward: 153, Epsilon: 0.156\n",
      "Updated target model.\n",
      "Episode 971/6000, Total Reward: 157, Epsilon: 0.152\n",
      "Episode 972/6000, Total Reward: 80, Epsilon: 0.151\n",
      "Episode 973/6000, Total Reward: -75, Epsilon: 0.151\n",
      "Episode 974/6000, Total Reward: 389, Epsilon: 0.150\n",
      "Episode 975/6000, Total Reward: 76, Epsilon: 0.150\n",
      "Episode 976/6000, Total Reward: -75, Epsilon: 0.150\n",
      "Episode 977/6000, Total Reward: 2, Epsilon: 0.149\n",
      "Episode 978/6000, Total Reward: -75, Epsilon: 0.149\n",
      "Episode 979/6000, Total Reward: 156, Epsilon: 0.149\n",
      "Episode 980/6000, Total Reward: -75, Epsilon: 0.149\n",
      "Updated target model.\n",
      "Episode 981/6000, Total Reward: -76, Epsilon: 0.149\n",
      "Episode 982/6000, Total Reward: 4, Epsilon: 0.147\n",
      "Episode 983/6000, Total Reward: -76, Epsilon: 0.147\n",
      "Episode 984/6000, Total Reward: 1, Epsilon: 0.147\n",
      "Episode 985/6000, Total Reward: 157, Epsilon: 0.146\n",
      "Episode 986/6000, Total Reward: -76, Epsilon: 0.146\n",
      "Episode 987/6000, Total Reward: -75, Epsilon: 0.146\n",
      "Episode 988/6000, Total Reward: 1, Epsilon: 0.146\n",
      "Episode 989/6000, Total Reward: 159, Epsilon: 0.145\n",
      "Episode 990/6000, Total Reward: 1, Epsilon: 0.145\n",
      "Updated target model.\n",
      "Episode 991/6000, Total Reward: -74, Epsilon: 0.145\n",
      "Episode 992/6000, Total Reward: 233, Epsilon: 0.143\n",
      "Episode 993/6000, Total Reward: -75, Epsilon: 0.143\n",
      "Episode 994/6000, Total Reward: -76, Epsilon: 0.143\n",
      "Episode 995/6000, Total Reward: -75, Epsilon: 0.143\n",
      "Episode 996/6000, Total Reward: 78, Epsilon: 0.143\n",
      "Episode 997/6000, Total Reward: 312, Epsilon: 0.142\n",
      "Episode 998/6000, Total Reward: 158, Epsilon: 0.141\n",
      "Episode 999/6000, Total Reward: 307, Epsilon: 0.140\n",
      "Episode 1000/6000, Total Reward: 5, Epsilon: 0.140\n",
      "Updated target model.\n",
      "Episode 1001/6000, Total Reward: 77, Epsilon: 0.139\n",
      "Episode 1002/6000, Total Reward: 79, Epsilon: 0.139\n",
      "Episode 1003/6000, Total Reward: -75, Epsilon: 0.139\n",
      "Episode 1004/6000, Total Reward: -76, Epsilon: 0.139\n",
      "Episode 1005/6000, Total Reward: 158, Epsilon: 0.138\n",
      "Episode 1006/6000, Total Reward: 387, Epsilon: 0.137\n",
      "Episode 1007/6000, Total Reward: 2, Epsilon: 0.136\n",
      "Episode 1008/6000, Total Reward: 310, Epsilon: 0.135\n",
      "Episode 1009/6000, Total Reward: 3, Epsilon: 0.135\n",
      "Episode 1010/6000, Total Reward: 235, Epsilon: 0.134\n",
      "Updated target model.\n",
      "Episode 1011/6000, Total Reward: 155, Epsilon: 0.133\n",
      "Episode 1012/6000, Total Reward: 79, Epsilon: 0.133\n",
      "Episode 1013/6000, Total Reward: 311, Epsilon: 0.132\n",
      "Episode 1014/6000, Total Reward: -73, Epsilon: 0.132\n",
      "Episode 1015/6000, Total Reward: -75, Epsilon: 0.132\n",
      "Episode 1016/6000, Total Reward: -75, Epsilon: 0.132\n",
      "Episode 1017/6000, Total Reward: 81, Epsilon: 0.131\n",
      "Episode 1018/6000, Total Reward: 311, Epsilon: 0.130\n",
      "Episode 1019/6000, Total Reward: -76, Epsilon: 0.130\n",
      "Episode 1020/6000, Total Reward: -76, Epsilon: 0.130\n",
      "Updated target model.\n",
      "Episode 1021/6000, Total Reward: -75, Epsilon: 0.130\n",
      "Episode 1022/6000, Total Reward: 232, Epsilon: 0.129\n",
      "Episode 1023/6000, Total Reward: -76, Epsilon: 0.129\n",
      "Episode 1024/6000, Total Reward: 82, Epsilon: 0.129\n",
      "Episode 1025/6000, Total Reward: 83, Epsilon: 0.128\n",
      "Episode 1026/6000, Total Reward: 77, Epsilon: 0.128\n",
      "Episode 1027/6000, Total Reward: 465, Epsilon: 0.126\n",
      "Episode 1028/6000, Total Reward: 80, Epsilon: 0.126\n",
      "Episode 1029/6000, Total Reward: -75, Epsilon: 0.126\n",
      "Episode 1030/6000, Total Reward: 2, Epsilon: 0.126\n",
      "Updated target model.\n",
      "Episode 1031/6000, Total Reward: 231, Epsilon: 0.125\n",
      "Episode 1032/6000, Total Reward: -75, Epsilon: 0.125\n",
      "Episode 1033/6000, Total Reward: 2, Epsilon: 0.125\n",
      "Episode 1034/6000, Total Reward: 233, Epsilon: 0.124\n",
      "Episode 1035/6000, Total Reward: 156, Epsilon: 0.124\n",
      "Episode 1036/6000, Total Reward: 156, Epsilon: 0.123\n",
      "Episode 1037/6000, Total Reward: 80, Epsilon: 0.123\n",
      "Episode 1038/6000, Total Reward: 80, Epsilon: 0.123\n",
      "Episode 1039/6000, Total Reward: -75, Epsilon: 0.122\n",
      "Episode 1040/6000, Total Reward: 78, Epsilon: 0.122\n",
      "Updated target model.\n",
      "Episode 1041/6000, Total Reward: 232, Epsilon: 0.122\n",
      "Episode 1042/6000, Total Reward: 155, Epsilon: 0.121\n",
      "Episode 1043/6000, Total Reward: -77, Epsilon: 0.121\n",
      "Episode 1044/6000, Total Reward: 231, Epsilon: 0.120\n",
      "Episode 1045/6000, Total Reward: 314, Epsilon: 0.115\n",
      "Episode 1046/6000, Total Reward: -75, Epsilon: 0.115\n",
      "Episode 1047/6000, Total Reward: 308, Epsilon: 0.114\n",
      "Episode 1048/6000, Total Reward: 82, Epsilon: 0.114\n",
      "Episode 1049/6000, Total Reward: -75, Epsilon: 0.114\n",
      "Episode 1050/6000, Total Reward: 1, Epsilon: 0.113\n",
      "Updated target model.\n",
      "Episode 1051/6000, Total Reward: -75, Epsilon: 0.113\n",
      "Episode 1052/6000, Total Reward: 157, Epsilon: 0.113\n",
      "Episode 1053/6000, Total Reward: 78, Epsilon: 0.112\n",
      "Episode 1054/6000, Total Reward: 80, Epsilon: 0.112\n",
      "Episode 1055/6000, Total Reward: 155, Epsilon: 0.111\n",
      "Episode 1056/6000, Total Reward: -77, Epsilon: 0.111\n",
      "Episode 1057/6000, Total Reward: 1, Epsilon: 0.111\n",
      "Episode 1058/6000, Total Reward: 157, Epsilon: 0.111\n",
      "Episode 1059/6000, Total Reward: -75, Epsilon: 0.111\n",
      "Episode 1060/6000, Total Reward: -76, Epsilon: 0.110\n",
      "Updated target model.\n",
      "Episode 1061/6000, Total Reward: 158, Epsilon: 0.110\n",
      "Episode 1062/6000, Total Reward: 159, Epsilon: 0.109\n",
      "Episode 1063/6000, Total Reward: -2, Epsilon: 0.109\n",
      "Episode 1064/6000, Total Reward: 81, Epsilon: 0.108\n",
      "Episode 1065/6000, Total Reward: 3, Epsilon: 0.108\n",
      "Episode 1066/6000, Total Reward: 77, Epsilon: 0.108\n",
      "Episode 1067/6000, Total Reward: -76, Epsilon: 0.108\n",
      "Episode 1068/6000, Total Reward: 156, Epsilon: 0.107\n",
      "Episode 1069/6000, Total Reward: 77, Epsilon: 0.107\n",
      "Episode 1070/6000, Total Reward: -76, Epsilon: 0.107\n",
      "Updated target model.\n",
      "Episode 1071/6000, Total Reward: 78, Epsilon: 0.106\n",
      "Episode 1072/6000, Total Reward: 158, Epsilon: 0.106\n",
      "Episode 1073/6000, Total Reward: 5, Epsilon: 0.105\n",
      "Episode 1074/6000, Total Reward: 80, Epsilon: 0.105\n",
      "Episode 1075/6000, Total Reward: 1, Epsilon: 0.104\n",
      "Episode 1076/6000, Total Reward: 3, Epsilon: 0.104\n",
      "Episode 1077/6000, Total Reward: 79, Epsilon: 0.104\n",
      "Episode 1078/6000, Total Reward: 232, Epsilon: 0.103\n",
      "Episode 1079/6000, Total Reward: 159, Epsilon: 0.103\n",
      "Episode 1080/6000, Total Reward: -76, Epsilon: 0.103\n",
      "Updated target model.\n",
      "Episode 1081/6000, Total Reward: 157, Epsilon: 0.102\n",
      "Episode 1082/6000, Total Reward: 237, Epsilon: 0.101\n",
      "Episode 1083/6000, Total Reward: 4, Epsilon: 0.101\n",
      "Episode 1084/6000, Total Reward: 3, Epsilon: 0.100\n",
      "Episode 1085/6000, Total Reward: -76, Epsilon: 0.100\n",
      "Episode 1086/6000, Total Reward: 4, Epsilon: 0.097\n",
      "Episode 1087/6000, Total Reward: -1, Epsilon: 0.096\n",
      "Episode 1088/6000, Total Reward: -73, Epsilon: 0.096\n",
      "Episode 1089/6000, Total Reward: -76, Epsilon: 0.096\n",
      "Episode 1090/6000, Total Reward: 78, Epsilon: 0.096\n",
      "Updated target model.\n",
      "Episode 1091/6000, Total Reward: 232, Epsilon: 0.095\n",
      "Episode 1092/6000, Total Reward: -75, Epsilon: 0.095\n",
      "Episode 1093/6000, Total Reward: 3, Epsilon: 0.093\n",
      "Episode 1094/6000, Total Reward: -77, Epsilon: 0.093\n",
      "Episode 1095/6000, Total Reward: 236, Epsilon: 0.093\n",
      "Episode 1096/6000, Total Reward: -75, Epsilon: 0.093\n",
      "Episode 1097/6000, Total Reward: 158, Epsilon: 0.092\n",
      "Episode 1098/6000, Total Reward: -74, Epsilon: 0.092\n",
      "Episode 1099/6000, Total Reward: -75, Epsilon: 0.092\n",
      "Episode 1100/6000, Total Reward: 236, Epsilon: 0.091\n",
      "Updated target model.\n",
      "Episode 1101/6000, Total Reward: 231, Epsilon: 0.091\n",
      "Episode 1102/6000, Total Reward: 80, Epsilon: 0.090\n",
      "Episode 1103/6000, Total Reward: 160, Epsilon: 0.090\n",
      "Episode 1104/6000, Total Reward: 235, Epsilon: 0.089\n",
      "Episode 1105/6000, Total Reward: -76, Epsilon: 0.089\n",
      "Episode 1106/6000, Total Reward: 155, Epsilon: 0.087\n",
      "Episode 1107/6000, Total Reward: 156, Epsilon: 0.087\n",
      "Episode 1108/6000, Total Reward: -77, Epsilon: 0.087\n",
      "Episode 1109/6000, Total Reward: 155, Epsilon: 0.086\n",
      "Episode 1110/6000, Total Reward: -75, Epsilon: 0.086\n",
      "Updated target model.\n",
      "Episode 1111/6000, Total Reward: 156, Epsilon: 0.086\n",
      "Episode 1112/6000, Total Reward: 80, Epsilon: 0.086\n",
      "Episode 1113/6000, Total Reward: 4, Epsilon: 0.085\n",
      "Episode 1114/6000, Total Reward: 5, Epsilon: 0.085\n",
      "Episode 1115/6000, Total Reward: 312, Epsilon: 0.084\n",
      "Episode 1116/6000, Total Reward: 81, Epsilon: 0.084\n",
      "Episode 1117/6000, Total Reward: 155, Epsilon: 0.084\n",
      "Episode 1118/6000, Total Reward: 232, Epsilon: 0.083\n",
      "Episode 1119/6000, Total Reward: 312, Epsilon: 0.083\n",
      "Episode 1120/6000, Total Reward: 235, Epsilon: 0.082\n",
      "Updated target model.\n",
      "Episode 1121/6000, Total Reward: 81, Epsilon: 0.081\n",
      "Episode 1122/6000, Total Reward: 1, Epsilon: 0.081\n",
      "Episode 1123/6000, Total Reward: -75, Epsilon: 0.081\n",
      "Episode 1124/6000, Total Reward: -75, Epsilon: 0.081\n",
      "Episode 1125/6000, Total Reward: -76, Epsilon: 0.081\n",
      "Episode 1126/6000, Total Reward: 155, Epsilon: 0.080\n",
      "Episode 1127/6000, Total Reward: 80, Epsilon: 0.080\n",
      "Episode 1128/6000, Total Reward: 232, Epsilon: 0.080\n",
      "Episode 1129/6000, Total Reward: -75, Epsilon: 0.080\n",
      "Episode 1130/6000, Total Reward: -74, Epsilon: 0.080\n",
      "Updated target model.\n",
      "Episode 1131/6000, Total Reward: 153, Epsilon: 0.079\n",
      "Episode 1132/6000, Total Reward: 156, Epsilon: 0.079\n",
      "Episode 1133/6000, Total Reward: -74, Epsilon: 0.079\n",
      "Episode 1134/6000, Total Reward: 1, Epsilon: 0.079\n",
      "Episode 1135/6000, Total Reward: -75, Epsilon: 0.079\n",
      "Episode 1136/6000, Total Reward: 233, Epsilon: 0.078\n",
      "Episode 1137/6000, Total Reward: -74, Epsilon: 0.078\n",
      "Episode 1138/6000, Total Reward: 159, Epsilon: 0.077\n",
      "Episode 1139/6000, Total Reward: 79, Epsilon: 0.077\n",
      "Episode 1140/6000, Total Reward: 156, Epsilon: 0.077\n",
      "Updated target model.\n",
      "Episode 1141/6000, Total Reward: 3, Epsilon: 0.077\n",
      "Episode 1142/6000, Total Reward: -76, Epsilon: 0.077\n",
      "Episode 1143/6000, Total Reward: 310, Epsilon: 0.076\n",
      "Episode 1144/6000, Total Reward: -76, Epsilon: 0.076\n",
      "Episode 1145/6000, Total Reward: -74, Epsilon: 0.076\n",
      "Episode 1146/6000, Total Reward: 2, Epsilon: 0.076\n",
      "Episode 1147/6000, Total Reward: -74, Epsilon: 0.076\n",
      "Episode 1148/6000, Total Reward: 233, Epsilon: 0.075\n",
      "Episode 1149/6000, Total Reward: 307, Epsilon: 0.075\n",
      "Episode 1150/6000, Total Reward: 235, Epsilon: 0.074\n",
      "Updated target model.\n",
      "Episode 1151/6000, Total Reward: 156, Epsilon: 0.074\n",
      "Episode 1152/6000, Total Reward: -75, Epsilon: 0.074\n",
      "Episode 1153/6000, Total Reward: 233, Epsilon: 0.073\n",
      "Episode 1154/6000, Total Reward: 311, Epsilon: 0.073\n",
      "Episode 1155/6000, Total Reward: 240, Epsilon: 0.072\n",
      "Episode 1156/6000, Total Reward: 156, Epsilon: 0.072\n",
      "Episode 1157/6000, Total Reward: 79, Epsilon: 0.071\n",
      "Episode 1158/6000, Total Reward: 234, Epsilon: 0.071\n",
      "Episode 1159/6000, Total Reward: -75, Epsilon: 0.071\n",
      "Episode 1160/6000, Total Reward: 384, Epsilon: 0.070\n",
      "Updated target model.\n",
      "Episode 1161/6000, Total Reward: 78, Epsilon: 0.070\n",
      "Episode 1162/6000, Total Reward: 157, Epsilon: 0.069\n",
      "Episode 1163/6000, Total Reward: 235, Epsilon: 0.069\n",
      "Episode 1164/6000, Total Reward: 79, Epsilon: 0.068\n",
      "Episode 1165/6000, Total Reward: 78, Epsilon: 0.067\n",
      "Episode 1166/6000, Total Reward: 156, Epsilon: 0.066\n",
      "Episode 1167/6000, Total Reward: -75, Epsilon: 0.066\n",
      "Episode 1168/6000, Total Reward: -73, Epsilon: 0.066\n",
      "Episode 1169/6000, Total Reward: 156, Epsilon: 0.066\n",
      "Episode 1170/6000, Total Reward: 235, Epsilon: 0.066\n",
      "Updated target model.\n",
      "Episode 1171/6000, Total Reward: 79, Epsilon: 0.065\n",
      "Episode 1172/6000, Total Reward: -75, Epsilon: 0.065\n",
      "Episode 1173/6000, Total Reward: -76, Epsilon: 0.065\n",
      "Episode 1174/6000, Total Reward: 156, Epsilon: 0.065\n",
      "Episode 1175/6000, Total Reward: -75, Epsilon: 0.065\n",
      "Episode 1176/6000, Total Reward: 156, Epsilon: 0.065\n",
      "Episode 1177/6000, Total Reward: -76, Epsilon: 0.065\n",
      "Episode 1178/6000, Total Reward: 310, Epsilon: 0.064\n",
      "Episode 1179/6000, Total Reward: -75, Epsilon: 0.064\n",
      "Episode 1180/6000, Total Reward: 158, Epsilon: 0.064\n",
      "Updated target model.\n",
      "Episode 1181/6000, Total Reward: -75, Epsilon: 0.064\n",
      "Episode 1182/6000, Total Reward: -75, Epsilon: 0.064\n",
      "Episode 1183/6000, Total Reward: -75, Epsilon: 0.064\n",
      "Episode 1184/6000, Total Reward: 235, Epsilon: 0.063\n",
      "Episode 1185/6000, Total Reward: -75, Epsilon: 0.063\n",
      "Episode 1186/6000, Total Reward: -75, Epsilon: 0.063\n",
      "Episode 1187/6000, Total Reward: 159, Epsilon: 0.063\n",
      "Episode 1188/6000, Total Reward: 81, Epsilon: 0.063\n",
      "Episode 1189/6000, Total Reward: 161, Epsilon: 0.062\n",
      "Episode 1190/6000, Total Reward: 154, Epsilon: 0.062\n",
      "Updated target model.\n",
      "Episode 1191/6000, Total Reward: 310, Epsilon: 0.062\n",
      "Episode 1192/6000, Total Reward: -75, Epsilon: 0.062\n",
      "Episode 1193/6000, Total Reward: 154, Epsilon: 0.061\n",
      "Episode 1194/6000, Total Reward: 388, Epsilon: 0.061\n",
      "Episode 1195/6000, Total Reward: -75, Epsilon: 0.061\n",
      "Episode 1196/6000, Total Reward: 4, Epsilon: 0.061\n",
      "Episode 1197/6000, Total Reward: -76, Epsilon: 0.061\n",
      "Episode 1198/6000, Total Reward: -74, Epsilon: 0.060\n",
      "Episode 1199/6000, Total Reward: 235, Epsilon: 0.060\n",
      "Episode 1200/6000, Total Reward: 156, Epsilon: 0.060\n",
      "Updated target model.\n",
      "Episode 1201/6000, Total Reward: 310, Epsilon: 0.059\n",
      "Episode 1202/6000, Total Reward: 236, Epsilon: 0.059\n",
      "Episode 1203/6000, Total Reward: 235, Epsilon: 0.058\n",
      "Episode 1204/6000, Total Reward: -76, Epsilon: 0.058\n",
      "Episode 1205/6000, Total Reward: -75, Epsilon: 0.058\n",
      "Episode 1206/6000, Total Reward: 158, Epsilon: 0.058\n",
      "Episode 1207/6000, Total Reward: -75, Epsilon: 0.058\n",
      "Episode 1208/6000, Total Reward: 155, Epsilon: 0.058\n",
      "Episode 1209/6000, Total Reward: -75, Epsilon: 0.058\n",
      "Episode 1210/6000, Total Reward: -77, Epsilon: 0.058\n",
      "Updated target model.\n",
      "Episode 1211/6000, Total Reward: 156, Epsilon: 0.057\n",
      "Episode 1212/6000, Total Reward: 158, Epsilon: 0.057\n",
      "Episode 1213/6000, Total Reward: 78, Epsilon: 0.057\n",
      "Episode 1214/6000, Total Reward: -75, Epsilon: 0.057\n",
      "Episode 1215/6000, Total Reward: 156, Epsilon: 0.056\n",
      "Episode 1216/6000, Total Reward: 158, Epsilon: 0.056\n",
      "Episode 1217/6000, Total Reward: 160, Epsilon: 0.056\n",
      "Episode 1218/6000, Total Reward: 230, Epsilon: 0.056\n",
      "Episode 1219/6000, Total Reward: -75, Epsilon: 0.056\n",
      "Episode 1220/6000, Total Reward: 234, Epsilon: 0.055\n",
      "Updated target model.\n",
      "Episode 1221/6000, Total Reward: -75, Epsilon: 0.055\n",
      "Episode 1222/6000, Total Reward: 158, Epsilon: 0.055\n",
      "Episode 1223/6000, Total Reward: 1, Epsilon: 0.055\n",
      "Episode 1224/6000, Total Reward: 3, Epsilon: 0.055\n",
      "Episode 1225/6000, Total Reward: 384, Epsilon: 0.054\n",
      "Episode 1226/6000, Total Reward: 161, Epsilon: 0.054\n",
      "Episode 1227/6000, Total Reward: 78, Epsilon: 0.054\n",
      "Episode 1228/6000, Total Reward: 230, Epsilon: 0.054\n",
      "Episode 1229/6000, Total Reward: 159, Epsilon: 0.053\n",
      "Episode 1230/6000, Total Reward: 157, Epsilon: 0.053\n",
      "Updated target model.\n",
      "Episode 1231/6000, Total Reward: 233, Epsilon: 0.053\n",
      "Episode 1232/6000, Total Reward: 159, Epsilon: 0.052\n",
      "Episode 1233/6000, Total Reward: 81, Epsilon: 0.052\n",
      "Episode 1234/6000, Total Reward: -75, Epsilon: 0.052\n",
      "Episode 1235/6000, Total Reward: 309, Epsilon: 0.052\n",
      "Episode 1236/6000, Total Reward: 155, Epsilon: 0.052\n",
      "Episode 1237/6000, Total Reward: 232, Epsilon: 0.051\n",
      "Episode 1238/6000, Total Reward: 234, Epsilon: 0.051\n",
      "Episode 1239/6000, Total Reward: 387, Epsilon: 0.051\n",
      "Episode 1240/6000, Total Reward: -75, Epsilon: 0.051\n",
      "Updated target model.\n",
      "Episode 1241/6000, Total Reward: 310, Epsilon: 0.050\n",
      "Episode 1242/6000, Total Reward: 79, Epsilon: 0.050\n",
      "Episode 1243/6000, Total Reward: -75, Epsilon: 0.050\n",
      "Episode 1244/6000, Total Reward: 156, Epsilon: 0.050\n",
      "Episode 1245/6000, Total Reward: 238, Epsilon: 0.050\n",
      "Episode 1246/6000, Total Reward: -75, Epsilon: 0.050\n",
      "Episode 1247/6000, Total Reward: 235, Epsilon: 0.049\n",
      "Episode 1248/6000, Total Reward: 80, Epsilon: 0.048\n",
      "Episode 1249/6000, Total Reward: 235, Epsilon: 0.048\n",
      "Episode 1250/6000, Total Reward: 81, Epsilon: 0.047\n",
      "Updated target model.\n",
      "Episode 1251/6000, Total Reward: -76, Epsilon: 0.047\n",
      "Episode 1252/6000, Total Reward: -75, Epsilon: 0.047\n",
      "Episode 1253/6000, Total Reward: 79, Epsilon: 0.046\n",
      "Episode 1254/6000, Total Reward: 81, Epsilon: 0.046\n",
      "Episode 1255/6000, Total Reward: 156, Epsilon: 0.046\n",
      "Episode 1256/6000, Total Reward: -75, Epsilon: 0.046\n",
      "Episode 1257/6000, Total Reward: -76, Epsilon: 0.046\n",
      "Episode 1258/6000, Total Reward: 157, Epsilon: 0.046\n",
      "Episode 1259/6000, Total Reward: 232, Epsilon: 0.045\n",
      "Episode 1260/6000, Total Reward: 158, Epsilon: 0.045\n",
      "Updated target model.\n",
      "Episode 1261/6000, Total Reward: -75, Epsilon: 0.045\n",
      "Episode 1262/6000, Total Reward: -75, Epsilon: 0.045\n",
      "Episode 1263/6000, Total Reward: 233, Epsilon: 0.045\n",
      "Episode 1264/6000, Total Reward: -75, Epsilon: 0.045\n",
      "Episode 1265/6000, Total Reward: 158, Epsilon: 0.044\n",
      "Episode 1266/6000, Total Reward: 158, Epsilon: 0.044\n",
      "Episode 1267/6000, Total Reward: -73, Epsilon: 0.044\n",
      "Episode 1268/6000, Total Reward: 309, Epsilon: 0.044\n",
      "Episode 1269/6000, Total Reward: 384, Epsilon: 0.043\n",
      "Episode 1270/6000, Total Reward: 77, Epsilon: 0.043\n",
      "Updated target model.\n",
      "Episode 1271/6000, Total Reward: 309, Epsilon: 0.042\n",
      "Episode 1272/6000, Total Reward: 2, Epsilon: 0.042\n",
      "Episode 1273/6000, Total Reward: 156, Epsilon: 0.042\n",
      "Episode 1274/6000, Total Reward: 82, Epsilon: 0.042\n",
      "Episode 1275/6000, Total Reward: 232, Epsilon: 0.041\n",
      "Episode 1276/6000, Total Reward: -75, Epsilon: 0.041\n",
      "Episode 1277/6000, Total Reward: 80, Epsilon: 0.041\n",
      "Episode 1278/6000, Total Reward: 310, Epsilon: 0.041\n",
      "Episode 1279/6000, Total Reward: 160, Epsilon: 0.040\n",
      "Episode 1280/6000, Total Reward: -74, Epsilon: 0.040\n",
      "Updated target model.\n",
      "Episode 1281/6000, Total Reward: 156, Epsilon: 0.040\n",
      "Episode 1282/6000, Total Reward: 388, Epsilon: 0.039\n",
      "Episode 1283/6000, Total Reward: 155, Epsilon: 0.039\n",
      "Episode 1284/6000, Total Reward: 232, Epsilon: 0.039\n",
      "Episode 1285/6000, Total Reward: 156, Epsilon: 0.039\n",
      "Episode 1286/6000, Total Reward: 154, Epsilon: 0.039\n",
      "Episode 1287/6000, Total Reward: 157, Epsilon: 0.038\n",
      "Episode 1288/6000, Total Reward: 154, Epsilon: 0.038\n",
      "Episode 1289/6000, Total Reward: 3, Epsilon: 0.038\n",
      "Episode 1290/6000, Total Reward: 81, Epsilon: 0.038\n",
      "Updated target model.\n",
      "Episode 1291/6000, Total Reward: 234, Epsilon: 0.038\n",
      "Episode 1292/6000, Total Reward: -75, Epsilon: 0.038\n",
      "Episode 1293/6000, Total Reward: 232, Epsilon: 0.037\n",
      "Episode 1294/6000, Total Reward: -75, Epsilon: 0.037\n",
      "Episode 1295/6000, Total Reward: 311, Epsilon: 0.037\n",
      "Episode 1296/6000, Total Reward: 309, Epsilon: 0.037\n",
      "Episode 1297/6000, Total Reward: 2, Epsilon: 0.037\n",
      "Episode 1298/6000, Total Reward: 154, Epsilon: 0.037\n",
      "Episode 1299/6000, Total Reward: 159, Epsilon: 0.036\n",
      "Episode 1300/6000, Total Reward: 155, Epsilon: 0.036\n",
      "Updated target model.\n",
      "Episode 1301/6000, Total Reward: -76, Epsilon: 0.036\n",
      "Episode 1302/6000, Total Reward: 234, Epsilon: 0.036\n",
      "Episode 1303/6000, Total Reward: 2, Epsilon: 0.036\n",
      "Episode 1304/6000, Total Reward: 306, Epsilon: 0.036\n",
      "Episode 1305/6000, Total Reward: 78, Epsilon: 0.036\n",
      "Episode 1306/6000, Total Reward: 157, Epsilon: 0.035\n",
      "Episode 1307/6000, Total Reward: 3, Epsilon: 0.035\n",
      "Episode 1308/6000, Total Reward: 78, Epsilon: 0.035\n",
      "Episode 1309/6000, Total Reward: 389, Epsilon: 0.035\n",
      "Episode 1310/6000, Total Reward: 308, Epsilon: 0.035\n",
      "Updated target model.\n",
      "Episode 1311/6000, Total Reward: 155, Epsilon: 0.034\n",
      "Episode 1312/6000, Total Reward: 79, Epsilon: 0.034\n",
      "Episode 1313/6000, Total Reward: 155, Epsilon: 0.033\n",
      "Episode 1314/6000, Total Reward: 77, Epsilon: 0.033\n",
      "Episode 1315/6000, Total Reward: 156, Epsilon: 0.033\n",
      "Episode 1316/6000, Total Reward: 156, Epsilon: 0.032\n",
      "Episode 1317/6000, Total Reward: -75, Epsilon: 0.031\n",
      "Episode 1318/6000, Total Reward: 156, Epsilon: 0.031\n",
      "Episode 1319/6000, Total Reward: -76, Epsilon: 0.031\n",
      "Episode 1320/6000, Total Reward: 236, Epsilon: 0.031\n",
      "Updated target model.\n",
      "Episode 1321/6000, Total Reward: 156, Epsilon: 0.031\n",
      "Episode 1322/6000, Total Reward: 78, Epsilon: 0.031\n",
      "Episode 1323/6000, Total Reward: 313, Epsilon: 0.030\n",
      "Episode 1324/6000, Total Reward: -75, Epsilon: 0.030\n",
      "Episode 1325/6000, Total Reward: -75, Epsilon: 0.030\n",
      "Episode 1326/6000, Total Reward: 158, Epsilon: 0.030\n",
      "Episode 1327/6000, Total Reward: 308, Epsilon: 0.030\n",
      "Episode 1328/6000, Total Reward: 78, Epsilon: 0.030\n",
      "Episode 1329/6000, Total Reward: 314, Epsilon: 0.029\n",
      "Episode 1330/6000, Total Reward: 77, Epsilon: 0.029\n",
      "Updated target model.\n",
      "Episode 1331/6000, Total Reward: -75, Epsilon: 0.029\n",
      "Episode 1332/6000, Total Reward: -76, Epsilon: 0.029\n",
      "Episode 1333/6000, Total Reward: -75, Epsilon: 0.029\n",
      "Episode 1334/6000, Total Reward: -75, Epsilon: 0.029\n",
      "Episode 1335/6000, Total Reward: 236, Epsilon: 0.029\n",
      "Episode 1336/6000, Total Reward: 153, Epsilon: 0.029\n",
      "Episode 1337/6000, Total Reward: -75, Epsilon: 0.029\n",
      "Episode 1338/6000, Total Reward: 312, Epsilon: 0.029\n",
      "Episode 1339/6000, Total Reward: 156, Epsilon: 0.028\n",
      "Episode 1340/6000, Total Reward: 308, Epsilon: 0.028\n",
      "Updated target model.\n",
      "Episode 1341/6000, Total Reward: 307, Epsilon: 0.028\n",
      "Episode 1342/6000, Total Reward: -75, Epsilon: 0.028\n",
      "Episode 1343/6000, Total Reward: 154, Epsilon: 0.028\n",
      "Episode 1344/6000, Total Reward: 237, Epsilon: 0.028\n",
      "Episode 1345/6000, Total Reward: 155, Epsilon: 0.028\n",
      "Episode 1346/6000, Total Reward: 232, Epsilon: 0.027\n",
      "Episode 1347/6000, Total Reward: 391, Epsilon: 0.027\n",
      "Episode 1348/6000, Total Reward: 309, Epsilon: 0.027\n",
      "Episode 1349/6000, Total Reward: 80, Epsilon: 0.027\n",
      "Episode 1350/6000, Total Reward: -75, Epsilon: 0.027\n",
      "Updated target model.\n",
      "Episode 1351/6000, Total Reward: 79, Epsilon: 0.027\n",
      "Episode 1352/6000, Total Reward: -75, Epsilon: 0.027\n",
      "Episode 1353/6000, Total Reward: 80, Epsilon: 0.027\n",
      "Episode 1354/6000, Total Reward: 77, Epsilon: 0.026\n",
      "Episode 1355/6000, Total Reward: 310, Epsilon: 0.026\n",
      "Episode 1356/6000, Total Reward: 311, Epsilon: 0.026\n",
      "Episode 1357/6000, Total Reward: 309, Epsilon: 0.026\n",
      "Episode 1358/6000, Total Reward: 156, Epsilon: 0.025\n",
      "Episode 1359/6000, Total Reward: 155, Epsilon: 0.025\n",
      "Episode 1360/6000, Total Reward: 5, Epsilon: 0.025\n",
      "Updated target model.\n",
      "Episode 1361/6000, Total Reward: -75, Epsilon: 0.025\n",
      "Episode 1362/6000, Total Reward: 158, Epsilon: 0.025\n",
      "Episode 1363/6000, Total Reward: -75, Epsilon: 0.025\n",
      "Episode 1364/6000, Total Reward: 155, Epsilon: 0.025\n",
      "Episode 1365/6000, Total Reward: 235, Epsilon: 0.025\n",
      "Episode 1366/6000, Total Reward: 157, Epsilon: 0.025\n",
      "Episode 1367/6000, Total Reward: 154, Epsilon: 0.024\n",
      "Episode 1368/6000, Total Reward: 156, Epsilon: 0.024\n",
      "Episode 1369/6000, Total Reward: 234, Epsilon: 0.023\n",
      "Episode 1370/6000, Total Reward: 463, Epsilon: 0.023\n",
      "Updated target model.\n",
      "Episode 1371/6000, Total Reward: 78, Epsilon: 0.023\n",
      "Episode 1372/6000, Total Reward: 231, Epsilon: 0.023\n",
      "Episode 1373/6000, Total Reward: 233, Epsilon: 0.023\n",
      "Episode 1374/6000, Total Reward: -75, Epsilon: 0.023\n",
      "Episode 1375/6000, Total Reward: 311, Epsilon: 0.023\n",
      "Episode 1376/6000, Total Reward: -75, Epsilon: 0.023\n",
      "Episode 1377/6000, Total Reward: 231, Epsilon: 0.023\n",
      "Episode 1378/6000, Total Reward: 79, Epsilon: 0.023\n",
      "Episode 1379/6000, Total Reward: 154, Epsilon: 0.023\n",
      "Episode 1380/6000, Total Reward: 155, Epsilon: 0.022\n",
      "Updated target model.\n",
      "Episode 1381/6000, Total Reward: 155, Epsilon: 0.022\n",
      "Episode 1382/6000, Total Reward: 307, Epsilon: 0.022\n",
      "Episode 1383/6000, Total Reward: 1, Epsilon: 0.022\n",
      "Episode 1384/6000, Total Reward: 156, Epsilon: 0.022\n",
      "Episode 1385/6000, Total Reward: 158, Epsilon: 0.022\n",
      "Episode 1386/6000, Total Reward: 158, Epsilon: 0.022\n",
      "Episode 1387/6000, Total Reward: 386, Epsilon: 0.022\n",
      "Episode 1388/6000, Total Reward: 234, Epsilon: 0.022\n",
      "Episode 1389/6000, Total Reward: -75, Epsilon: 0.022\n",
      "Episode 1390/6000, Total Reward: 311, Epsilon: 0.021\n",
      "Updated target model.\n",
      "Episode 1391/6000, Total Reward: 161, Epsilon: 0.021\n",
      "Episode 1392/6000, Total Reward: 156, Epsilon: 0.021\n",
      "Episode 1393/6000, Total Reward: 231, Epsilon: 0.021\n",
      "Episode 1394/6000, Total Reward: 467, Epsilon: 0.021\n",
      "Episode 1395/6000, Total Reward: 314, Epsilon: 0.021\n",
      "Episode 1396/6000, Total Reward: 159, Epsilon: 0.020\n",
      "Episode 1397/6000, Total Reward: 233, Epsilon: 0.020\n",
      "Episode 1398/6000, Total Reward: 80, Epsilon: 0.020\n",
      "Episode 1399/6000, Total Reward: 230, Epsilon: 0.020\n",
      "Episode 1400/6000, Total Reward: 234, Epsilon: 0.020\n",
      "Updated target model.\n",
      "Episode 1401/6000, Total Reward: -75, Epsilon: 0.020\n",
      "Episode 1402/6000, Total Reward: 313, Epsilon: 0.020\n",
      "Episode 1403/6000, Total Reward: 84, Epsilon: 0.020\n",
      "Episode 1404/6000, Total Reward: 153, Epsilon: 0.020\n",
      "Episode 1405/6000, Total Reward: 156, Epsilon: 0.020\n",
      "Episode 1406/6000, Total Reward: 156, Epsilon: 0.020\n",
      "Episode 1407/6000, Total Reward: 2, Epsilon: 0.019\n",
      "Episode 1408/6000, Total Reward: 79, Epsilon: 0.019\n",
      "Episode 1409/6000, Total Reward: 231, Epsilon: 0.019\n",
      "Episode 1410/6000, Total Reward: 235, Epsilon: 0.019\n",
      "Updated target model.\n",
      "Episode 1411/6000, Total Reward: 464, Epsilon: 0.019\n",
      "Episode 1412/6000, Total Reward: 232, Epsilon: 0.019\n",
      "Episode 1413/6000, Total Reward: 310, Epsilon: 0.019\n",
      "Episode 1414/6000, Total Reward: 239, Epsilon: 0.018\n",
      "Episode 1415/6000, Total Reward: 153, Epsilon: 0.018\n",
      "Episode 1416/6000, Total Reward: 309, Epsilon: 0.018\n",
      "Episode 1417/6000, Total Reward: 233, Epsilon: 0.018\n",
      "Episode 1418/6000, Total Reward: 234, Epsilon: 0.018\n",
      "Episode 1419/6000, Total Reward: 311, Epsilon: 0.018\n",
      "Episode 1420/6000, Total Reward: -75, Epsilon: 0.018\n",
      "Updated target model.\n",
      "Episode 1421/6000, Total Reward: -75, Epsilon: 0.018\n",
      "Episode 1422/6000, Total Reward: -76, Epsilon: 0.018\n",
      "Episode 1423/6000, Total Reward: -76, Epsilon: 0.018\n",
      "Episode 1424/6000, Total Reward: 80, Epsilon: 0.017\n",
      "Episode 1425/6000, Total Reward: 155, Epsilon: 0.017\n",
      "Episode 1426/6000, Total Reward: 158, Epsilon: 0.017\n",
      "Episode 1427/6000, Total Reward: 234, Epsilon: 0.017\n",
      "Episode 1428/6000, Total Reward: 2, Epsilon: 0.017\n",
      "Episode 1429/6000, Total Reward: 154, Epsilon: 0.017\n",
      "Episode 1430/6000, Total Reward: 78, Epsilon: 0.017\n",
      "Updated target model.\n",
      "Episode 1431/6000, Total Reward: 154, Epsilon: 0.017\n",
      "Episode 1432/6000, Total Reward: 156, Epsilon: 0.017\n",
      "Episode 1433/6000, Total Reward: -75, Epsilon: 0.017\n",
      "Episode 1434/6000, Total Reward: 78, Epsilon: 0.017\n",
      "Episode 1435/6000, Total Reward: 156, Epsilon: 0.017\n",
      "Episode 1436/6000, Total Reward: 232, Epsilon: 0.017\n",
      "Episode 1437/6000, Total Reward: 157, Epsilon: 0.017\n",
      "Episode 1438/6000, Total Reward: 737, Epsilon: 0.017\n",
      "Episode 1439/6000, Total Reward: 232, Epsilon: 0.016\n",
      "Episode 1440/6000, Total Reward: -74, Epsilon: 0.016\n",
      "Updated target model.\n",
      "Episode 1441/6000, Total Reward: 158, Epsilon: 0.016\n",
      "Episode 1442/6000, Total Reward: 231, Epsilon: 0.016\n",
      "Episode 1443/6000, Total Reward: 231, Epsilon: 0.016\n",
      "Episode 1444/6000, Total Reward: 233, Epsilon: 0.016\n",
      "Episode 1445/6000, Total Reward: 157, Epsilon: 0.014\n",
      "Episode 1446/6000, Total Reward: 155, Epsilon: 0.014\n",
      "Episode 1447/6000, Total Reward: 155, Epsilon: 0.013\n",
      "Episode 1448/6000, Total Reward: -75, Epsilon: 0.013\n",
      "Episode 1449/6000, Total Reward: 156, Epsilon: 0.013\n",
      "Episode 1450/6000, Total Reward: -76, Epsilon: 0.013\n",
      "Updated target model.\n",
      "Episode 1451/6000, Total Reward: -76, Epsilon: 0.013\n",
      "Episode 1452/6000, Total Reward: 230, Epsilon: 0.013\n",
      "Episode 1453/6000, Total Reward: -75, Epsilon: 0.013\n",
      "Episode 1454/6000, Total Reward: 160, Epsilon: 0.013\n",
      "Episode 1455/6000, Total Reward: 463, Epsilon: 0.013\n",
      "Episode 1456/6000, Total Reward: 1, Epsilon: 0.013\n",
      "Episode 1457/6000, Total Reward: 158, Epsilon: 0.013\n",
      "Episode 1458/6000, Total Reward: 311, Epsilon: 0.013\n",
      "Episode 1459/6000, Total Reward: 235, Epsilon: 0.013\n",
      "Episode 1460/6000, Total Reward: -75, Epsilon: 0.013\n",
      "Updated target model.\n",
      "Episode 1461/6000, Total Reward: 231, Epsilon: 0.013\n",
      "Episode 1462/6000, Total Reward: 234, Epsilon: 0.012\n",
      "Episode 1463/6000, Total Reward: 155, Epsilon: 0.012\n",
      "Episode 1464/6000, Total Reward: 315, Epsilon: 0.011\n",
      "Episode 1465/6000, Total Reward: 463, Epsilon: 0.011\n",
      "Episode 1466/6000, Total Reward: 314, Epsilon: 0.011\n",
      "Episode 1467/6000, Total Reward: 231, Epsilon: 0.011\n",
      "Episode 1468/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 1469/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1470/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1471/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 1472/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 1473/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1474/6000, Total Reward: 307, Epsilon: 0.010\n",
      "Episode 1475/6000, Total Reward: 313, Epsilon: 0.010\n",
      "Episode 1476/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1477/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1478/6000, Total Reward: 313, Epsilon: 0.010\n",
      "Episode 1479/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 1480/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1481/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 1482/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 1483/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 1484/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 1485/6000, Total Reward: 229, Epsilon: 0.010\n",
      "Episode 1486/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 1487/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1488/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 1489/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 1490/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1491/6000, Total Reward: 160, Epsilon: 0.010\n",
      "Episode 1492/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1493/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1494/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 1495/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 1496/6000, Total Reward: 305, Epsilon: 0.010\n",
      "Episode 1497/6000, Total Reward: 228, Epsilon: 0.010\n",
      "Episode 1498/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 1499/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 1500/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1501/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 1502/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 1503/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1504/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1505/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1506/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1507/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 1508/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 1509/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1510/6000, Total Reward: 0, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1511/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1512/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 1513/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1514/6000, Total Reward: 384, Epsilon: 0.010\n",
      "Episode 1515/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 1516/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1517/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 1518/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 1519/6000, Total Reward: 77, Epsilon: 0.010\n",
      "Episode 1520/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1521/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 1522/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 1523/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1524/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1525/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 1526/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 1527/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 1528/6000, Total Reward: 314, Epsilon: 0.010\n",
      "Episode 1529/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 1530/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1531/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1532/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 1533/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 1534/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1535/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 1536/6000, Total Reward: 388, Epsilon: 0.010\n",
      "Episode 1537/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 1538/6000, Total Reward: 81, Epsilon: 0.010\n",
      "Episode 1539/6000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 1540/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1541/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 1542/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1543/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 1544/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 1545/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 1546/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 1547/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 1548/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 1549/6000, Total Reward: 388, Epsilon: 0.010\n",
      "Episode 1550/6000, Total Reward: 237, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1551/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1552/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1553/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 1554/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 1555/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1556/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 1557/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1558/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1559/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 1560/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1561/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1562/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 1563/6000, Total Reward: 307, Epsilon: 0.010\n",
      "Episode 1564/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 1565/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 1566/6000, Total Reward: 314, Epsilon: 0.010\n",
      "Episode 1567/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 1568/6000, Total Reward: 314, Epsilon: 0.010\n",
      "Episode 1569/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1570/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1571/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 1572/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 1573/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1574/6000, Total Reward: 393, Epsilon: 0.010\n",
      "Episode 1575/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 1576/6000, Total Reward: 81, Epsilon: 0.010\n",
      "Episode 1577/6000, Total Reward: 388, Epsilon: 0.010\n",
      "Episode 1578/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 1579/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 1580/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1581/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1582/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 1583/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1584/6000, Total Reward: 314, Epsilon: 0.010\n",
      "Episode 1585/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 1586/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 1587/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1588/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1589/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 1590/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1591/6000, Total Reward: 313, Epsilon: 0.010\n",
      "Episode 1592/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1593/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1594/6000, Total Reward: 307, Epsilon: 0.010\n",
      "Episode 1595/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 1596/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1597/6000, Total Reward: 6, Epsilon: 0.010\n",
      "Episode 1598/6000, Total Reward: 307, Epsilon: 0.010\n",
      "Episode 1599/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 1600/6000, Total Reward: -74, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1601/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 1602/6000, Total Reward: 77, Epsilon: 0.010\n",
      "Episode 1603/6000, Total Reward: 153, Epsilon: 0.010\n",
      "Episode 1604/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 1605/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 1606/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 1607/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 1608/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 1609/6000, Total Reward: 314, Epsilon: 0.010\n",
      "Episode 1610/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1611/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1612/6000, Total Reward: 389, Epsilon: 0.010\n",
      "Episode 1613/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1614/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 1615/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 1616/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 1617/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 1618/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1619/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 1620/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1621/6000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 1622/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 1623/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 1624/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1625/6000, Total Reward: 315, Epsilon: 0.010\n",
      "Episode 1626/6000, Total Reward: -77, Epsilon: 0.010\n",
      "Episode 1627/6000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 1628/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 1629/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1630/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1631/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 1632/6000, Total Reward: 2, Epsilon: 0.010\n",
      "Episode 1633/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1634/6000, Total Reward: 230, Epsilon: 0.010\n",
      "Episode 1635/6000, Total Reward: 2, Epsilon: 0.010\n",
      "Episode 1636/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1637/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1638/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 1639/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1640/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1641/6000, Total Reward: 239, Epsilon: 0.010\n",
      "Episode 1642/6000, Total Reward: 389, Epsilon: 0.010\n",
      "Episode 1643/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 1644/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 1645/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 1646/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 1647/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 1648/6000, Total Reward: 390, Epsilon: 0.010\n",
      "Episode 1649/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 1650/6000, Total Reward: 307, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1651/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 1652/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1653/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 1654/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1655/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1656/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1657/6000, Total Reward: 391, Epsilon: 0.010\n",
      "Episode 1658/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 1659/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 1660/6000, Total Reward: 391, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1661/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 1662/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1663/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1664/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 1665/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 1666/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 1667/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1668/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 1669/6000, Total Reward: 307, Epsilon: 0.010\n",
      "Episode 1670/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1671/6000, Total Reward: 313, Epsilon: 0.010\n",
      "Episode 1672/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 1673/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 1674/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1675/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 1676/6000, Total Reward: 313, Epsilon: 0.010\n",
      "Episode 1677/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 1678/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1679/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 1680/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1681/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 1682/6000, Total Reward: 462, Epsilon: 0.010\n",
      "Episode 1683/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1684/6000, Total Reward: -77, Epsilon: 0.010\n",
      "Episode 1685/6000, Total Reward: 736, Epsilon: 0.010\n",
      "Episode 1686/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 1687/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1688/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 1689/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 1690/6000, Total Reward: 464, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1691/6000, Total Reward: 313, Epsilon: 0.010\n",
      "Episode 1692/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 1693/6000, Total Reward: 160, Epsilon: 0.010\n",
      "Episode 1694/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1695/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 1696/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1697/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1698/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 1699/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 1700/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1701/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1702/6000, Total Reward: -77, Epsilon: 0.010\n",
      "Episode 1703/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 1704/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 1705/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1706/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 1707/6000, Total Reward: 307, Epsilon: 0.010\n",
      "Episode 1708/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 1709/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 1710/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1711/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 1712/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1713/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1714/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 1715/6000, Total Reward: 2, Epsilon: 0.010\n",
      "Episode 1716/6000, Total Reward: 462, Epsilon: 0.010\n",
      "Episode 1717/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1718/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1719/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 1720/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1721/6000, Total Reward: 463, Epsilon: 0.010\n",
      "Episode 1722/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 1723/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 1724/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 1725/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 1726/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1727/6000, Total Reward: 384, Epsilon: 0.010\n",
      "Episode 1728/6000, Total Reward: 230, Epsilon: 0.010\n",
      "Episode 1729/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 1730/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1731/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 1732/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 1733/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 1734/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 1735/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 1736/6000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 1737/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1738/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 1739/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 1740/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1741/6000, Total Reward: 2, Epsilon: 0.010\n",
      "Episode 1742/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 1743/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 1744/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 1745/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 1746/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 1747/6000, Total Reward: 237, Epsilon: 0.010\n",
      "Episode 1748/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 1749/6000, Total Reward: 464, Epsilon: 0.010\n",
      "Episode 1750/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1751/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 1752/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1753/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1754/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1755/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1756/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1757/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1758/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 1759/6000, Total Reward: 468, Epsilon: 0.010\n",
      "Episode 1760/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1761/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1762/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 1763/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1764/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 1765/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 1766/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 1767/6000, Total Reward: 82, Epsilon: 0.010\n",
      "Episode 1768/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1769/6000, Total Reward: 306, Epsilon: 0.010\n",
      "Episode 1770/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1771/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 1772/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 1773/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 1774/6000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 1775/6000, Total Reward: 0, Epsilon: 0.010\n",
      "Episode 1776/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 1777/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 1778/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1779/6000, Total Reward: 466, Epsilon: 0.010\n",
      "Episode 1780/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1781/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1782/6000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 1783/6000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 1784/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 1785/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1786/6000, Total Reward: 462, Epsilon: 0.010\n",
      "Episode 1787/6000, Total Reward: 4, Epsilon: 0.010\n",
      "Episode 1788/6000, Total Reward: 0, Epsilon: 0.010\n",
      "Episode 1789/6000, Total Reward: 463, Epsilon: 0.010\n",
      "Episode 1790/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1791/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1792/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 1793/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 1794/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 1795/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 1796/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1797/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1798/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 1799/6000, Total Reward: 237, Epsilon: 0.010\n",
      "Episode 1800/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1801/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 1802/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 1803/6000, Total Reward: 389, Epsilon: 0.010\n",
      "Episode 1804/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1805/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 1806/6000, Total Reward: 462, Epsilon: 0.010\n",
      "Episode 1807/6000, Total Reward: 160, Epsilon: 0.010\n",
      "Episode 1808/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 1809/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 1810/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1811/6000, Total Reward: 315, Epsilon: 0.010\n",
      "Episode 1812/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1813/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 1814/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1815/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1816/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 1817/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1818/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 1819/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1820/6000, Total Reward: 389, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1821/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1822/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1823/6000, Total Reward: -74, Epsilon: 0.010\n",
      "Episode 1824/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1825/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 1826/6000, Total Reward: 462, Epsilon: 0.010\n",
      "Episode 1827/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 1828/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 1829/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1830/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1831/6000, Total Reward: 466, Epsilon: 0.010\n",
      "Episode 1832/6000, Total Reward: 460, Epsilon: 0.010\n",
      "Episode 1833/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 1834/6000, Total Reward: -77, Epsilon: 0.010\n",
      "Episode 1835/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 1836/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1837/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 1838/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 1839/6000, Total Reward: 464, Epsilon: 0.010\n",
      "Episode 1840/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1841/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1842/6000, Total Reward: 384, Epsilon: 0.010\n",
      "Episode 1843/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 1844/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 1845/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1846/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1847/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 1848/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1849/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 1850/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1851/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 1852/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 1853/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 1854/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 1855/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 1856/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 1857/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 1858/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 1859/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1860/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1861/6000, Total Reward: 81, Epsilon: 0.010\n",
      "Episode 1862/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 1863/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 1864/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1865/6000, Total Reward: 464, Epsilon: 0.010\n",
      "Episode 1866/6000, Total Reward: 466, Epsilon: 0.010\n",
      "Episode 1867/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 1868/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1869/6000, Total Reward: -77, Epsilon: 0.010\n",
      "Episode 1870/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1871/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 1872/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1873/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1874/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1875/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1876/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 1877/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1878/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 1879/6000, Total Reward: -77, Epsilon: 0.010\n",
      "Episode 1880/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1881/6000, Total Reward: 464, Epsilon: 0.010\n",
      "Episode 1882/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 1883/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1884/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 1885/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 1886/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1887/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 1888/6000, Total Reward: 462, Epsilon: 0.010\n",
      "Episode 1889/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 1890/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1891/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 1892/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1893/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 1894/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1895/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 1896/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 1897/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 1898/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1899/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 1900/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1901/6000, Total Reward: 316, Epsilon: 0.010\n",
      "Episode 1902/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1903/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 1904/6000, Total Reward: 306, Epsilon: 0.010\n",
      "Episode 1905/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1906/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1907/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1908/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 1909/6000, Total Reward: 466, Epsilon: 0.010\n",
      "Episode 1910/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1911/6000, Total Reward: 388, Epsilon: 0.010\n",
      "Episode 1912/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1913/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 1914/6000, Total Reward: 384, Epsilon: 0.010\n",
      "Episode 1915/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1916/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1917/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 1918/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 1919/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 1920/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1921/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1922/6000, Total Reward: 307, Epsilon: 0.010\n",
      "Episode 1923/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 1924/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 1925/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1926/6000, Total Reward: 466, Epsilon: 0.010\n",
      "Episode 1927/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1928/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 1929/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 1930/6000, Total Reward: 313, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1931/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1932/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 1933/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 1934/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1935/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1936/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1937/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1938/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 1939/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 1940/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1941/6000, Total Reward: 736, Epsilon: 0.010\n",
      "Episode 1942/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 1943/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1944/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 1945/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1946/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 1947/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 1948/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 1949/6000, Total Reward: 238, Epsilon: 0.010\n",
      "Episode 1950/6000, Total Reward: 153, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1951/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 1952/6000, Total Reward: 466, Epsilon: 0.010\n",
      "Episode 1953/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 1954/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 1955/6000, Total Reward: 462, Epsilon: 0.010\n",
      "Episode 1956/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 1957/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 1958/6000, Total Reward: 462, Epsilon: 0.010\n",
      "Episode 1959/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 1960/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1961/6000, Total Reward: 306, Epsilon: 0.010\n",
      "Episode 1962/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 1963/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 1964/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 1965/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1966/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1967/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1968/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 1969/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1970/6000, Total Reward: 314, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1971/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 1972/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 1973/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 1974/6000, Total Reward: 388, Epsilon: 0.010\n",
      "Episode 1975/6000, Total Reward: -77, Epsilon: 0.010\n",
      "Episode 1976/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 1977/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 1978/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 1979/6000, Total Reward: 463, Epsilon: 0.010\n",
      "Episode 1980/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1981/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 1982/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1983/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1984/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 1985/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 1986/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 1987/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1988/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 1989/6000, Total Reward: 77, Epsilon: 0.010\n",
      "Episode 1990/6000, Total Reward: 460, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 1991/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1992/6000, Total Reward: 467, Epsilon: 0.010\n",
      "Episode 1993/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1994/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 1995/6000, Total Reward: 469, Epsilon: 0.010\n",
      "Episode 1996/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 1997/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 1998/6000, Total Reward: 307, Epsilon: 0.010\n",
      "Episode 1999/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2000/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2001/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2002/6000, Total Reward: 81, Epsilon: 0.010\n",
      "Episode 2003/6000, Total Reward: 461, Epsilon: 0.010\n",
      "Episode 2004/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2005/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2006/6000, Total Reward: 82, Epsilon: 0.010\n",
      "Episode 2007/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2008/6000, Total Reward: 237, Epsilon: 0.010\n",
      "Episode 2009/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2010/6000, Total Reward: 160, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2011/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2012/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 2013/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 2014/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2015/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2016/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2017/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2018/6000, Total Reward: 740, Epsilon: 0.010\n",
      "Episode 2019/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 2020/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2021/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2022/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2023/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 2024/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 2025/6000, Total Reward: 160, Epsilon: 0.010\n",
      "Episode 2026/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2027/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2028/6000, Total Reward: 306, Epsilon: 0.010\n",
      "Episode 2029/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 2030/6000, Total Reward: 462, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2031/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2032/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2033/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2034/6000, Total Reward: 464, Epsilon: 0.010\n",
      "Episode 2035/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 2036/6000, Total Reward: 463, Epsilon: 0.010\n",
      "Episode 2037/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2038/6000, Total Reward: 153, Epsilon: 0.010\n",
      "Episode 2039/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2040/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2041/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 2042/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2043/6000, Total Reward: 389, Epsilon: 0.010\n",
      "Episode 2044/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2045/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 2046/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2047/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2048/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2049/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2050/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2051/6000, Total Reward: 153, Epsilon: 0.010\n",
      "Episode 2052/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2053/6000, Total Reward: 461, Epsilon: 0.010\n",
      "Episode 2054/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2055/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2056/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 2057/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 2058/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2059/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2060/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2061/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2062/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 2063/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 2064/6000, Total Reward: 463, Epsilon: 0.010\n",
      "Episode 2065/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2066/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 2067/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2068/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2069/6000, Total Reward: 468, Epsilon: 0.010\n",
      "Episode 2070/6000, Total Reward: 313, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2071/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 2072/6000, Total Reward: 153, Epsilon: 0.010\n",
      "Episode 2073/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2074/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2075/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2076/6000, Total Reward: -77, Epsilon: 0.010\n",
      "Episode 2077/6000, Total Reward: 152, Epsilon: 0.010\n",
      "Episode 2078/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2079/6000, Total Reward: 388, Epsilon: 0.010\n",
      "Episode 2080/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2081/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 2082/6000, Total Reward: 466, Epsilon: 0.010\n",
      "Episode 2083/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2084/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2085/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2086/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2087/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2088/6000, Total Reward: 463, Epsilon: 0.010\n",
      "Episode 2089/6000, Total Reward: 464, Epsilon: 0.010\n",
      "Episode 2090/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2091/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2092/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2093/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 2094/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2095/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2096/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2097/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2098/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2099/6000, Total Reward: 388, Epsilon: 0.010\n",
      "Episode 2100/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2101/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 2102/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2103/6000, Total Reward: 390, Epsilon: 0.010\n",
      "Episode 2104/6000, Total Reward: 462, Epsilon: 0.010\n",
      "Episode 2105/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 2106/6000, Total Reward: 307, Epsilon: 0.010\n",
      "Episode 2107/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2108/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2109/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2110/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2111/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 2112/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2113/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 2114/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2115/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2116/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2117/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2118/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2119/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 2120/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2121/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2122/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2123/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2124/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2125/6000, Total Reward: 5, Epsilon: 0.010\n",
      "Episode 2126/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2127/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2128/6000, Total Reward: 461, Epsilon: 0.010\n",
      "Episode 2129/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 2130/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2131/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2132/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 2133/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2134/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2135/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2136/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2137/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2138/6000, Total Reward: 468, Epsilon: 0.010\n",
      "Episode 2139/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2140/6000, Total Reward: 458, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2141/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 2142/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2143/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2144/6000, Total Reward: 389, Epsilon: 0.010\n",
      "Episode 2145/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 2146/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2147/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2148/6000, Total Reward: 459, Epsilon: 0.010\n",
      "Episode 2149/6000, Total Reward: 383, Epsilon: 0.010\n",
      "Episode 2150/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2151/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2152/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2153/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2154/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2155/6000, Total Reward: -74, Epsilon: 0.010\n",
      "Episode 2156/6000, Total Reward: 160, Epsilon: 0.010\n",
      "Episode 2157/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 2158/6000, Total Reward: 463, Epsilon: 0.010\n",
      "Episode 2159/6000, Total Reward: 152, Epsilon: 0.010\n",
      "Episode 2160/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2161/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 2162/6000, Total Reward: 460, Epsilon: 0.010\n",
      "Episode 2163/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 2164/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2165/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 2166/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2167/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2168/6000, Total Reward: 461, Epsilon: 0.010\n",
      "Episode 2169/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2170/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2171/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 2172/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 2173/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2174/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 2175/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 2176/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2177/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2178/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2179/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2180/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2181/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2182/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2183/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2184/6000, Total Reward: 237, Epsilon: 0.010\n",
      "Episode 2185/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2186/6000, Total Reward: 81, Epsilon: 0.010\n",
      "Episode 2187/6000, Total Reward: 740, Epsilon: 0.010\n",
      "Episode 2188/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 2189/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2190/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2191/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2192/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2193/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2194/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 2195/6000, Total Reward: 464, Epsilon: 0.010\n",
      "Episode 2196/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2197/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2198/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2199/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2200/6000, Total Reward: 2, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2201/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 2202/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 2203/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2204/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2205/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 2206/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 2207/6000, Total Reward: 466, Epsilon: 0.010\n",
      "Episode 2208/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2209/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2210/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2211/6000, Total Reward: 5, Epsilon: 0.010\n",
      "Episode 2212/6000, Total Reward: 77, Epsilon: 0.010\n",
      "Episode 2213/6000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 2214/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2215/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2216/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2217/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2218/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 2219/6000, Total Reward: 306, Epsilon: 0.010\n",
      "Episode 2220/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2221/6000, Total Reward: 384, Epsilon: 0.010\n",
      "Episode 2222/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 2223/6000, Total Reward: -73, Epsilon: 0.010\n",
      "Episode 2224/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2225/6000, Total Reward: 76, Epsilon: 0.010\n",
      "Episode 2226/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2227/6000, Total Reward: 307, Epsilon: 0.010\n",
      "Episode 2228/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2229/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 2230/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2231/6000, Total Reward: 306, Epsilon: 0.010\n",
      "Episode 2232/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2233/6000, Total Reward: 462, Epsilon: 0.010\n",
      "Episode 2234/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2235/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2236/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2237/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 2238/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2239/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2240/6000, Total Reward: 464, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2241/6000, Total Reward: 384, Epsilon: 0.010\n",
      "Episode 2242/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2243/6000, Total Reward: 463, Epsilon: 0.010\n",
      "Episode 2244/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2245/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2246/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2247/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2248/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2249/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2250/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2251/6000, Total Reward: 460, Epsilon: 0.010\n",
      "Episode 2252/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2253/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 2254/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2255/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2256/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2257/6000, Total Reward: 153, Epsilon: 0.010\n",
      "Episode 2258/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 2259/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2260/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2261/6000, Total Reward: 314, Epsilon: 0.010\n",
      "Episode 2262/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2263/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 2264/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2265/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2266/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2267/6000, Total Reward: 230, Epsilon: 0.010\n",
      "Episode 2268/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 2269/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2270/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2271/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2272/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 2273/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 2274/6000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 2275/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2276/6000, Total Reward: 230, Epsilon: 0.010\n",
      "Episode 2277/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2278/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 2279/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 2280/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2281/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2282/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 2283/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 2284/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2285/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2286/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2287/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 2288/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2289/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2290/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2291/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2292/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2293/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2294/6000, Total Reward: 468, Epsilon: 0.010\n",
      "Episode 2295/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2296/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2297/6000, Total Reward: 384, Epsilon: 0.010\n",
      "Episode 2298/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2299/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 2300/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2301/6000, Total Reward: 466, Epsilon: 0.010\n",
      "Episode 2302/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2303/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2304/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2305/6000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 2306/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2307/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2308/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2309/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2310/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2311/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 2312/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2313/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2314/6000, Total Reward: 464, Epsilon: 0.010\n",
      "Episode 2315/6000, Total Reward: 388, Epsilon: 0.010\n",
      "Episode 2316/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 2317/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 2318/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 2319/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2320/6000, Total Reward: 384, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2321/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2322/6000, Total Reward: 388, Epsilon: 0.010\n",
      "Episode 2323/6000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 2324/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2325/6000, Total Reward: 160, Epsilon: 0.010\n",
      "Episode 2326/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2327/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2328/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2329/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2330/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2331/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 2332/6000, Total Reward: 77, Epsilon: 0.010\n",
      "Episode 2333/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2334/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2335/6000, Total Reward: 389, Epsilon: 0.010\n",
      "Episode 2336/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2337/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2338/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2339/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2340/6000, Total Reward: 463, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2341/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2342/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2343/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2344/6000, Total Reward: 462, Epsilon: 0.010\n",
      "Episode 2345/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2346/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2347/6000, Total Reward: 466, Epsilon: 0.010\n",
      "Episode 2348/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2349/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2350/6000, Total Reward: 384, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2351/6000, Total Reward: 466, Epsilon: 0.010\n",
      "Episode 2352/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 2353/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 2354/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2355/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2356/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2357/6000, Total Reward: 230, Epsilon: 0.010\n",
      "Episode 2358/6000, Total Reward: 384, Epsilon: 0.010\n",
      "Episode 2359/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2360/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2361/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2362/6000, Total Reward: 230, Epsilon: 0.010\n",
      "Episode 2363/6000, Total Reward: 464, Epsilon: 0.010\n",
      "Episode 2364/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 2365/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2366/6000, Total Reward: 81, Epsilon: 0.010\n",
      "Episode 2367/6000, Total Reward: 737, Epsilon: 0.010\n",
      "Episode 2368/6000, Total Reward: 76, Epsilon: 0.010\n",
      "Episode 2369/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2370/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2371/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2372/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2373/6000, Total Reward: 462, Epsilon: 0.010\n",
      "Episode 2374/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2375/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2376/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2377/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2378/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2379/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2380/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2381/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2382/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2383/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 2384/6000, Total Reward: 389, Epsilon: 0.010\n",
      "Episode 2385/6000, Total Reward: -1, Epsilon: 0.010\n",
      "Episode 2386/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2387/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2388/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2389/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2390/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2391/6000, Total Reward: 4, Epsilon: 0.010\n",
      "Episode 2392/6000, Total Reward: 2, Epsilon: 0.010\n",
      "Episode 2393/6000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 2394/6000, Total Reward: 389, Epsilon: 0.010\n",
      "Episode 2395/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2396/6000, Total Reward: -72, Epsilon: 0.010\n",
      "Episode 2397/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2398/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2399/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2400/6000, Total Reward: 383, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2401/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2402/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 2403/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2404/6000, Total Reward: 463, Epsilon: 0.010\n",
      "Episode 2405/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 2406/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 2407/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2408/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2409/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 2410/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2411/6000, Total Reward: 237, Epsilon: 0.010\n",
      "Episode 2412/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2413/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 2414/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2415/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2416/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2417/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 2418/6000, Total Reward: 237, Epsilon: 0.010\n",
      "Episode 2419/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2420/6000, Total Reward: 462, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2421/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 2422/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2423/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2424/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2425/6000, Total Reward: 463, Epsilon: 0.010\n",
      "Episode 2426/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 2427/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2428/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 2429/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2430/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2431/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2432/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2433/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2434/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2435/6000, Total Reward: 466, Epsilon: 0.010\n",
      "Episode 2436/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2437/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2438/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2439/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 2440/6000, Total Reward: 153, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2441/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2442/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 2443/6000, Total Reward: 384, Epsilon: 0.010\n",
      "Episode 2444/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2445/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 2446/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2447/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2448/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2449/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2450/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2451/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 2452/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 2453/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 2454/6000, Total Reward: 153, Epsilon: 0.010\n",
      "Episode 2455/6000, Total Reward: 77, Epsilon: 0.010\n",
      "Episode 2456/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 2457/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2458/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2459/6000, Total Reward: 2, Epsilon: 0.010\n",
      "Episode 2460/6000, Total Reward: 460, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2461/6000, Total Reward: 82, Epsilon: 0.010\n",
      "Episode 2462/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2463/6000, Total Reward: 237, Epsilon: 0.010\n",
      "Episode 2464/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2465/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2466/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2467/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2468/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2469/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 2470/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2471/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2472/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2473/6000, Total Reward: 463, Epsilon: 0.010\n",
      "Episode 2474/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 2475/6000, Total Reward: 466, Epsilon: 0.010\n",
      "Episode 2476/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2477/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2478/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2479/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2480/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2481/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2482/6000, Total Reward: 463, Epsilon: 0.010\n",
      "Episode 2483/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 2484/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2485/6000, Total Reward: 463, Epsilon: 0.010\n",
      "Episode 2486/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2487/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2488/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2489/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2490/6000, Total Reward: 388, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2491/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2492/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2493/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2494/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 2495/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2496/6000, Total Reward: 384, Epsilon: 0.010\n",
      "Episode 2497/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2498/6000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 2499/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2500/6000, Total Reward: -74, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2501/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2502/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 2503/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2504/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2505/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2506/6000, Total Reward: 463, Epsilon: 0.010\n",
      "Episode 2507/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2508/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 2509/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2510/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2511/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2512/6000, Total Reward: 77, Epsilon: 0.010\n",
      "Episode 2513/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2514/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2515/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2516/6000, Total Reward: 389, Epsilon: 0.010\n",
      "Episode 2517/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 2518/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2519/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2520/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2521/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2522/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2523/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2524/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2525/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2526/6000, Total Reward: -73, Epsilon: 0.010\n",
      "Episode 2527/6000, Total Reward: 388, Epsilon: 0.010\n",
      "Episode 2528/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2529/6000, Total Reward: 389, Epsilon: 0.010\n",
      "Episode 2530/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2531/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 2532/6000, Total Reward: 0, Epsilon: 0.010\n",
      "Episode 2533/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2534/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2535/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2536/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2537/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2538/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2539/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 2540/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2541/6000, Total Reward: 462, Epsilon: 0.010\n",
      "Episode 2542/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2543/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2544/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2545/6000, Total Reward: 314, Epsilon: 0.010\n",
      "Episode 2546/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 2547/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2548/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 2549/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2550/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2551/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2552/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2553/6000, Total Reward: 238, Epsilon: 0.010\n",
      "Episode 2554/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2555/6000, Total Reward: 461, Epsilon: 0.010\n",
      "Episode 2556/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2557/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 2558/6000, Total Reward: 737, Epsilon: 0.010\n",
      "Episode 2559/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2560/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2561/6000, Total Reward: 230, Epsilon: 0.010\n",
      "Episode 2562/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2563/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 2564/6000, Total Reward: 239, Epsilon: 0.010\n",
      "Episode 2565/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2566/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2567/6000, Total Reward: 384, Epsilon: 0.010\n",
      "Episode 2568/6000, Total Reward: 77, Epsilon: 0.010\n",
      "Episode 2569/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 2570/6000, Total Reward: 237, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2571/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2572/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2573/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2574/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2575/6000, Total Reward: -74, Epsilon: 0.010\n",
      "Episode 2576/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2577/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2578/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2579/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2580/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2581/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2582/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2583/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2584/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 2585/6000, Total Reward: 0, Epsilon: 0.010\n",
      "Episode 2586/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2587/6000, Total Reward: 466, Epsilon: 0.010\n",
      "Episode 2588/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2589/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 2590/6000, Total Reward: 82, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2591/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2592/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2593/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2594/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2595/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2596/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2597/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2598/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2599/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 2600/6000, Total Reward: 230, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2601/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2602/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2603/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2604/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2605/6000, Total Reward: 464, Epsilon: 0.010\n",
      "Episode 2606/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2607/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2608/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2609/6000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 2610/6000, Total Reward: 0, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2611/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 2612/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 2613/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2614/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2615/6000, Total Reward: 2, Epsilon: 0.010\n",
      "Episode 2616/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 2617/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2618/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 2619/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2620/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2621/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2622/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 2623/6000, Total Reward: 462, Epsilon: 0.010\n",
      "Episode 2624/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2625/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2626/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2627/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 2628/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2629/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2630/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2631/6000, Total Reward: 459, Epsilon: 0.010\n",
      "Episode 2632/6000, Total Reward: 313, Epsilon: 0.010\n",
      "Episode 2633/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2634/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2635/6000, Total Reward: 81, Epsilon: 0.010\n",
      "Episode 2636/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2637/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2638/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 2639/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2640/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2641/6000, Total Reward: 237, Epsilon: 0.010\n",
      "Episode 2642/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 2643/6000, Total Reward: 239, Epsilon: 0.010\n",
      "Episode 2644/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2645/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2646/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2647/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2648/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2649/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2650/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2651/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 2652/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2653/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2654/6000, Total Reward: 307, Epsilon: 0.010\n",
      "Episode 2655/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2656/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2657/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 2658/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2659/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2660/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2661/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2662/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2663/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 2664/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2665/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2666/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2667/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2668/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2669/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 2670/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2671/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 2672/6000, Total Reward: 466, Epsilon: 0.010\n",
      "Episode 2673/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2674/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2675/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2676/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2677/6000, Total Reward: 82, Epsilon: 0.010\n",
      "Episode 2678/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2679/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2680/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2681/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2682/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2683/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2684/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2685/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 2686/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2687/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2688/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2689/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2690/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2691/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2692/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2693/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2694/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 2695/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2696/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2697/6000, Total Reward: 230, Epsilon: 0.010\n",
      "Episode 2698/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2699/6000, Total Reward: 239, Epsilon: 0.010\n",
      "Episode 2700/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2701/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2702/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2703/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2704/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2705/6000, Total Reward: 2, Epsilon: 0.010\n",
      "Episode 2706/6000, Total Reward: 460, Epsilon: 0.010\n",
      "Episode 2707/6000, Total Reward: 82, Epsilon: 0.010\n",
      "Episode 2708/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 2709/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2710/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2711/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 2712/6000, Total Reward: 461, Epsilon: 0.010\n",
      "Episode 2713/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2714/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2715/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2716/6000, Total Reward: 388, Epsilon: 0.010\n",
      "Episode 2717/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2718/6000, Total Reward: 153, Epsilon: 0.010\n",
      "Episode 2719/6000, Total Reward: 458, Epsilon: 0.010\n",
      "Episode 2720/6000, Total Reward: 4, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2721/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 2722/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2723/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2724/6000, Total Reward: 237, Epsilon: 0.010\n",
      "Episode 2725/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2726/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2727/6000, Total Reward: 464, Epsilon: 0.010\n",
      "Episode 2728/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2729/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2730/6000, Total Reward: -77, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2731/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2732/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2733/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2734/6000, Total Reward: 383, Epsilon: 0.010\n",
      "Episode 2735/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2736/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2737/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2738/6000, Total Reward: 461, Epsilon: 0.010\n",
      "Episode 2739/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 2740/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2741/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2742/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2743/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2744/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 2745/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 2746/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2747/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2748/6000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 2749/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 2750/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2751/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2752/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2753/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 2754/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2755/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 2756/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2757/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2758/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2759/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2760/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2761/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 2762/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2763/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2764/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2765/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2766/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2767/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2768/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2769/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2770/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2771/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2772/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 2773/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2774/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 2775/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 2776/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 2777/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 2778/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2779/6000, Total Reward: 383, Epsilon: 0.010\n",
      "Episode 2780/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2781/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 2782/6000, Total Reward: 388, Epsilon: 0.010\n",
      "Episode 2783/6000, Total Reward: 160, Epsilon: 0.010\n",
      "Episode 2784/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2785/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2786/6000, Total Reward: 388, Epsilon: 0.010\n",
      "Episode 2787/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2788/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2789/6000, Total Reward: 4, Epsilon: 0.010\n",
      "Episode 2790/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2791/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2792/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2793/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 2794/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 2795/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2796/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2797/6000, Total Reward: 383, Epsilon: 0.010\n",
      "Episode 2798/6000, Total Reward: 739, Epsilon: 0.010\n",
      "Episode 2799/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2800/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2801/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 2802/6000, Total Reward: 466, Epsilon: 0.010\n",
      "Episode 2803/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2804/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 2805/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2806/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2807/6000, Total Reward: 464, Epsilon: 0.010\n",
      "Episode 2808/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 2809/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2810/6000, Total Reward: 463, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2811/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2812/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2813/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2814/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2815/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2816/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2817/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 2818/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2819/6000, Total Reward: 153, Epsilon: 0.010\n",
      "Episode 2820/6000, Total Reward: 1, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2821/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 2822/6000, Total Reward: 307, Epsilon: 0.010\n",
      "Episode 2823/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 2824/6000, Total Reward: 460, Epsilon: 0.010\n",
      "Episode 2825/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2826/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 2827/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 2828/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2829/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2830/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2831/6000, Total Reward: 153, Epsilon: 0.010\n",
      "Episode 2832/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2833/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 2834/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 2835/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2836/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2837/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2838/6000, Total Reward: 230, Epsilon: 0.010\n",
      "Episode 2839/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2840/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2841/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2842/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2843/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2844/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 2845/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2846/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2847/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2848/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2849/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 2850/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2851/6000, Total Reward: 2, Epsilon: 0.010\n",
      "Episode 2852/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 2853/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 2854/6000, Total Reward: 743, Epsilon: 0.010\n",
      "Episode 2855/6000, Total Reward: 464, Epsilon: 0.010\n",
      "Episode 2856/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 2857/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2858/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2859/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2860/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2861/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2862/6000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 2863/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2864/6000, Total Reward: 461, Epsilon: 0.010\n",
      "Episode 2865/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2866/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2867/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 2868/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2869/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2870/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2871/6000, Total Reward: 305, Epsilon: 0.010\n",
      "Episode 2872/6000, Total Reward: 314, Epsilon: 0.010\n",
      "Episode 2873/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2874/6000, Total Reward: 464, Epsilon: 0.010\n",
      "Episode 2875/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2876/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 2877/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2878/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2879/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2880/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2881/6000, Total Reward: -74, Epsilon: 0.010\n",
      "Episode 2882/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 2883/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 2884/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2885/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2886/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2887/6000, Total Reward: 237, Epsilon: 0.010\n",
      "Episode 2888/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2889/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2890/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2891/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2892/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2893/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 2894/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2895/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2896/6000, Total Reward: 459, Epsilon: 0.010\n",
      "Episode 2897/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2898/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2899/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2900/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2901/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2902/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2903/6000, Total Reward: 160, Epsilon: 0.010\n",
      "Episode 2904/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2905/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2906/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2907/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 2908/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 2909/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 2910/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2911/6000, Total Reward: 463, Epsilon: 0.010\n",
      "Episode 2912/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 2913/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2914/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 2915/6000, Total Reward: 315, Epsilon: 0.010\n",
      "Episode 2916/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2917/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2918/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 2919/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2920/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2921/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2922/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 2923/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2924/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 2925/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2926/6000, Total Reward: 461, Epsilon: 0.010\n",
      "Episode 2927/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2928/6000, Total Reward: -74, Epsilon: 0.010\n",
      "Episode 2929/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 2930/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2931/6000, Total Reward: 2, Epsilon: 0.010\n",
      "Episode 2932/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 2933/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2934/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2935/6000, Total Reward: 463, Epsilon: 0.010\n",
      "Episode 2936/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2937/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2938/6000, Total Reward: 77, Epsilon: 0.010\n",
      "Episode 2939/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2940/6000, Total Reward: 462, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2941/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 2942/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2943/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2944/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 2945/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2946/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2947/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2948/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 2949/6000, Total Reward: 313, Epsilon: 0.010\n",
      "Episode 2950/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2951/6000, Total Reward: 463, Epsilon: 0.010\n",
      "Episode 2952/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 2953/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 2954/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2955/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2956/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 2957/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2958/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2959/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 2960/6000, Total Reward: 4, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2961/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2962/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2963/6000, Total Reward: 160, Epsilon: 0.010\n",
      "Episode 2964/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2965/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2966/6000, Total Reward: 734, Epsilon: 0.010\n",
      "Episode 2967/6000, Total Reward: 81, Epsilon: 0.010\n",
      "Episode 2968/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2969/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2970/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2971/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 2972/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2973/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2974/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 2975/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2976/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 2977/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 2978/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 2979/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 2980/6000, Total Reward: 466, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2981/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2982/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2983/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 2984/6000, Total Reward: 315, Epsilon: 0.010\n",
      "Episode 2985/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2986/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 2987/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 2988/6000, Total Reward: 464, Epsilon: 0.010\n",
      "Episode 2989/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2990/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 2991/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 2992/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2993/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2994/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2995/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 2996/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 2997/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 2998/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 2999/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 3000/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3001/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 3002/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3003/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 3004/6000, Total Reward: 239, Epsilon: 0.010\n",
      "Episode 3005/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 3006/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 3007/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 3008/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 3009/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 3010/6000, Total Reward: 461, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3011/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3012/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 3013/6000, Total Reward: 388, Epsilon: 0.010\n",
      "Episode 3014/6000, Total Reward: 313, Epsilon: 0.010\n",
      "Episode 3015/6000, Total Reward: 229, Epsilon: 0.010\n",
      "Episode 3016/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 3017/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 3018/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 3019/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3020/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3021/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 3022/6000, Total Reward: -73, Epsilon: 0.010\n",
      "Episode 3023/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 3024/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 3025/6000, Total Reward: 466, Epsilon: 0.010\n",
      "Episode 3026/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 3027/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 3028/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 3029/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3030/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3031/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3032/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3033/6000, Total Reward: 4, Epsilon: 0.010\n",
      "Episode 3034/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3035/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 3036/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3037/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 3038/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 3039/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 3040/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3041/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 3042/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3043/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 3044/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 3045/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 3046/6000, Total Reward: 237, Epsilon: 0.010\n",
      "Episode 3047/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 3048/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 3049/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 3050/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3051/6000, Total Reward: 313, Epsilon: 0.010\n",
      "Episode 3052/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 3053/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 3054/6000, Total Reward: 379, Epsilon: 0.010\n",
      "Episode 3055/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 3056/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3057/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3058/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 3059/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 3060/6000, Total Reward: 237, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3061/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 3062/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 3063/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3064/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 3065/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 3066/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 3067/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 3068/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 3069/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 3070/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3071/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 3072/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 3073/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 3074/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3075/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 3076/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3077/6000, Total Reward: 153, Epsilon: 0.010\n",
      "Episode 3078/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3079/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 3080/6000, Total Reward: 237, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3081/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 3082/6000, Total Reward: 153, Epsilon: 0.010\n",
      "Episode 3083/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 3084/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3085/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 3086/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3087/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 3088/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 3089/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 3090/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3091/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 3092/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3093/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 3094/6000, Total Reward: 461, Epsilon: 0.010\n",
      "Episode 3095/6000, Total Reward: 230, Epsilon: 0.010\n",
      "Episode 3096/6000, Total Reward: 462, Epsilon: 0.010\n",
      "Episode 3097/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 3098/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 3099/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 3100/6000, Total Reward: -77, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3101/6000, Total Reward: 4, Epsilon: 0.010\n",
      "Episode 3102/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 3103/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 3104/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 3105/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 3106/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3107/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 3108/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 3109/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 3110/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3111/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 3112/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 3113/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3114/6000, Total Reward: -74, Epsilon: 0.010\n",
      "Episode 3115/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 3116/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3117/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 3118/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 3119/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 3120/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3121/6000, Total Reward: 161, Epsilon: 0.010\n",
      "Episode 3122/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 3123/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3124/6000, Total Reward: -77, Epsilon: 0.010\n",
      "Episode 3125/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 3126/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3127/6000, Total Reward: 81, Epsilon: 0.010\n",
      "Episode 3128/6000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 3129/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 3130/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3131/6000, Total Reward: 464, Epsilon: 0.010\n",
      "Episode 3132/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 3133/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 3134/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3135/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 3136/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3137/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 3138/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 3139/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 3140/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3141/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 3142/6000, Total Reward: 314, Epsilon: 0.010\n",
      "Episode 3143/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 3144/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3145/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 3146/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3147/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3148/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3149/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 3150/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3151/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 3152/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 3153/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 3154/6000, Total Reward: 2, Epsilon: 0.010\n",
      "Episode 3155/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 3156/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 3157/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 3158/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3159/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 3160/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3161/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 3162/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3163/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 3164/6000, Total Reward: 461, Epsilon: 0.010\n",
      "Episode 3165/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 3166/6000, Total Reward: 153, Epsilon: 0.010\n",
      "Episode 3167/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3168/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3169/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 3170/6000, Total Reward: 384, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3171/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 3172/6000, Total Reward: 388, Epsilon: 0.010\n",
      "Episode 3173/6000, Total Reward: 461, Epsilon: 0.010\n",
      "Episode 3174/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3175/6000, Total Reward: 314, Epsilon: 0.010\n",
      "Episode 3176/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3177/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 3178/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 3179/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 3180/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3181/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 3182/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 3183/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3184/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 3185/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 3186/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 3187/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 3188/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3189/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3190/6000, Total Reward: 1, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3191/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 3192/6000, Total Reward: 229, Epsilon: 0.010\n",
      "Episode 3193/6000, Total Reward: 461, Epsilon: 0.010\n",
      "Episode 3194/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 3195/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3196/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3197/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3198/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 3199/6000, Total Reward: -74, Epsilon: 0.010\n",
      "Episode 3200/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3201/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3202/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3203/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 3204/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 3205/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 3206/6000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 3207/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 3208/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 3209/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 3210/6000, Total Reward: 4, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3211/6000, Total Reward: 465, Epsilon: 0.010\n",
      "Episode 3212/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 3213/6000, Total Reward: 4, Epsilon: 0.010\n",
      "Episode 3214/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3215/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3216/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 3217/6000, Total Reward: 4, Epsilon: 0.010\n",
      "Episode 3218/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 3219/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 3220/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3221/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 3222/6000, Total Reward: 4, Epsilon: 0.010\n",
      "Episode 3223/6000, Total Reward: 0, Epsilon: 0.010\n",
      "Episode 3224/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3225/6000, Total Reward: 314, Epsilon: 0.010\n",
      "Episode 3226/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 3227/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3228/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 3229/6000, Total Reward: 461, Epsilon: 0.010\n",
      "Episode 3230/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3231/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 3232/6000, Total Reward: 306, Epsilon: 0.010\n",
      "Episode 3233/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 3234/6000, Total Reward: 5, Epsilon: 0.010\n",
      "Episode 3235/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 3236/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3237/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3238/6000, Total Reward: 389, Epsilon: 0.010\n",
      "Episode 3239/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 3240/6000, Total Reward: 389, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3241/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 3242/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 3243/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 3244/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 3245/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 3246/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 3247/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 3248/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 3249/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 3250/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3251/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 3252/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3253/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3254/6000, Total Reward: 238, Epsilon: 0.010\n",
      "Episode 3255/6000, Total Reward: 238, Epsilon: 0.010\n",
      "Episode 3256/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3257/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3258/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 3259/6000, Total Reward: 313, Epsilon: 0.010\n",
      "Episode 3260/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3261/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 3262/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3263/6000, Total Reward: 2, Epsilon: 0.010\n",
      "Episode 3264/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 3265/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3266/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3267/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 3268/6000, Total Reward: 238, Epsilon: 0.010\n",
      "Episode 3269/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 3270/6000, Total Reward: -73, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3271/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3272/6000, Total Reward: 231, Epsilon: 0.010\n",
      "Episode 3273/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 3274/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 3275/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 3276/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 3277/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 3278/6000, Total Reward: 462, Epsilon: 0.010\n",
      "Episode 3279/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 3280/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3281/6000, Total Reward: 155, Epsilon: 0.010\n",
      "Episode 3282/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 3283/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 3284/6000, Total Reward: 158, Epsilon: 0.010\n",
      "Episode 3285/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 3286/6000, Total Reward: -74, Epsilon: 0.010\n",
      "Episode 3287/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 3288/6000, Total Reward: 386, Epsilon: 0.010\n",
      "Episode 3289/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 3290/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3291/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 3292/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 3293/6000, Total Reward: 388, Epsilon: 0.010\n",
      "Episode 3294/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 3295/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 3296/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 3297/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 3298/6000, Total Reward: 230, Epsilon: 0.010\n",
      "Episode 3299/6000, Total Reward: 313, Epsilon: 0.010\n",
      "Episode 3300/6000, Total Reward: 316, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3301/6000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 3302/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 3303/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3304/6000, Total Reward: 309, Epsilon: 0.010\n",
      "Episode 3305/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 3306/6000, Total Reward: 235, Epsilon: 0.010\n",
      "Episode 3307/6000, Total Reward: -74, Epsilon: 0.010\n",
      "Episode 3308/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 3309/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 3310/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3311/6000, Total Reward: 310, Epsilon: 0.010\n",
      "Episode 3312/6000, Total Reward: 382, Epsilon: 0.010\n",
      "Episode 3313/6000, Total Reward: 313, Epsilon: 0.010\n",
      "Episode 3314/6000, Total Reward: 78, Epsilon: 0.010\n",
      "Episode 3315/6000, Total Reward: 308, Epsilon: 0.010\n",
      "Episode 3316/6000, Total Reward: 237, Epsilon: 0.010\n",
      "Episode 3317/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 3318/6000, Total Reward: 313, Epsilon: 0.010\n",
      "Episode 3319/6000, Total Reward: 384, Epsilon: 0.010\n",
      "Episode 3320/6000, Total Reward: 5, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3321/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 3322/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 3323/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 3324/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3325/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3326/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 3327/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3328/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3329/6000, Total Reward: 237, Epsilon: 0.010\n",
      "Episode 3330/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3331/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 3332/6000, Total Reward: -76, Epsilon: 0.010\n",
      "Episode 3333/6000, Total Reward: 75, Epsilon: 0.010\n",
      "Episode 3334/6000, Total Reward: 3, Epsilon: 0.010\n",
      "Episode 3335/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 3336/6000, Total Reward: 233, Epsilon: 0.010\n",
      "Episode 3337/6000, Total Reward: 79, Epsilon: 0.010\n",
      "Episode 3338/6000, Total Reward: 153, Epsilon: 0.010\n",
      "Episode 3339/6000, Total Reward: 466, Epsilon: 0.010\n",
      "Episode 3340/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3341/6000, Total Reward: 230, Epsilon: 0.010\n",
      "Episode 3342/6000, Total Reward: 237, Epsilon: 0.010\n",
      "Episode 3343/6000, Total Reward: 461, Epsilon: 0.010\n",
      "Episode 3344/6000, Total Reward: 385, Epsilon: 0.010\n",
      "Episode 3345/6000, Total Reward: 4, Epsilon: 0.010\n",
      "Episode 3346/6000, Total Reward: 156, Epsilon: 0.010\n",
      "Episode 3347/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 3348/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3349/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 3350/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3351/6000, Total Reward: 232, Epsilon: 0.010\n",
      "Episode 3352/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3353/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 3354/6000, Total Reward: 738, Epsilon: 0.010\n",
      "Episode 3355/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 3356/6000, Total Reward: 313, Epsilon: 0.010\n",
      "Episode 3357/6000, Total Reward: 80, Epsilon: 0.010\n",
      "Episode 3358/6000, Total Reward: 307, Epsilon: 0.010\n",
      "Episode 3359/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3360/6000, Total Reward: 81, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3361/6000, Total Reward: 234, Epsilon: 0.010\n",
      "Episode 3362/6000, Total Reward: 387, Epsilon: 0.010\n",
      "Episode 3363/6000, Total Reward: 312, Epsilon: 0.010\n",
      "Episode 3364/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3365/6000, Total Reward: 154, Epsilon: 0.010\n",
      "Episode 3366/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 3367/6000, Total Reward: 153, Epsilon: 0.010\n",
      "Episode 3368/6000, Total Reward: -75, Epsilon: 0.010\n",
      "Episode 3369/6000, Total Reward: 236, Epsilon: 0.010\n",
      "Episode 3370/6000, Total Reward: 81, Epsilon: 0.010\n",
      "Updated target model.\n",
      "Episode 3371/6000, Total Reward: 157, Epsilon: 0.010\n",
      "Episode 3372/6000, Total Reward: 159, Epsilon: 0.010\n",
      "Episode 3373/6000, Total Reward: 1, Epsilon: 0.010\n",
      "Episode 3374/6000, Total Reward: 311, Epsilon: 0.010\n",
      "Episode 3375/6000, Total Reward: 315, Epsilon: 0.010\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m action_dim \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mn\n\u001b[1;32m     11\u001b[0m agent \u001b[38;5;241m=\u001b[39m DQNAgent(state_dim, action_dim)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrain_dqn\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[73], line 80\u001b[0m, in \u001b[0;36mtrain_dqn\u001b[0;34m(env, agent, episodes, update_target_every)\u001b[0m\n\u001b[1;32m     78\u001b[0m next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     79\u001b[0m agent\u001b[38;5;241m.\u001b[39mremember(state, action, reward, next_state, done)\n\u001b[0;32m---> 80\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[1;32m     82\u001b[0m total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[0;32mIn[73], line 58\u001b[0m, in \u001b[0;36mDQNAgent.replay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m target_q_values \u001b[38;5;241m=\u001b[39m rewards \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dones) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m next_q_values\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Update the Q-network\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_q_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     60\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/5sem/RL_ShakeGame_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/5sem/RL_ShakeGame_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/5sem/RL_ShakeGame_project/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:608\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/5sem/RL_ShakeGame_project/.venv/lib/python3.12/site-packages/torch/nn/functional.py:3791\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3789\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3791\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(\n\u001b[1;32m   3793\u001b[0m     expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3794\u001b[0m )\n",
      "File \u001b[0;32m~/5sem/RL_ShakeGame_project/.venv/lib/python3.12/site-packages/torch/functional.py:76\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m(tensors)\n",
      "File \u001b[0;32m~/5sem/RL_ShakeGame_project/.venv/lib/python3.12/site-packages/torch/_VF.py:27\u001b[0m, in \u001b[0;36mVFModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvf \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_VariableFunctions\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvf, name)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dqn(env, agent, episodes=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: 76\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n",
      "Reward: -1\n",
      "Reward: -1\n",
      "Reward: 1\n",
      "Reward: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mact(state)\n\u001b[1;32m      6\u001b[0m state, reward, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m----> 7\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/5sem/RL_ShakeGame_project/src/FullObsSnakeEnv.py:225\u001b[0m, in \u001b[0;36mFullobsSnakeEnv.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    222\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdraw\u001b[38;5;241m.\u001b[39mrect(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscreen, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m220\u001b[39m, \u001b[38;5;241m0\u001b[39m), segment_rect)  \u001b[38;5;66;03m# Green color for snake\u001b[39;00m\n\u001b[1;32m    224\u001b[0m pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mflip()\n\u001b[0;32m--> 225\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if isinstance(env, FullObsSnakeEnv):\n",
    "    env.interact = True\n",
    "else:\n",
    "    grid_size = env.grid_size\n",
    "    env = ParObsSnakeEnv(grid_size=2*grid_size)\n",
    "    \n",
    "state = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = agent.act(state)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    print(f\"Reward: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
